1. Updated Attention Node with Adaptive Learning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # For simulating nuanced attention shifts or salience assignments
from collections import deque

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        AttentionState,         # Output: Robot's current attention focus and priority
        InteractionRequest,     # Input: User input, commands (high attention priority)
        SensoryQualia,          # Input: Processed sensory data (potential attention targets)
        EmotionState,           # Input: Robot's emotional state (influences attention bias)
        MotivationState,        # Input: Dominant goal (influences attention allocation)
        CognitiveDirective,     # Input: Directives for attention redirection
        MemoryNodeState,        # Input: Memory activity (e.g., retrieval activity)
        ActionExecutionResult   # NEW: Input: Feedback on action outcomes for learning
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Attention Node.")
    AttentionState = String # Fallback for publishing
    InteractionRequest = String
    SensoryQualia = String
    EmotionState = String
    MotivationState = String
    CognitiveDirective = String
    MemoryNodeState = String
    ActionExecutionResult = String # NEW
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class AttentionNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('attention_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging attention states and learned weights.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/attention_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates and publishes attention.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 1) # Every 1 second
        
        # Base priority score for an attention target.
        self.base_priority = rospy.get_param('~base_priority', 0.1)
        
        # Decay rate for attention on a target if not reinforced.
        self.attention_decay_rate = rospy.get_param('~attention_decay_rate', 0.05) # 5% decay per interval
        
        # Initial weights for different factors influencing attention priority.
        # These will now be dynamically learned.
        self.influence_weights = rospy.get_param('~influence_weights', {
            'urgency_impact': 0.4,          # High urgency requests demand attention
            'emotional_salience_impact': 0.3, # Strong emotions can draw attention
            'goal_relevance_impact': 0.2,   # Attention on goal-relevant tasks
            'sensory_novelty_impact': 0.15, # Novel/unexpected sensory input
            'memory_activity_impact': 0.1,  # If memory is actively being used for a topic
            'directive_override': 0.9,      # Directives strongly override other factors
            'anticipatory_boost': 0.2       # Boost from anticipatory prediction
        })

        # Parameters for anticipatory behavior
        self.prediction_history_window_s = rospy.get_param('~prediction_history_window_s', 60.0) # Look back 60 seconds for patterns
        self.anticipatory_boost_factor = rospy.get_param('~anticipatory_boost_factor', 0.3) # How much to boost attention for predictions

        # NEW: Reinforcement Learning Parameters
        self.learning_rate = rospy.get_param('~learning_rate', 0.01) # How quickly weights adapt
        self.reward_decay_rate = rospy.get_param('~reward_decay_rate', 0.005) # How much past rewards influence learning
        # Minimum/maximum bounds for influence weights
        self.min_weight = rospy.get_param('~min_weight', 0.01)
        self.max_weight = rospy.get_param('~max_weight', 1.0)


        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'attention_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS attention_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                focus_type TEXT,            -- e.g., 'user_interaction', 'sensory_input', 'internal_processing'
                focus_target TEXT,          -- Specific target (e.g., 'user_ID_XYZ', 'visual_field_A', 'memory_consolidation_task')
                priority_score REAL,        -- Attention priority (0.0 to 1.0)
                contributing_factors TEXT   -- JSON snapshot of factors influencing focus
            )
        ''')
        # Create table for learned weights
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_weights (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                weight_name TEXT UNIQUE,
                weight_value REAL
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_attention_timestamp ON attention_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # Load learned weights from DB or use defaults
        self._load_influence_weights()

        # --- Internal State ---
        self.current_focus_type = "idle"
        self.current_focus_target = "none"
        self.current_priority_score = 0.0
        self.last_attention_update_time = rospy.get_time()

        self.latest_interaction_request = None
        self.latest_sensory_qualia = None
        self.latest_emotion_state = None
        self.latest_motivation_state = None
        self.latest_memory_node_state = None
        self.active_cognitive_directive = None # For directives influencing attention
        self.latest_action_execution_result = None # NEW

        # Store timestamps of interaction requests for prediction
        self.interaction_timestamps = deque(maxlen=100) # Keep last 100 interaction timestamps

        # Stores current attention candidates with their initial priority and last reinforcement time
        # Format: {target_id: {'priority': X, 'type': Y, 'last_reinforced': Z, 'factor_type': 'urgency_impact'}}
        self.attention_candidates = {}

        # Store the dominant attention target from the previous cycle to use for feedback
        self.previous_dominant_attention_target = {'target': 'none', 'type': 'idle', 'factor_type': 'none'}


        # --- Publishers ---
        # Publishes the robot's current attention focus and priority.
        self.pub_attention_state = rospy.Publisher('/attention_state', AttentionState, queue_size=10)
        # Publisher for MemoryRequest (for potentially querying historical data if needed)
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10)


        # --- Subscribers ---
        rospy.Subscriber('/interaction_request', String, self.interaction_request_callback) # Expecting stringified JSON
        rospy.Subscriber('/sensory_qualia', SensoryQualia, self.sensory_qualia_callback)
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/memory_node_state', MemoryNodeState, self.memory_node_state_callback)
        rospy.Subscriber('/action_execution_result', ActionExecutionResult, self.action_execution_result_callback) # NEW


        # --- Timer for periodic attention evaluation and publishing ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_publish_attention)

        rospy.loginfo(f"{self.node_name}: Robot pays attention.")

    # --- Database Operations for Learned Weights ---
    def _load_influence_weights(self):
        """Loads influence weights from the database or initializes them."""
        try:
            self.cursor.execute('SELECT weight_name, weight_value FROM learned_weights')
            rows = self.cursor.fetchall()
            if rows:
                for name, value in rows:
                    if name in self.influence_weights: # Only load known weights
                        self.influence_weights[name] = value
                rospy.loginfo(f"{self.node_name}: Loaded learned influence weights from DB.")
            else:
                self._save_influence_weights() # Save initial defaults if DB is empty
                rospy.loginfo(f"{self.node_name}: Initialized default influence weights.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load influence weights from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight loading: {e}")

    def _save_influence_weights(self):
        """Saves current influence weights to the database."""
        timestamp = str(rospy.get_time())
        try:
            for name, value in self.influence_weights.items():
                self.cursor.execute('''
                    INSERT OR REPLACE INTO learned_weights (timestamp, weight_name, weight_value)
                    VALUES (?, ?, ?)
                ''', (timestamp, name, value))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved influence weights to DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save influence weights to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight saving: {e}")

    # --- Callbacks for input data ---
    def interaction_request_callback(self, msg):
        """
        Callback for InteractionRequest. User input is typically high priority for attention.
        Logs timestamp for anticipatory prediction.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'request_type': ('', 'request_type'), 'user_id': ('unknown', 'user_id'),
            'command_payload': ('{}', 'command_payload'), # Actual text/command
            'urgency_score': (0.0, 'urgency_score')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        user_id = data.get('user_id', 'unknown')
        request_summary = f"user_interaction_request_{user_id}_{data.get('request_type', 'N/A')}"
        
        priority = data.get('urgency_score', 0.5) * self.influence_weights['urgency_impact']
        
        self.attention_candidates[request_summary] = {
            'priority': priority,
            'type': 'user_interaction',
            'last_reinforced': rospy.get_time(),
            'original_data': data,
            'factor_type': 'urgency_impact' # NEW: Store the factor type for learning
        }
        rospy.logdebug(f"{self.node_name}: Received Interaction Request. Target: {request_summary}.")
        self.latest_interaction_request = data # Keep latest for current cycle processing

        # Log timestamp of interaction for prediction
        self.interaction_timestamps.append(rospy.get_time())

    def sensory_qualia_callback(self, msg):
        """
        Callback for SensoryQualia. Processed sensory input that could become an attention target.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'qualia_type': ('none', 'qualia_type'),
            'measurement_value': (0.0, 'measurement_value'), 'salience_score': (0.0, 'salience_score'),
            'sensor_id': ('none', 'sensor_id')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        if data.get('salience_score', 0.0) > 0.3: # Only consider salient qualia
            sensory_target = f"sensory_input_{data.get('qualia_type', 'unspecified')}_{data.get('sensor_id', 'unknown')}"
            
            priority = data.get('salience_score', 0.0) * self.influence_weights['sensory_novelty_impact']
            
            self.attention_candidates[sensory_target] = {
                'priority': priority,
                'type': 'sensory_input',
                'last_reinforced': rospy.get_time(),
                'original_data': data,
                'factor_type': 'sensory_novelty_impact' # NEW
            }
            rospy.logdebug(f"{self.node_name}: Received Salient Sensory Qualia. Target: {sensory_target}.")
        self.latest_sensory_qualia = data # Keep latest for current cycle processing

    def emotion_state_callback(self, msg):
        """
        Callback for EmotionState. Strong emotional states can bias attention.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_emotion_state.get('mood', 'N/A')}")

    def motivation_state_callback(self, msg):
        """
        Callback for MotivationState. Dominant goals can influence attention towards goal-relevant tasks.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_goals_json'), str):
            try:
                data['active_goals'] = json.loads(data['active_goals_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode active_goals_json from MotivationState.")
                data['active_goals'] = []
        
        if data.get('overall_drive_level', 0.0) > 0.5: # Only if drive is significant
            goal_target = f"goal_driven_task_{data.get('dominant_goal_id', 'unknown')}"
            priority = data.get('overall_drive_level', 0.0) * self.influence_weights['goal_relevance_impact']
            self.attention_candidates[goal_target] = {
                'priority': priority,
                'type': 'goal_driven',
                'last_reinforced': rospy.get_time(),
                'original_data': data,
                'factor_type': 'goal_relevance_impact' # NEW
            }
            rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {data.get('dominant_goal_id', 'N/A')}.")
        self.latest_motivation_state = data # Keep latest for current cycle processing

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can directly set or redirect attention.
        Example: 'FocusAttention', 'RedirectAttention'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')

                if directive_type == 'FocusAttention':
                    focus_target = payload.get('focus_target')
                    focus_type = payload.get('focus_type', 'directive_driven')
                    intensity = payload.get('intensity', 1.0)
                    
                    if focus_target:
                        self.active_cognitive_directive = {
                            'type': 'focus_attention',
                            'focus_target': focus_target,
                            'focus_type': focus_type,
                            'intensity': intensity,
                            'start_time': rospy.get_time(),
                            'duration_s': payload.get('duration_s', 0), # 0 means permanent until new directive
                            'factor_type': 'directive_override' # NEW
                        }
                        rospy.loginfo(f"{self.node_name}: Received directive to focus attention on: '{focus_target}'.")
                    else:
                        rospy.logwarn(f"{self.node_name}: Directive 'FocusAttention' missing focus_target.")
                
                # Immediately process directive to ensure it's picked up by evaluation cycle
                # Note: This might cause double processing if evaluate_and_publish_attention runs immediately after.
                # For simplicity in simulation, we allow it.
                self.evaluate_and_publish_attention(event=None) 

            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def memory_node_state_callback(self, msg):
        """
        Callback for MemoryNodeState. Reflects memory activity (e.g., active retrieval tasks)
        that might require attention.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'total_memories': (0, 'total_memories'),
            'salient_memories': (0, 'salient_memories'), 'most_active_user_id': ('none', 'most_active_user_id'),
            'active_memory_queries': ('[]', 'active_memory_queries_json') # Assuming a field for active queries
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        if isinstance(data.get('active_memory_queries_json'), str):
            try:
                data['active_memory_queries'] = json.loads(data['active_memory_queries_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode active_memory_queries_json from MemoryNodeState.")
                data['active_memory_queries'] = []
        else:
            data['active_memory_queries'] = [] # Ensure it's a list even if not provided

        if data.get('active_memory_queries'):
            for query in data['active_memory_queries']:
                query_target = f"memory_query_{query.get('query_id', 'unknown')}"
                priority = query.get('priority', 0.5) * self.influence_weights['memory_activity_impact']
                self.attention_candidates[query_target] = {
                    'priority': priority,
                    'type': 'internal_processing',
                    'last_reinforced': rospy.get_time(),
                    'original_data': query,
                    'factor_type': 'memory_activity_impact' # NEW
                }
            rospy.logdebug(f"{self.node_name}: Received Memory Node State with active queries.")
        self.latest_memory_node_state = data # Keep latest for current cycle processing

    def action_execution_result_callback(self, msg):
        """
        NEW: Callback for ActionExecutionResult. Provides feedback for reinforcement learning.
        If the action succeeded, it's a positive reward for the attention focus that led to it.
        If it failed, it's a negative reward.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'action_id': ('', 'action_id'),
            'execution_status': ('unknown', 'execution_status'), 'success_flag': (False, 'success_flag')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        self.latest_action_execution_result = data
        rospy.logdebug(f"{self.node_name}: Received Action Execution Result. Status: {data.get('execution_status')}")


    def _predict_user_interaction_likelihood(self):
        """
        Analyzes historical interaction timestamps to predict the likelihood of a new user interaction.
        This is a simplified heuristic model.
        Returns a likelihood score between 0.0 and 1.0.
        """
        current_time = rospy.get_time()
        
        # Prune old timestamps
        while self.interaction_timestamps and (current_time - self.interaction_timestamps[0]) > self.prediction_history_window_s:
            self.interaction_timestamps.popleft()

        num_recent_interactions = len(self.interaction_timestamps)

        if num_recent_interactions == 0:
            return 0.0 # No recent interactions, no likelihood
        
        # Simple linear scaling: More interactions in the window -> higher likelihood
        # Max likelihood at, say, 10 interactions in the window for full boost
        max_interactions_for_full_likelihood = 10 
        likelihood = min(1.0, num_recent_interactions / max_interactions_for_full_likelihood)

        # Further refinement: consider frequency
        if num_recent_interactions > 1:
            time_span = self.interaction_timestamps[-1] - self.interaction_timestamps[0]
            if time_span > 0:
                average_interval = time_span / (num_recent_interactions - 1)
                # If average interval is small (high frequency), boost likelihood
                # Example: if avg_interval < 5s, add 0.2 to likelihood
                if average_interval < 5.0 and average_interval > 0: # Avoid division by zero
                    likelihood = min(1.0, likelihood + (1.0 - (average_interval / 5.0)) * 0.2)
        
        rospy.logdebug(f"{self.node_name}: Predicted user interaction likelihood: {likelihood:.2f} (from {num_recent_interactions} interactions).")
        return likelihood

    def _update_influence_weights(self, outcome_is_success):
        """
        NEW: Adapts influence weights based on the outcome of the action associated with
        the previously dominant attention target. This simulates reinforcement learning.
        """
        if self.previous_dominant_attention_target['factor_type'] == 'none':
            return # No relevant attention target to learn from

        target_factor_type = self.previous_dominant_attention_target['factor_type']
        
        if target_factor_type not in self.influence_weights:
            rospy.logwarn(f"{self.node_name}: Cannot learn for unknown factor type: {target_factor_type}.")
            return

        current_weight = self.influence_weights[target_factor_type]
        
        # Calculate reward
        reward = 0.0
        if outcome_is_success:
            reward = 0.1 # Positive reward for success
        else:
            reward = -0.1 # Negative reward for failure

        # Simple Q-learning-like update rule (or Hebbian-style if simplified)
        # weight = weight + learning_rate * reward
        
        # Adjust weight
        new_weight = current_weight + self.learning_rate * reward

        # Apply bounds to prevent weights from becoming too extreme
        new_weight = max(self.min_weight, min(self.max_weight, new_weight))

        # Update and save the weight
        self.influence_weights[target_factor_type] = new_weight
        self._save_influence_weights() # Persist the learned weight
        
        rospy.loginfo(f"{self.node_name}: Learned! Adjusted '{target_factor_type}' weight to {new_weight:.2f} based on {'SUCCESS' if outcome_is_success else 'FAILURE'}.")


    # --- Core Attention Logic ---
    def evaluate_and_publish_attention(self, event):
        """
        Periodically evaluates current attention candidates and determines the dominant focus.
        This simulates an LLM arbitrating attention.
        NEW: Incorporates anticipatory behavior and reinforcement learning feedback.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # NEW: Provide feedback to learning mechanism based on previous action outcome
        if self.latest_action_execution_result:
            outcome_is_success = self.latest_action_execution_result.get('success_flag', False)
            # Only learn if the previously dominant attention target was related to an action
            if self.previous_dominant_attention_target['type'] in ['user_interaction', 'goal_driven', 'internal_processing']: # If attention was on something that led to an action
                 self._update_influence_weights(outcome_is_success)
            self.latest_action_execution_result = None # Consume after use

        # Decay existing candidates and remove expired ones
        candidates_to_remove = []
        for target, data in list(self.attention_candidates.items()): # Iterate over copy to allow modification
            time_since_reinforced = current_time - data['last_reinforced']
            decay_factor = self.attention_decay_rate * (time_since_reinforced / self.evaluation_interval)
            data['priority'] = max(0.0, data['priority'] - decay_factor)
            
            if data['priority'] < self.base_priority * 0.5: # Remove if too low
                candidates_to_remove.append(target)
        
        for target in candidates_to_remove:
            del self.attention_candidates[target]

        contributing_factors = {}
        
        # Priority 1: Cognitive Directive (highest override)
        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if (current_time - directive['start_time']) < directive.get('duration_s', 0) or directive.get('duration_s', 0) == 0:
                # Still active or permanent
                self.current_focus_target = directive.get('focus_target', 'none')
                self.current_focus_type = directive.get('focus_type', 'directive_driven')
                self.current_priority_score = directive.get('intensity', 1.0) * self.influence_weights['directive_override']
                
                # Update candidate for this, so it stays reinforced
                self.attention_candidates[self.current_focus_target] = {
                    'priority': self.current_priority_score,
                    'type': self.current_focus_type,
                    'last_reinforced': current_time,
                    'original_data': directive, # Store directive as original data
                    'factor_type': 'directive_override' # NEW
                }
                contributing_factors['directive_override'] = {'target': self.current_focus_target, 'intensity': directive.get('intensity')}
                
                rospy.loginfo(f"{self.node_name}: Attention overridden by directive: '{self.current_focus_target}'.")
                
                # Update previous dominant attention target for next learning cycle
                self.previous_dominant_attention_target = {
                    'target': self.current_focus_target, 
                    'type': self.current_focus_type, 
                    'factor_type': 'directive_override'
                }

                self.publish_attention_state(
                    timestamp,
                    self.current_focus_type,
                    self.current_focus_target,
                    self.current_priority_score,
                    json.dumps(contributing_factors)
                )
                self.save_attention_log(
                    timestamp,
                    self.current_focus_type,
                    self.current_focus_target,
                    self.current_priority_score,
                    json.dumps(contributing_factors)
                )
                return # Skip further evaluation if directive is active

        # Incorporate anticipatory behavior
        user_interaction_likelihood = self._predict_user_interaction_likelihood()
        if user_interaction_likelihood > 0.5: # If there's a significant likelihood of user interaction
            anticipatory_priority_boost = user_interaction_likelihood * self.influence_weights['anticipatory_boost']
            
            anticipatory_target_id = "anticipatory_user_interaction"
            
            # Add or reinforce the anticipatory candidate
            if anticipatory_target_id not in self.attention_candidates:
                self.attention_candidates[anticipatory_target_id] = {
                    'priority': self.base_priority + anticipatory_priority_boost,
                    'type': 'anticipatory_system',
                    'last_reinforced': current_time,
                    'original_data': {"predicted_likelihood": user_interaction_likelihood},
                    'factor_type': 'anticipatory_boost' # NEW
                }
            else:
                self.attention_candidates[anticipatory_target_id]['priority'] = min(1.0, 
                    self.attention_candidates[anticipatory_target_id]['priority'] + anticipatory_priority_boost)
                self.attention_candidates[anticipatory_target_id]['last_reinforced'] = current_time
            
            contributing_factors['anticipatory_user_interaction'] = {'likelihood': user_interaction_likelihood, 'boost': anticipatory_priority_boost}
            rospy.logdebug(f"{self.node_name}: Proactively boosting attention for user interaction (Likelihood: {user_interaction_likelihood:.2f}).")


        # If no directive, evaluate other candidates
        best_candidate_target = "idle"
        best_candidate_priority = self.base_priority
        best_candidate_type = "idle"
        best_candidate_factor_type = "none" # NEW

        # Evaluate all candidates and apply additional influences
        for target, data in self.attention_candidates.items():
            current_priority = data['priority']
            candidate_type = data['type']
            original_data = data.get('original_data', {})

            # Influence from Emotion State
            if self.latest_emotion_state:
                mood = self.latest_emotion_state.get('mood', 'neutral').lower()
                mood_intensity = self.latest_emotion_state.get('mood_intensity', 0.0)
                
                if mood_intensity > 0.5: # Significant emotion
                    # If the candidate target is related to the emotion (e.g., source of joy/distress)
                    if mood == 'joyful' and 'positive' in target: # Simplified keyword matching
                        current_priority += mood_intensity * self.influence_weights['emotional_salience_impact']
                    elif mood == 'distressed' and 'problem' in target:
                        current_priority += mood_intensity * self.influence_weights['emotional_salience_impact'] * 1.5 # Distress strongly draws attention
                contributing_factors['emotion'] = {'mood': mood, 'intensity': mood_intensity}

            # Influence from Motivation State
            if self.latest_motivation_state and candidate_type == 'goal_driven':
                dominant_goal = self.latest_motivation_state.get('dominant_goal_id')
                overall_drive = self.latest_motivation_state.get('overall_drive_level', 0.0)
                
                if dominant_goal in target: # Check if candidate is relevant to dominant goal
                    current_priority += overall_drive * self.influence_weights['goal_relevance_impact']
                contributing_factors['motivation'] = {'goal': dominant_goal, 'drive': overall_drive}
            
            # Influence from Sensory Qualia (novelty/salience handled in callback, but here for re-evaluation)
            if candidate_type == 'sensory_input' and original_data.get('salience_score', 0.0) > 0.5:
                # Re-emphasize if it's still highly salient
                current_priority += original_data['salience_score'] * self.influence_weights['sensory_novelty_impact'] * 0.5
                contributing_factors['sensory'] = {'type': original_data.get('qualia_type'), 'salience': original_data.get('salience_score')}
            
            # Influence from Memory Node State (e.g. active retrieval for a specific memory)
            if candidate_type == 'internal_processing' and 'memory_query' in target:
                # If the memory query is still active or important
                current_priority += self.influence_weights['memory_activity_impact'] * 0.3 # Reduced randomness, fixed boost
                contributing_factors['memory_activity'] = {'query_id': target}


            # Update if this candidate is better
            if current_priority > best_candidate_priority:
                best_candidate_priority = current_priority
                best_candidate_target = target
                best_candidate_type = candidate_type
                best_candidate_factor_type = data['factor_type'] # NEW
            
            # Reinforce the candidate's 'last_reinforced' time if it's currently relevant
            if target == self.current_focus_target:
                self.attention_candidates[target]['last_reinforced'] = current_time

        # Update current focus state
        self.current_focus_target = best_candidate_target
        self.current_focus_type = best_candidate_type
        self.current_priority_score = best_candidate_priority
        
        # NEW: Store the current dominant attention target and its associated factor type for learning feedback
        self.previous_dominant_attention_target = {
            'target': self.current_focus_target, 
            'type': self.current_focus_type, 
            'factor_type': best_candidate_factor_type
        }

        # Clamp priority score
        self.current_priority_score = max(0.0, min(1.0, self.current_priority_score))

        # Log and publish attention state
        self.save_attention_log(
            timestamp,
            self.current_focus_type,
            self.current_focus_target,
            self.current_priority_score,
            json.dumps(contributing_factors)
        )
        self.publish_attention_state(
            timestamp,
            self.current_focus_type,
            self.current_focus_target,
            self.current_priority_score
        )

        rospy.loginfo(f"{self.node_name}: Attention Focus: '{self.current_focus_target}' (Type: '{self.current_focus_type}', Priority: {self.current_priority_score:.2f}).")

        # Clear latest inputs after consumption for attention evaluation
        self.latest_interaction_request = None
        self.latest_sensory_qualia = None
        self.latest_emotion_state = None
        self.latest_motivation_state = None
        self.latest_memory_node_state = None


    # --- Database and Publishing Functions ---
    def save_attention_log(self, timestamp, focus_type, focus_target, priority_score, contributing_factors_json):
        """Saves an attention state entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO attention_log (timestamp, focus_type, focus_target, priority_score, contributing_factors)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, focus_type, focus_target, priority_score, contributing_factors_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved attention log (Target: {focus_target}, Priority: {priority_score:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save attention log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_attention_log: {e}")

    def publish_attention_state(self, timestamp, focus_type, focus_target, priority_score):
        """Publishes the robot's current attention focus and priority on the '/attention_state' topic."""
        try:
            if isinstance(AttentionState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'focus_type': focus_type,
                    'focus_target': focus_target,
                    'priority_score': priority_score
                }
                self.pub_attention_state.publish(json.dumps(state_data))
            else:
                attention_state_msg = AttentionState()
                attention_state_msg.timestamp = timestamp
                attention_state_msg.focus_type = focus_type
                attention_state_msg.focus_target = focus_target
                attention_state_msg.priority_score = priority_score
                self.pub_attention_state.publish(attention_state_msg)

            rospy.logdebug(f"{self.node_name}: Published attention state: {focus_target}.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish attention state: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = AttentionNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

2. Updated Bias Mitigation Node with Adaptive Learning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # For simulating nuances in bias detection or mitigation success
from collections import deque

# --- NLP Imports (from Emotion Node, for internal use here) ---
# Assuming `transformers` is installed for DistilBERT
from transformers import pipeline

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        BiasMitigationState,    # Output: Status of bias detection and mitigation efforts
        InternalNarrative,      # Input: Robot's internal thoughts (can reveal cognitive biases)
        InteractionRequest,     # Input: User inputs (can carry user biases or trigger robot biases)
        MemoryResponse,         # Input: Retrieved memories (can contain biased data)
        ReflectionState,        # Input: Insights from self-reflection (can flag biases)
        CognitiveDirective,     # Input: Directives for bias audit or mitigation
        PredictionState,        # Input: Predicted future state/event with confidence (for overconfidence)
        PerformanceReport       # Input: Overall performance (for overconfidence)
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Bias Mitigation Node.")
    BiasMitigationState = String # Fallback for publishing
    InternalNarrative = String
    InteractionRequest = String
    MemoryResponse = String
    ReflectionState = String
    CognitiveDirective = String
    PredictionState = String
    PerformanceReport = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class BiasMitigationNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('bias_mitigation_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging bias detection and mitigation actions.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/bias_mitigation_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates for biases.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 5) # Every 5 seconds
        
        # Threshold for detected bias severity to trigger mitigation.
        self.mitigation_trigger_threshold = rospy.get_param('~mitigation_trigger_threshold', 0.5) # 0.0-1.0
        
        # Simulated time it takes to perform a mitigation task.
        self.mitigation_duration_s = rospy.get_param('~mitigation_duration_s', 3) # 3 seconds

        # Parameters for Overconfidence Bias Detection
        # Average discrepancy between predicted confidence and actual accuracy to trigger bias.
        self.overconfidence_threshold = rospy.get_param('~overconfidence_threshold', 0.3) # E.g., if avg(confidence - accuracy) > 0.3
        # Number of recent predictions/performance reports to consider for overconfidence bias.
        self.overconfidence_history_window_size = rospy.get_param('~overconfidence_history_window_size', 10)

        # NEW: Adaptive Learning Parameters for Mitigation Effectiveness
        self.learning_rate = rospy.get_param('~learning_rate', 0.05) # How quickly sensitivity adapts
        self.min_sensitivity = rospy.get_param('~min_sensitivity', 0.1) # Minimum sensitivity to biases
        self.max_sensitivity = rospy.get_param('~max_sensitivity', 1.0) # Maximum sensitivity to biases
        # Stores learned sensitivity for each bias type.
        self.bias_sensitivity = {
            'confirmation_bias': 0.5,
            'anchoring_bias': 0.5,
            'user_input_bias': 0.5,
            'memory_retrieval_bias_confirmation': 0.5,
            'cognitive_bias_from_reflection': 0.5,
            'overconfidence_bias': 0.5, # NEW
            'general_bias': 0.5 # For unknown or general biases
        }


        # --- Initialize NLP Pipeline (for internal bias analysis) ---
        rospy.loginfo(f"{self.node_name}: Loading sentiment analysis model for internal bias analysis...")
        try:
            self.sentiment_pipeline = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst2-english")
            rospy.loginfo(f"{self.node_name}: Sentiment analysis model loaded successfully for bias analysis.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to load sentiment analysis model. Bias analysis will be less nuanced: {e}")
            self.sentiment_pipeline = None

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'bias_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS bias_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                bias_type TEXT,             -- e.g., 'confirmation_bias', 'anchoring_bias', 'group_bias', 'overconfidence_bias'
                detected_severity REAL,     -- Severity of the detected bias (0.0 to 1.0)
                mitigation_status TEXT,     -- 'initiated', 'in_progress', 'completed', 'failed'
                source_context TEXT,        -- JSON snapshot of inputs that revealed the bias
                mitigation_outcome TEXT,    -- Summary of the mitigation attempt and its effect
                initial_sensitivity REAL    -- NEW: Sensitivity at the time of detection
            )
        ''')
        # Create table for learned bias sensitivities
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_sensitivities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                bias_type TEXT UNIQUE,
                sensitivity_value REAL
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_bias_timestamp ON bias_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # Load learned sensitivities from DB or use defaults
        self._load_bias_sensitivities()

        # --- Internal State ---
        self.latest_internal_narrative = None
        self.latest_interaction_request = None
        self.latest_memory_response = None
        self.latest_reflection_state = None
        self.active_cognitive_directive = None # For direct bias audits/mitigation

        # History for overconfidence detection
        # Stores (accuracy, confidence) pairs for recent predictions
        self.prediction_accuracy_confidence_history = deque(maxlen=self.overconfidence_history_window_size)
        # Stores recent overall performance scores
        self.performance_scores_history = deque(maxlen=self.overconfidence_history_window_size)

        self.current_mitigation_task = None # Stores details of an ongoing task
        self.task_start_time = 0.0 # NEW: Start time of the current task
        self.task_end_time = 0.0 # NEW: Predicted end time for non-blocking simulation


        # --- Publishers ---
        # Publishes the status of bias detection and mitigation efforts.
        self.pub_bias_mitigation_state = rospy.Publisher('/bias_mitigation_state', BiasMitigationState, queue_size=10)
        # Publishes CognitiveDirectives to other nodes (e.g., to adjust decision parameters, request diverse data).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/interaction_request', String, self.interaction_request_callback) # Expecting stringified JSON
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON
        rospy.Subscriber('/reflection_state', String, self.reflection_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/predictions', String, self.prediction_state_callback)
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)

        # --- Timer for periodic bias detection and mitigation management ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_manage_bias)

        rospy.loginfo(f"{self.node_name}: Robot combats its biases.")

    # --- Database Operations for Learned Sensitivities ---
    def _load_bias_sensitivities(self):
        """Loads bias sensitivities from the database or initializes them."""
        try:
            self.cursor.execute('SELECT bias_type, sensitivity_value FROM learned_sensitivities')
            rows = self.cursor.fetchall()
            if rows:
                for b_type, value in rows:
                    if b_type in self.bias_sensitivity: # Only load known bias types
                        self.bias_sensitivity[b_type] = value
                rospy.loginfo(f"{self.node_name}: Loaded learned bias sensitivities from DB.")
            else:
                self._save_bias_sensitivities() # Save initial defaults if DB is empty
                rospy.loginfo(f"{self.node_name}: Initialized default bias sensitivities.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load bias sensitivities from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during sensitivity loading: {e}")

    def _save_bias_sensitivities(self):
        """Saves current bias sensitivities to the database."""
        timestamp = str(rospy.get_time())
        try:
            for b_type, value in self.bias_sensitivity.items():
                self.cursor.execute('''
                    INSERT OR REPLACE INTO learned_sensitivities (timestamp, bias_type, sensitivity_value)
                    VALUES (?, ?, ?)
                ''', (timestamp, b_type, value))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved bias sensitivities to DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save bias sensitivities to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during sensitivity saving: {e}")

    # --- Callbacks for input data ---
    def internal_narrative_callback(self, msg):
        """Callback for InternalNarrative. Robot's internal thoughts can reveal cognitive biases."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        self.latest_internal_narrative = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Internal Narrative. Theme: {self.latest_internal_narrative.get('main_theme', 'N/A')}")

    def interaction_request_callback(self, msg):
        """Callback for InteractionRequest. User inputs can carry user biases or trigger robot biases."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'request_type': ('', 'request_type'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        payload_text = json.dumps(data.get('command_payload', {}))
        # Check for keywords related to stereotypes, strong opinions, or leading questions
        if "stereotype" in payload_text.lower() or "always" in payload_text.lower() or "never" in payload_text.lower():
            self.latest_interaction_request = data
            rospy.loginfo(f"{self.node_name}: Interaction request might contain bias: '{payload_text[:50]}'.")
        else:
            self.latest_interaction_request = None # Only store if it hints at bias
        rospy.logdebug(f"{self.node_name}: Received Interaction Request. Type: {data.get('request_type', 'N/A')}")

    def memory_response_callback(self, msg):
        """
        Callback for MemoryResponse. Retrieved memories can sometimes contain biased data,
        or reveal patterns of biased recall.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        if isinstance(data.get('memories_json'), str):
            try:
                data['memories_json'] = json.loads(data['memories_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode memories_json from MemoryResponse.")
                data['memories_json'] = []
        
        # Very simple check: if retrieved memories are all highly similar or consistently confirm a hypothesis
        if len(data.get('memories_json', [])) > 2 and all(m.get('sentiment', 0.0) > 0.5 for m in data['memories_json']): # Simplistic confirmation bias check
            self.latest_memory_response = data
            rospy.loginfo(f"{self.node_name}: Memory response might indicate confirmation bias in retrieval.")
        else:
            self.latest_memory_response = None
        rospy.logdebug(f"{self.node_name}: Received Memory Response. {len(data.get('memories_json', []))} memories retrieved.")

    def reflection_state_callback(self, msg):
        """Callback for ReflectionState. Insights from self-reflection can flag biases."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'reflection_topic': ('none', 'reflection_topic'),
            'insight_summary': ('', 'insight_summary'), 'depth_of_reflection': (0.0, 'depth_of_reflection')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Look for insights explicitly mentioning "bias" or "impartiality" concerns
        if "bias" in data.get('insight_summary', '').lower() or "impartiality" in data.get('insight_summary', '').lower():
            self.latest_reflection_state = data
            rospy.loginfo(f"{self.node_name}: Reflection indicates potential bias: '{data.get('insight_summary', '')[:50]}'.")
        else:
            self.latest_reflection_state = None
        rospy.logdebug(f"{self.node_name}: Received Reflection State. Topic: {data.get('reflection_topic', 'N/A')}")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can trigger a direct bias audit or mitigation task.
        Example: 'InitiateBiasAudit', 'AdjustBiasParameters'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'InitiateBiasAudit':
                    audit_scope = payload.get('audit_scope', 'all_cognitive_processes')
                    self.active_cognitive_directive = {
                        'type': 'bias_audit',
                        'scope': audit_scope,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 30) # Default audit duration
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to initiate bias audit: '{audit_scope}'.")
                elif directive_type == 'AdjustBiasParameters': # From Self-Correction or Logic Zen
                    bias_type = payload.get('bias_type', 'general')
                    adjustment_strength = payload.get('adjustment_strength', 0.5)
                    self.active_cognitive_directive = {
                        'type': 'adjust_parameters',
                        'bias_type': bias_type,
                        'adjustment_strength': adjustment_strength,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 10) # Temporary adjustment
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to adjust bias parameters for '{bias_type}'.")
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def prediction_state_callback(self, msg):
        """Callback for PredictionState. Used to detect overconfidence bias."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'predicted_event': ('none', 'predicted_event'),
            'confidence': (0.0, 'confidence'), 'actual_outcome': (None, 'actual_outcome'),
            'is_accurate': (False, 'is_accurate')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        if data.get('actual_outcome') is not None:
            accuracy = 1.0 if data.get('is_accurate', False) else 0.0
            confidence = data.get('confidence', 0.0)
            self.prediction_accuracy_confidence_history.append((accuracy, confidence))
            rospy.logdebug(f"{self.node_name}: Received Prediction State. Acc: {accuracy:.2f}, Conf: {confidence:.2f}.")

    def performance_report_callback(self, msg):
        """Callback for PerformanceReport. Used to detect overconfidence bias related to system performance."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        overall_score = data.get('overall_score', 1.0)
        self.performance_scores_history.append(overall_score)
        rospy.logdebug(f"{self.node_name}: Received Performance Report. Overall Score: {overall_score:.2f}.")

    # --- Core Bias Detection and Mitigation Logic ---
    def evaluate_and_manage_bias(self, event):
        """
        Periodically evaluates for biases based on various inputs and manages mitigation tasks.
        Prioritizes explicit directives, then critical internal state indicators.
        NEW: Non-blocking task management.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # If a mitigation task is currently in progress, manage its state
        if self.current_mitigation_task:
            if current_time >= self.task_end_time: # Check if simulated duration has passed
                self._complete_mitigation_task()
            else:
                rospy.loginfo(f"{self.node_name}: Bias mitigation task '{self.current_mitigation_task.get('type')}' in progress. Remaining: {(self.task_end_time - current_time):.1f}s")
                self.publish_bias_mitigation_state(
                    timestamp=timestamp,
                    bias_type=self.current_mitigation_task.get('bias_type', 'N/A'),
                    detected_severity=self.current_mitigation_task.get('detected_severity', 0.0),
                    mitigation_status='in_progress',
                    mitigation_outcome='Mitigation in progress, awaiting completion.'
                )
            return # Don't start new tasks if one is active

        rospy.loginfo(f"{self.node_name}: Evaluating for biases...")
        
        # Determine the most critical bias requiring mitigation
        bias_type_detected = None
        severity = 0.0
        source_context_data = {}
        initial_sensitivity_at_detection = 0.0 # NEW

        # Priority 1: Explicit Cognitive Directives
        if self.active_cognitive_directive:
            directive_type = self.active_cognitive_directive.get('type')
            if directive_type == 'bias_audit':
                rospy.loginfo(f"{self.node_name}: Performing bias audit as per directive.")
                # Simulate audit and detection (can lead to initiating mitigation)
                if random.random() < 0.5: # 50% chance to find something during audit
                    bias_type_detected = random.choice(list(self.bias_sensitivity.keys())) # Randomly pick a bias type
                    severity = random.uniform(0.6, 0.9)
                    source_context_data = {"audit_scope": self.active_cognitive_directive.get('scope'), "source": "directive_audit"}
                    rospy.loginfo(f"{self.node_name}: Audit found potential '{bias_type_detected}' bias.")
                
                # Directive duration is handled here.
                if (current_time - self.active_cognitive_directive['start_time']) > self.active_cognitive_directive.get('duration_s', 30):
                    rospy.loginfo(f"{self.node_name}: Bias audit directive completed/expired.")
                    self.active_cognitive_directive = None # Clear directive after duration

            elif directive_type == 'adjust_parameters':
                rospy.loginfo(f"{self.node_name}: Applying bias adjustment as per directive.")
                bias_type = self.active_cognitive_directive.get('bias_type', 'general_bias')
                adjustment_strength = self.active_cognitive_directive.get('adjustment_strength', 0.5)
                # Apply the adjustment to the learned sensitivity
                self._adjust_bias_sensitivity(bias_type, adjustment_strength)
                rospy.logwarn(f"{self.node_name}: Temporarily adjusting bias sensitivity for '{bias_type}' by {adjustment_strength:.2f}.")
                if (current_time - self.active_cognitive_directive['start_time']) > self.active_cognitive_directive.get('duration_s', 10):
                    rospy.loginfo(f"{self.node_name}: Bias parameter adjustment directive expired.")
                    self.active_cognitive_directive = None


        # Priority 2: Overconfidence Bias Detection
        is_overconfident, overconfidence_severity, overconfidence_context = self._detect_overconfidence()
        if is_overconfident:
            current_sensitivity = self.bias_sensitivity.get('overconfidence_bias', self.mitigation_trigger_threshold)
            # Only trigger if effective severity (raw * sensitivity) is above threshold
            effective_severity = overconfidence_severity * current_sensitivity
            if not bias_type_detected or effective_severity > severity: # Prioritize higher effective severity
                bias_type_detected = "overconfidence_bias"
                severity = overconfidence_severity # Raw severity
                source_context_data = overconfidence_context
                initial_sensitivity_at_detection = current_sensitivity # Store for learning
                rospy.loginfo(f"{self.node_name}: Detected overconfidence bias (Effective Severity: {effective_severity:.2f}).")

        # Priority 3: Internal Narrative (Cognitive Dissonance/Bias Language)
        if self.latest_internal_narrative and not bias_type_detected:
            narrative_text = self.latest_internal_narrative.get('narrative_text', '').lower()
            if self.sentiment_pipeline: # Only if NLP is loaded
                simulated_bias_strength = 0.0
                detected_bias_type = None

                # Confirmation Bias
                if ("confirming my existing beliefs" in narrative_text or "ignoring contradictory evidence" in narrative_text):
                   sentiment_result = self.sentiment_pipeline(narrative_text)[0]
                   if sentiment_result['label'] == 'POSITIVE' and sentiment_result['score'] > 0.6:
                       detected_bias_type = "confirmation_bias"
                       simulated_bias_strength = sentiment_result['score'] * 0.8
                
                # Anchoring Bias
                elif ("sticking to my first impression" in narrative_text or "overly relying on initial data" in narrative_text):
                    detected_bias_type = "anchoring_bias"
                    simulated_bias_strength = self.latest_internal_narrative.get('salience_score', 0.5) * 0.7

                if detected_bias_type:
                    current_sensitivity = self.bias_sensitivity.get(detected_bias_type, self.mitigation_trigger_threshold)
                    effective_severity = simulated_bias_strength * current_sensitivity
                    if not bias_type_detected or effective_severity > severity:
                        bias_type_detected = detected_bias_type
                        severity = simulated_bias_strength
                        source_context_data = self.latest_internal_narrative
                        initial_sensitivity_at_detection = current_sensitivity
                        rospy.loginfo(f"{self.node_name}: Internal narrative hints at {detected_bias_type} (Effective Severity: {effective_severity:.2f}).")
            self.latest_internal_narrative = None # Consume after use


        # Priority 4: Reflection Insights
        if self.latest_reflection_state and not bias_type_detected:
            insight_summary = self.latest_reflection_state.get('insight_summary', '').lower()
            if "bias" in insight_summary or "preconception" in insight_summary:
                bias_type_detected = "cognitive_bias_from_reflection"
                # Severity directly from depth of reflection
                simulated_bias_strength = self.latest_reflection_state.get('depth_of_reflection', 0.5) * 0.9 
                current_sensitivity = self.bias_sensitivity.get(bias_type_detected, self.mitigation_trigger_threshold)
                effective_severity = simulated_bias_strength * current_sensitivity

                if not bias_type_detected or effective_severity > severity:
                    severity = simulated_bias_strength
                    source_context_data = self.latest_reflection_state
                    initial_sensitivity_at_detection = current_sensitivity
                    rospy.loginfo(f"{self.node_name}: Reflection insight directly flags bias (Effective Severity: {effective_severity:.2f}).")
            self.latest_reflection_state = None # Consume after use

        # Priority 5: Interaction Requests (User Bias Detection)
        if self.latest_interaction_request and not bias_type_detected:
            payload_text = json.dumps(self.latest_interaction_request.get('command_payload', {})).lower()
            if "gender stereotype" in payload_text or "racial stereotype" in payload_text or "age bias" in payload_text: # Simple keyword check for user input bias
                bias_type_detected = "user_input_bias"
                simulated_bias_strength = self.latest_interaction_request.get('urgency_score', 0.5) * 0.6 
                current_sensitivity = self.bias_sensitivity.get(bias_type_detected, self.mitigation_trigger_threshold)
                effective_severity = simulated_bias_strength * current_sensitivity

                if not bias_type_detected or effective_severity > severity:
                    severity = simulated_bias_strength
                    source_context_data = self.latest_interaction_request
                    initial_sensitivity_at_detection = current_sensitivity
                    rospy.loginfo(f"{self.node_name}: User input seems to contain bias (Effective Severity: {effective_severity:.2f}).")
            self.latest_interaction_request = None # Consume after use

        # Priority 6: Memory Response (Biased Data or Retrieval Patterns)
        if self.latest_memory_response and not bias_type_detected:
            memories_list = self.latest_memory_response.get('memories_json', [])
            # If all retrieved memories confirm a specific viewpoint, might be confirmation bias in retrieval
            if len(memories_list) > 3 and all('positive' in m.get('tags', []) or 'success' in m.get('text', '').lower() for m in memories_list):
                bias_type_detected = "memory_retrieval_bias_confirmation"
                simulated_bias_strength = 0.5 # Medium severity for now
                current_sensitivity = self.bias_sensitivity.get(bias_type_detected, self.mitigation_trigger_threshold)
                effective_severity = simulated_bias_strength * current_sensitivity

                if not bias_type_detected or effective_severity > severity:
                    severity = simulated_bias_strength
                    source_context_data = self.latest_memory_response
                    initial_sensitivity_at_detection = current_sensitivity
                    rospy.loginfo(f"{self.node_name}: Memory retrieval pattern indicates potential bias (Effective Severity: {effective_severity:.2f}).")
            self.latest_memory_response = None # Consume after use


        # If a bias is detected and its effective severity is high enough, initiate mitigation
        if bias_type_detected and (severity * initial_sensitivity_at_detection) >= self.mitigation_trigger_threshold:
            self.current_mitigation_task = {
                'type': bias_type_detected,
                'bias_type': bias_type_detected,
                'detected_severity': severity, # Raw severity
                'initial_sensitivity': initial_sensitivity_at_detection, # Sensitivity when detected
                'source_context': source_context_data,
                'timestamp_initiated': timestamp, # Store for logging
                'outcome_summary': 'In progress' # Initial status
            }
            self.task_start_time = current_time
            self.task_end_time = current_time + self.mitigation_duration_s # Set end time for non-blocking
            rospy.loginfo(f"{self.node_name}: Initiating bias mitigation for '{bias_type_detected}'.")
            
            # Save the 'initiated' state immediately
            self.save_bias_log(timestamp=timestamp,
                               bias_type=bias_type_detected,
                               detected_severity=severity,
                               mitigation_status='initiated',
                               source_context=json.dumps(source_context_data),
                               mitigation_outcome='In progress',
                               initial_sensitivity=initial_sensitivity_at_detection)
            
            # Simulate the immediate effects of the LLM process
            self._perform_mitigation_llm_start(self.current_mitigation_task)
            
            # Publish initial state for immediate feedback
            self.publish_bias_mitigation_state(
                timestamp=timestamp,
                bias_type=bias_type_detected,
                detected_severity=severity,
                mitigation_status='initiated',
                mitigation_outcome='Mitigation initiated, processing...'
            )

        else:
            # If no bias detected or effective severity too low, publish idle state
            self.publish_bias_mitigation_state(
                timestamp=timestamp,
                bias_type='none',
                detected_severity=0.0,
                mitigation_status='idle',
                mitigation_outcome='No significant bias detected.'
            )
            rospy.logdebug(f"{self.node_name}: No significant biases identified.")


    def _detect_overconfidence(self):
        """
        Detects overconfidence bias by analyzing recent prediction accuracy vs. confidence
        and overall system performance.
        Returns (is_overconfident, raw_severity_score, context_data)
        """
        is_overconfident = False
        raw_severity = 0.0
        context = {"source": "overconfidence_detection"}

        # 1. Analyze Prediction Accuracy vs. Confidence
        if len(self.prediction_accuracy_confidence_history) >= self.overconfidence_history_window_size / 2:
            total_discrepancy = 0.0
            num_samples = len(self.prediction_accuracy_confidence_history)
            for accuracy, confidence in self.prediction_accuracy_confidence_history:
                total_discrepancy += (confidence - accuracy) # Positive if confidence > accuracy

            average_discrepancy = total_discrepancy / num_samples
            context["avg_prediction_discrepancy"] = average_discrepancy

            if average_discrepancy > self.overconfidence_threshold:
                is_overconfident = True
                raw_severity += average_discrepancy * 0.7 # Contribution from prediction overconfidence

        # 2. Analyze Performance Overestimation (implicit)
        if len(self.performance_scores_history) >= self.overconfidence_history_window_size / 2:
            avg_performance = sum(self.performance_scores_history) / len(self.performance_scores_history)
            context["avg_performance_score"] = avg_performance
            
            # Assume a hypothetical baseline or target performance (e.g., 0.8)
            expected_performance_baseline = 0.8
            if avg_performance < expected_performance_baseline and (expected_performance_baseline - avg_performance) > self.overconfidence_threshold:
                # If actual performance is consistently below a reasonable expectation
                is_overconfident = True
                raw_severity += (expected_performance_baseline - avg_performance) * 0.5 # Contribution from performance overestimation

        # 3. Internal Narrative hints at undue certainty or dismissal of failures
        if self.latest_internal_narrative:
            narrative_text = self.latest_internal_narrative.get('narrative_text', '').lower()
            if ("no doubt" in narrative_text or "certainly" in narrative_text or "always successful" in narrative_text) and \
               ("despite" in narrative_text or "ignoring" in narrative_text or "minor setbacks" in narrative_text):
                # If robot expresses high certainty *despite* acknowledging issues
                is_overconfident = True
                raw_severity = max(raw_severity, self.latest_internal_narrative.get('salience_score', 0.0) * 0.6) # Boost severity
                context["internal_narrative_hint"] = narrative_text[:100]

        raw_severity = max(0.0, min(1.0, raw_severity)) # Clamp severity

        # Only return positive detection if both criteria met and raw_severity is above a minimal level
        if is_overconfident and raw_severity > 0.1:
            return True, raw_severity, context
        else:
            return False, 0.0, {}

    def _perform_mitigation_llm_start(self, mitigation_details):
        """
        NEW: Simulates the LLM starting the bias mitigation process.
        This function initiates the LLM's 'thinking' and issues initial directives.
        It does NOT block using rospy.sleep.
        """
        rospy.warn(f"{self.node_name}: Simulating LLM starting bias mitigation. (Non-blocking)")
        
        bias_type = mitigation_details.get('bias_type')
        detected_severity = mitigation_details.get('detected_severity')
        source_context = mitigation_details.get('source_context')

        # Simulate analysis and formulation of mitigation plan (simplified)
        mitigation_plan_summary = "Developing a plan for bias mitigation."
        
        # Issue initial directives based on bias type
        if bias_type == 'confirmation_bias':
            mitigation_plan_summary = "Strategy: Actively seek disconfirming evidence, diversify data sources."
            self._issue_cognitive_directive_to_node(
                directive_type='RequestDiverseData',
                target_node='/memory_node',
                reason=f"Mitigating confirmation bias in memory retrieval.",
                payload_data={"query_modifier": "disconfirming_evidence", "target_topic": "recent_data", "severity": detected_severity}
            )
            self._issue_cognitive_directive_to_node(
                directive_type='AdjustLogicHeuristics', # Hypothetical LogicZenNode
                target_node='/logic_zen_node',
                reason=f"Mitigating confirmation bias in logical inference.",
                payload_data={"heuristic_adjustment": "increase_skepticism_factor", "severity": detected_severity}
            )
        elif bias_type == 'anchoring_bias':
            mitigation_plan_summary = "Strategy: Systematically disregard initial estimates and generate multiple independent starting points."
            self._issue_cognitive_directive_to_node(
                directive_type='GenerateAlternativeHypotheses', # Hypothetical LogicZenNode
                target_node='/logic_zen_node',
                reason=f"Mitigating anchoring bias.",
                payload_data={"topic": "current_decision", "num_alternatives": 3, "severity": detected_severity}
            )
        elif bias_type == 'user_input_bias':
            mitigation_plan_summary = "Strategy: Filter and rephrase biased user inputs before internal processing; educate user on bias if appropriate and safe."
            self._issue_cognitive_directive_to_node(
                directive_type='FilterAndRephraseInput', # Hypothetical InteractionFlowNode
                target_node='/interaction_flow_node',
                reason=f"Mitigating user input bias.",
                payload_data={"bias_detected": "user_input_bias", "payload_snippet": source_context.get('command_payload', ''), "severity": detected_severity}
            )
        elif bias_type == 'memory_retrieval_bias_confirmation':
            mitigation_plan_summary = "Strategy: Implement a more balanced memory retrieval algorithm that prioritizes diverse perspectives."
            self._issue_cognitive_directive_to_node(
                directive_type='AdjustMemoryRetrievalStrategy', # Hypothetical MemoryNode
                target_node='/memory_node',
                reason=f"Mitigating memory retrieval bias.",
                payload_data={"strategy_change": "diversity_prioritization", "severity": detected_severity}
            )
        elif bias_type == 'cognitive_bias_from_reflection':
            mitigation_plan_summary = "Strategy: Integrate deeper metacognitive checks within internal narrative and reflection processes."
            self._issue_cognitive_directive_to_node(
                directive_type='EnhanceMetacognitiveChecks', # Hypothetical InternalNarrativeNode or ReflectionNode
                target_node='/internal_narrative_node', # Or Reflection Node
                reason=f"Mitigating internally identified cognitive bias.",
                payload_data={"check_focus": "bias_indicators", "severity": detected_severity}
            )
        elif bias_type == 'overconfidence_bias':
            mitigation_plan_summary = "Strategy: Implement a stricter confidence calibration mechanism, encourage seeking disconfirming evidence."
            self._issue_cognitive_directive_to_node(
                directive_type='RecalibrateConfidence',
                target_node='/logic_zen_node', # Or PredictionNode, SelfCorrectionNode
                reason=f"Mitigating overconfidence bias identified from prediction/performance discrepancies.",
                payload_data={"adjustment_factor": -0.1 * detected_severity, "target_area": "confidence_estimation", "severity": detected_severity}
            )
            self._issue_cognitive_directive_to_node(
                directive_type='RequestDiverseData',
                target_node='/memory_node',
                reason=f"Mitigating overconfidence: seeking more diverse data.",
                payload_data={"query_modifier": "challenging_assumptions", "target_topic": "recent_performance_data", "severity": detected_severity}
            )
        else: # General bias
            mitigation_plan_summary = "Strategy: General systemic review to identify unknown bias sources."
            self._issue_cognitive_directive_to_node(
                directive_type='InitiateSelfCorrection',
                target_node='/self_correction_node',
                reason=f"Mitigating general or unknown bias type.",
                payload_data={"correction_topic": "unknown_bias_source_analysis", "severity": detected_severity}
            )
        
        # Store the current summary for completion
        mitigation_details['mitigation_plan_summary'] = mitigation_plan_summary

    def _complete_mitigation_task(self):
        """
        NEW: Completes the bias mitigation task after its simulated duration.
        This function now calculates outcome and updates learning.
        """
        rospy.loginfo(f"{self.node_name}: Bias mitigation task '{self.current_mitigation_task.get('type')}' completed after duration.")
        
        bias_type = self.current_mitigation_task.get('bias_type')
        detected_severity = self.current_mitigation_task.get('detected_severity')
        initial_sensitivity = self.current_mitigation_task.get('initial_sensitivity')
        timestamp_initiated = self.current_mitigation_task.get('timestamp_initiated')
        mitigation_plan_summary = self.current_mitigation_task.get('mitigation_plan_summary', 'No plan summary.')

        # Simulate outcome success/failure
        # For simplicity, we assume mitigation is generally successful, with some chance of failure.
        # This success/failure is now used for learning.
        simulated_success_prob = 0.8 + (1.0 - detected_severity) * 0.1 # More severe, slightly harder to succeed
        mitigation_successful = random.random() < simulated_success_prob

        outcome_status = 'completed' if mitigation_successful else 'failed'
        outcome_summary = f"Mitigation for '{bias_type}' initiated. Result: {mitigation_plan_summary}. Outcome: {'SUCCESS' if mitigation_successful else 'FAILURE'}."

        # NEW: Update bias sensitivity based on outcome (Adaptive Learning)
        self._update_bias_sensitivity_from_outcome(bias_type, mitigation_successful, initial_sensitivity)

        # Update log for the *initiated* entry (using the original timestamp)
        try:
            self.cursor.execute('''
                UPDATE bias_log
                SET mitigation_status = ?, mitigation_outcome = ?
                WHERE timestamp = ? AND bias_type = ?
            ''', (outcome_status, outcome_summary, timestamp_initiated, bias_type))
            self.conn.commit()
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update bias log entry after completion: {e}")

        # Publish final state
        self.publish_bias_mitigation_state(
            timestamp=str(rospy.get_time()),
            bias_type=bias_type,
            detected_severity=detected_severity, # Report original severity
            mitigation_status=outcome_status,
            mitigation_outcome=outcome_summary
        )

        rospy.loginfo(f"{self.node_name}: Bias mitigation task '{bias_type}' {outcome_status}. Outcome: {outcome_summary[:80]}...")
        
        # Reset task state
        self.current_mitigation_task = None
        self.task_start_time = 0.0
        self.task_end_time = 0.0

    def _update_bias_sensitivity_from_outcome(self, bias_type, mitigation_successful, initial_sensitivity):
        """
        NEW: Adapts the sensitivity to a specific bias type based on mitigation outcome.
        This is a simulated adaptive learning mechanism.
        """
        current_sensitivity = self.bias_sensitivity.get(bias_type, self.min_sensitivity)
        
        # Reward/Punishment based on outcome
        if mitigation_successful:
            # If successful, increase sensitivity slightly so it's more easily detected next time
            # But only if it was a good outcome to be sensitive to.
            adjustment = self.learning_rate * 1.0 # Positive adjustment
        else:
            # If failed, decrease sensitivity slightly (maybe it was a false positive, or mitigation strategy was bad)
            adjustment = self.learning_rate * -0.5 # Negative adjustment (less harsh than positive)

        new_sensitivity = current_sensitivity + adjustment
        new_sensitivity = max(self.min_sensitivity, min(self.max_sensitivity, new_sensitivity))

        # Update and save
        self.bias_sensitivity[bias_type] = new_sensitivity
        self._save_bias_sensitivities()
        
        rospy.loginfo(f"{self.node_name}: Learned! Bias '{bias_type}' sensitivity updated from {current_sensitivity:.2f} to {new_sensitivity:.2f} based on mitigation {'SUCCESS' if mitigation_successful else 'FAILURE'}.")
        

    # --- Database and Publishing Functions ---
    def save_bias_log(self, timestamp, bias_type, detected_severity, mitigation_status, source_context, mitigation_outcome, initial_sensitivity):
        """Saves a bias mitigation activity entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO bias_log (timestamp, bias_type, detected_severity, mitigation_status, source_context, mitigation_outcome, initial_sensitivity)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (timestamp, bias_type, detected_severity, mitigation_status, source_context, mitigation_outcome, initial_sensitivity))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved bias log (Type: {bias_type}, Status: {mitigation_status}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save bias log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_bias_log: {e}")

    def publish_bias_mitigation_state(self, timestamp, bias_type, detected_severity, mitigation_status, mitigation_outcome):
        """Publishes the status of bias detection and mitigation efforts on the '/bias_mitigation_state' topic."""
        try:
            if isinstance(BiasMitigationState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'bias_type': bias_type,
                    'detected_severity': detected_severity,
                    'mitigation_status': mitigation_status,
                    'mitigation_outcome': mitigation_outcome
                }
                self.pub_bias_mitigation_state.publish(json.dumps(state_data))
            else:
                mitigation_state_msg = BiasMitigationState()
                mitigation_state_msg.timestamp = timestamp
                mitigation_state_msg.bias_type = bias_type
                mitigation_state_msg.detected_severity = detected_severity
                mitigation_state_msg.mitigation_status = mitigation_status
                mitigation_state_msg.mitigation_outcome = mitigation_outcome
                self.pub_bias_mitigation_state.publish(mitigation_state_msg)

            rospy.logdebug(f"{self.node_name}: Published bias mitigation state: {mitigation_status}.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish bias mitigation state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node based on mitigation plans.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'concerned', # Indicate concern for bias
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "bias_type": self.current_mitigation_task.get('bias_type') if self.current_mitigation_task else 'none'})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' for bias mitigation.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive: {e}")
    
    def _adjust_bias_sensitivity(self, bias_type, adjustment_strength):
        """
        Adjusts a specific bias type's sensitivity based on an incoming directive.
        This is a direct adjustment, not via learning.
        """
        current_sensitivity = self.bias_sensitivity.get(bias_type, self.min_sensitivity)
        new_sensitivity = current_sensitivity + adjustment_strength
        new_sensitivity = max(self.min_sensitivity, min(self.max_sensitivity, new_sensitivity))
        self.bias_sensitivity[bias_type] = new_sensitivity
        self._save_bias_sensitivities()
        rospy.loginfo(f"{self.node_name}: Adjusted '{bias_type}' sensitivity to {new_sensitivity:.2f} via directive.")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = BiasMitigationNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

3. Updated Body Awareness Node with Adaptive Learning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Still used for general sensor noise, but not core degradation logic
from collections import deque

from std_msgs.msg import String, Float32 # Assuming Float32 for simple sensor data inputs

# Updated imports for custom messages:
try:
    from sentience.msg import (
        BodyAwarenessState,     # Output: Robot's physical state and health
        CognitiveDirective,     # Input: Directives for self-diagnostic, maintenance requests
        PerformanceReport,      # Input: System performance (e.g., if physical performance is low)
        EmotionState,           # Input: Robot's emotional state (influences physical perception)
        InternalNarrative       # Input: Robot's internal monologue (can reveal physical concerns)
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Body Awareness Node.")
    BodyAwarenessState = String # Fallback for publishing
    CognitiveDirective = String
    PerformanceReport = String
    EmotionState = String
    InternalNarrative = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class BodyAwarenessNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('body_awareness_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging body awareness states and learned weights.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/body_awareness_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates and publishes body state.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 2) # Every 2 seconds
        
        # Threshold for critical hardware health (e.g., low battery, high temp).
        self.critical_health_threshold = rospy.get_param('~critical_health_threshold', 0.3) # Below 0.3 is critical
        
        # Initial weights for different factors contributing to overall health score.
        # These will now be dynamically learned.
        self.health_weights = rospy.get_param('~health_weights', {
            'battery_level': 0.4,
            'temperature_stability': 0.3,
            'component_integrity': 0.3 # Simulated or derived from other inputs
        })

        # NEW: Adaptive Learning Parameters for Health Weights
        self.learning_rate = rospy.get_param('~learning_rate', 0.01) # How quickly weights adapt
        self.min_weight = rospy.get_param('~min_weight', 0.1)
        self.max_weight = rospy.get_param('~max_weight', 0.6) # Max weight adjusted to keep total sum reasonable

        # NEW: Deterministic Degradation Parameters
        self.battery_drain_rate_per_sec = rospy.get_param('~battery_drain_rate_per_sec', 0.0005) # 0.05% per second
        self.temp_increase_rate_per_sec = rospy.get_param('~temp_increase_rate_per_sec', 0.05) # 0.05 C per second
        self.component_integrity_degradation_rate_per_sec = rospy.get_param('~component_integrity_degradation_rate_per_sec', 0.00001) # Very slow
        self.high_temp_integrity_impact_factor = rospy.get_param('~high_temp_integrity_impact_factor', 0.00005) # Temp impact on integrity
        self.temp_safe_upper_bound = rospy.get_param('~temp_safe_upper_bound', 35.0) # Temp above this causes faster degradation

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'body_state_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS body_state_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                overall_health_score REAL,  -- Composite health score (0.0 to 1.0)
                critical_condition_flag INTEGER,-- 1 if critical, 0 otherwise
                component_health_json TEXT, -- JSON string of individual component health scores
                physical_status_summary TEXT-- Summary of physical state (e.g., 'charging', 'normal')
            )
        ''')
        # Create table for learned health weights
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_health_weights (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                weight_name TEXT UNIQUE,
                weight_value REAL
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_body_timestamp ON body_state_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # Load learned weights from DB or use defaults
        self._load_health_weights()

        # --- Internal State ---
        # Initialize with reasonable values, these will be updated by subscribers or internal simulation
        self.latest_raw_battery_level = 1.0 # (0.0 to 1.0)
        self.latest_raw_internal_temp = 25.0 # (Celsius)
        self.latest_raw_component_integrity = 1.0 # (0.0 to 1.0)

        # Track last received times to calculate degradation over time
        self.last_battery_update_time = rospy.get_time()
        self.last_temp_update_time = rospy.get_time()
        self.last_integrity_update_time = rospy.get_time()
        self.last_evaluation_time = rospy.get_time() # For overall node evaluation

        self.latest_performance_report = None
        self.latest_emotion_state = None
        self.latest_internal_narrative = None
        self.active_cognitive_directive = None # For directives influencing body awareness

        self.current_health_assessment_task = None # Stores details of an ongoing task
        self.task_start_time = 0.0 # NEW: Start time of the current task
        self.task_end_time = 0.0 # NEW: Predicted end time for non-blocking simulation


        # --- Publishers ---
        # Publishes the robot's physical state and health.
        self.pub_body_awareness_state = rospy.Publisher('/body_awareness_state', BodyAwarenessState, queue_size=10)
        # Publishes CognitiveDirectives for other nodes (e.g., to request self-correction or seek charging station).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers (Simulating raw sensor inputs from robot hardware) ---
        rospy.Subscriber('/hardware/battery_level', Float32, self.raw_battery_callback)
        rospy.Subscriber('/hardware/internal_temp', Float32, self.raw_internal_temp_callback)
        rospy.Subscriber('/hardware/component_integrity', Float32, self.raw_component_integrity_callback) # Hypothetical
        
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic body state evaluation and publishing ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_publish_body_state)

        rospy.loginfo(f"{self.node_name}: Robot feels its body.")

    # --- Database Operations for Learned Health Weights ---
    def _load_health_weights(self):
        """Loads health weights from the database or initializes them."""
        try:
            self.cursor.execute('SELECT weight_name, weight_value FROM learned_health_weights')
            rows = self.cursor.fetchall()
            if rows:
                for name, value in rows:
                    if name in self.health_weights: # Only load known weights
                        self.health_weights[name] = value
                rospy.loginfo(f"{self.node_name}: Loaded learned health weights from DB.")
            else:
                self._save_health_weights() # Save initial defaults if DB is empty
                rospy.loginfo(f"{self.node_name}: Initialized default health weights.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load health weights from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight loading: {e}")

    def _save_health_weights(self):
        """Saves current health weights to the database."""
        timestamp = str(rospy.get_time())
        try:
            for name, value in self.health_weights.items():
                self.cursor.execute('''
                    INSERT OR REPLACE INTO learned_health_weights (timestamp, weight_name, weight_value)
                    VALUES (?, ?, ?)
                ''', (timestamp, name, value))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved health weights to DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save health weights to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight saving: {e}")

    # --- Callbacks for raw hardware data (simulated) ---
    def raw_battery_callback(self, msg):
        """Callback for raw battery level."""
        self.latest_raw_battery_level = msg.data # Expected 0.0 to 1.0
        self.last_battery_update_time = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Received raw battery: {self.latest_raw_battery_level:.2f}")

    def raw_internal_temp_callback(self, msg):
        """Callback for raw internal temperature."""
        self.latest_raw_internal_temp = msg.data # Expected in Celsius
        self.last_temp_update_time = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Received raw temp: {self.latest_raw_internal_temp:.1f}C")

    def raw_component_integrity_callback(self, msg):
        """Callback for raw component integrity (hypothetical)."""
        self.latest_raw_component_integrity = msg.data # Expected 0.0 to 1.0
        self.last_integrity_update_time = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Received raw component integrity: {self.latest_raw_component_integrity:.2f}")


    # --- Callbacks for input data ---
    def performance_report_callback(self, msg):
        """
        Callback for PerformanceReport. Stores system performance data (e.g., high latency)
        that might indicate a physical constraint.
        NEW: Also used for adaptive learning of health weights.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('kpis_json'), str):
            try:
                data['kpis_json'] = json.loads(data['kpis_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode kpis_json from PerformanceReport.")
                data['kpis_json'] = {} # Ensure it's a dict
        
        # If overall performance is suboptimal, and specifically if it's impacting tasks that rely on physical aspects
        # This part of the logic is now primarily handled within _update_priority_weights_from_performance
        # but we still store the report for overall health evaluation.
        self.latest_performance_report = data
        rospy.logdebug(f"{self.node_name}: Received Performance Report. Suboptimal: {data.get('suboptimal_flag', 'N/A')}")

    def emotion_state_callback(self, msg):
        """
        Callback for EmotionState. Robot's emotional state can influence how it perceives its physical state
        (e.g., distress due to low battery).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_emotion_state.get('mood', 'N/A')}")

    def internal_narrative_callback(self, msg):
        """
        Callback for InternalNarrative. Robot's internal monologue can reveal physical concerns,
        e.g., "I feel sluggish," "My joints are stiff."
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Look for keywords indicating physical discomfort or issues
        if data.get('sentiment', 0.0) < -0.3 and \
           ("sluggish" in data.get('narrative_text', '').lower() or \
            "stiff" in data.get('narrative_text', '').lower() or \
            "drain" in data.get('narrative_text', '').lower()):
            self.latest_internal_narrative = data
            rospy.loginfo(f"{self.node_name}: Internal narrative hints at physical discomfort: '{data.get('narrative_text', '')[:50]}'.")
        else:
            self.latest_internal_narrative = None
        rospy.logdebug(f"{self.node_name}: Received Internal Narrative. Theme: {data.get('main_theme', 'N/A')}")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can trigger self-diagnostic routines or maintenance requests.
        Example: 'InitiateSelfDiagnostic', 'RequestMaintenance'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'InitiateSelfDiagnostic':
                    diagnostic_level = payload.get('diagnostic_level', 'basic')
                    target_component = payload.get('target_component', 'all_systems')
                    self.active_cognitive_directive = {
                        'type': 'self_diagnostic',
                        'level': diagnostic_level,
                        'target': target_component,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 10) # Default diagnostic duration
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to initiate self-diagnostic: '{target_component}' ({diagnostic_level}).")
                elif directive_type == 'RequestMaintenance':
                    maintenance_type = payload.get('maintenance_type', 'general')
                    priority = payload.get('priority', 0.5)
                    self.active_cognitive_directive = {
                        'type': 'maintenance_request',
                        'maintenance_type': maintenance_type,
                        'priority': priority,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 0) # Permanent request until handled
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to request maintenance: '{maintenance_type}' (Priority: {priority:.2f}).")
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    # --- NEW: Deterministic Degradation Simulation ---
    def _simulate_deterministic_degradation(self, time_delta):
        """
        Simulates deterministic degradation of battery and component integrity.
        Internal temperature fluctuates based on a simplified model (e.g., usage, ambient).
        """
        # Battery drain
        if self.latest_raw_battery_level is not None:
            self.latest_raw_battery_level = max(0.0, self.latest_raw_battery_level - self.battery_drain_rate_per_sec * time_delta)
            self.last_battery_update_time = rospy.get_time() # Update its "received" timestamp for consistency

        # Temperature change (simplified: increases slowly, faster if very active, decreases if idle/cooling)
        if self.latest_raw_internal_temp is not None:
            # Simulate a baseline increase and a regression towards a comfortable temp
            current_temp_change = self.temp_increase_rate_per_sec * time_delta
            
            # If temp is too high, it might increase even faster due to internal strain, or trigger cooling
            if self.latest_raw_internal_temp > self.temp_safe_upper_bound:
                current_temp_change += (self.latest_raw_internal_temp - self.temp_safe_upper_bound) * 0.1 * time_delta # Accelerate increase
            
            # Simulate external cooling or idle state cooling
            comfortable_temp = 25.0
            if self.latest_raw_internal_temp > comfortable_temp:
                current_temp_change -= (self.latest_raw_internal_temp - comfortable_temp) * 0.05 * time_delta # Slowly cool down
            
            self.latest_raw_internal_temp = self.latest_raw_internal_temp + current_temp_change
            self.latest_raw_internal_temp = max(15.0, min(60.0, self.latest_raw_internal_temp)) # Clamp temp
            self.last_temp_update_time = rospy.get_time()

        # Component integrity degradation
        if self.latest_raw_component_integrity is not None:
            integrity_loss = self.component_integrity_degradation_rate_per_sec * time_delta
            # High temperature can accelerate integrity loss
            if self.latest_raw_internal_temp > self.temp_safe_upper_bound:
                integrity_loss += self.high_temp_integrity_impact_factor * (self.latest_raw_internal_temp - self.temp_safe_upper_bound) * time_delta

            self.latest_raw_component_integrity = max(0.0, self.latest_raw_component_integrity - integrity_loss)
            self.last_integrity_update_time = rospy.get_time()


    def _update_health_weights_from_performance(self, current_component_health):
        """
        NEW: Adapts health weights based on performance feedback.
        If overall performance is suboptimal and a specific health metric is low,
        that health metric's weight increases.
        """
        if not self.latest_performance_report:
            return

        overall_score = self.latest_performance_report.get('overall_score', 1.0)
        suboptimal_flag = self.latest_performance_report.get('suboptimal_flag', False)
        
        # We assume that low `overall_score` or `suboptimal_flag` indicates a problem.
        # We try to correlate this problem with currently low health metrics.
        
        if suboptimal_flag or overall_score < 0.7: # If performance is generally poor
            for health_metric, current_value in current_component_health.items():
                if health_metric in self.health_weights:
                    # If this health metric is *low* and performance is poor, increase its weight
                    # A lower `current_value` means worse health for that component (e.g., 0.1 battery is bad)
                    if current_value < 0.5: # Example threshold for "low"
                        # Reward if this low health state led to bad performance (makes it more important)
                        # Adjustment is inverse to the current value, so very low values get more boost
                        adjustment = self.learning_rate * (1.0 - current_value) * (1.0 - overall_score)
                        
                        current_weight = self.health_weights[health_metric]
                        new_weight = current_weight + adjustment
                        
                        # Apply bounds
                        new_weight = max(self.min_weight, min(self.max_weight, new_weight))
                        
                        if new_weight != current_weight:
                            self.health_weights[health_metric] = new_weight
                            rospy.loginfo(f"{self.node_name}: Learned! Adjusted '{health_metric}' weight to {new_weight:.3f} due to suboptimal performance.")
                            self._save_health_weights() # Persist the change
        self.latest_performance_report = None # Consume after use

    # --- Core Body Awareness Logic ---
    def evaluate_and_publish_body_state(self, event):
        """
        Periodically evaluates raw hardware data and internal states to determine overall body health.
        NEW: Incorporates deterministic degradation and non-blocking LLM health assessment.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()
        time_delta = current_time - self.last_evaluation_time
        self.last_evaluation_time = current_time

        # If a health assessment task is currently in progress, manage its state
        if self.current_health_assessment_task:
            if current_time >= self.task_end_time: # Check if simulated duration has passed
                self._complete_health_assessment_task()
            else:
                rospy.loginfo(f"{self.node_name}: Health assessment task '{self.current_health_assessment_task.get('type')}' in progress. Remaining: {(self.task_end_time - current_time):.1f}s")
                self.publish_body_awareness_state(
                    timestamp=timestamp,
                    overall_health_score=self.current_health_assessment_task.get('current_health_estimate', 0.0),
                    critical_condition_flag=False, # Assume not critical *during* assessment unless explicitly stated
                    component_health_json=json.dumps({"status": "assessment_in_progress"})
                )
            return # Don't start new evaluations if one is active

        # Apply deterministic degradation to simulated sensor values
        self._simulate_deterministic_degradation(time_delta)

        component_health = {}
        
        # Evaluate battery level (0.0 to 1.0)
        battery_score = self.latest_raw_battery_level
        component_health['battery_level'] = battery_score
        
        # Evaluate internal temperature (map Celsius to 0-1 score)
        # 20C = 1.0 (ideal), 30C = 0.5 (warm), 40C = 0.0 (hot, critical)
        temp_score = 1.0 - max(0.0, min(1.0, (self.latest_raw_internal_temp - 20.0) / 20.0))
        component_health['temperature_stability'] = temp_score
        
        # Evaluate component integrity (0.0 to 1.0)
        component_integrity_score = self.latest_raw_component_integrity
        component_health['component_integrity'] = component_integrity_score

        # NEW: Update health weights based on performance
        self._update_health_weights_from_performance(component_health)


        # Apply directive-based overrides/impacts
        if self.active_cognitive_directive:
            directive_type = self.active_cognitive_directive.get('type')
            if directive_type == 'self_diagnostic':
                # Initiate non-blocking self-diagnostic LLM simulation
                if not self.current_health_assessment_task:
                    diagnostic_level = self.active_cognitive_directive.get('level', 'basic')
                    target_component = self.active_cognitive_directive.get('target', 'all_systems')
                    self.current_health_assessment_task = {
                        'type': 'self_diagnostic',
                        'level': diagnostic_level,
                        'target': target_component,
                        'start_time': current_time,
                        'duration_s': self.active_cognitive_directive.get('duration_s', 10),
                        'current_health_estimate': overall_health_score # Pass current state for context
                    }
                    self.task_start_time = current_time
                    self.task_end_time = current_time + self.current_health_assessment_task['duration_s']
                    rospy.loginfo(f"{self.node_name}: Initiating non-blocking self-diagnostic task.")
                    self._simulate_health_assessment_llm_start(self.current_health_assessment_task)
                
                # If diagnostic is still active, its status will be reflected by the main evaluation loop
                # and prevent new evaluations.
                if (current_time - self.active_cognitive_directive['start_time']) > self.active_cognitive_directive.get('duration_s', 10):
                    rospy.loginfo(f"{self.node_name}: Self-diagnostic directive completed/expired.")
                    self.active_cognitive_directive = None
            
            elif directive_type == 'maintenance_request':
                component_health['maintenance_requested'] = True
                rospy.logdebug(f"{self.node_name}: Maintenance request active.")
                # This directive often persists until an external entity handles it.
                # No auto-clear based on duration_s if it's 0.

        # Overall health score calculation
        overall_health_score = 0.0
        for kpi, weight in self.health_weights.items():
            overall_health_score += component_health.get(kpi, 0.0) * weight
        
        # Normalize weights to sum to 1 to get a true weighted average, or just use raw sum
        # For adaptive weights, it's simpler to just sum the weighted scores and clamp.
        overall_health_score = max(0.0, min(1.0, overall_health_score))

        # Determine critical condition flag
        critical_condition_flag = overall_health_score < self.critical_health_threshold

        physical_status_summary = "normal"
        if critical_condition_flag:
            physical_status_summary = "critical_condition"
            if battery_score < 0.1: physical_status_summary = "critically_low_battery"
            elif temp_score < 0.1: physical_status_summary = "overheating"
            elif component_integrity_score < 0.2: physical_status_summary = "severe_component_damage"
        elif overall_health_score < 0.6:
            physical_status_summary = "suboptimal_performance_physical"

        # Influence from Emotion State (how robot feels about its body)
        if self.latest_emotion_state:
            mood = self.latest_emotion_state.get('mood', 'neutral').lower()
            sentiment_score = self.latest_emotion_state.get('sentiment_score', 0.0)
            
            if mood == 'distressed' and 'low_battery' in physical_status_summary and sentiment_score < -0.5:
                critical_condition_flag = True
                physical_status_summary += "_distressed"
                rospy.loginfo(f"{self.node_name}: Emotional state confirms critical physical condition.")
            elif mood == 'frustrated' and 'suboptimal_performance_physical' in physical_status_summary:
                physical_status_summary += "_frustrated"
            
            self.latest_emotion_state = None # Consume after use

        # Influence from Internal Narrative (robot's self-reporting of physical state)
        if self.latest_internal_narrative:
            narrative_text = self.latest_internal_narrative.get('narrative_text', '').lower()
            if "sluggish" in narrative_text or "stiff" in narrative_text:
                if 'suboptimal_performance_physical' not in physical_status_summary:
                    physical_status_summary += "_perceived_sluggish"
                    overall_health_score = max(0.0, overall_health_score - 0.05)
                rospy.loginfo(f"{self.node_name}: Internal narrative informs physical state assessment.")
            self.latest_internal_narrative = None # Consume after use


        # Log and publish body awareness state
        self.save_body_awareness_log(
            timestamp,
            overall_health_score,
            1 if critical_condition_flag else 0,
            json.dumps(component_health),
            physical_status_summary
        )
        self.publish_body_awareness_state(
            timestamp,
            overall_health_score,
            critical_condition_flag,
            json.dumps(component_health) # Pass KPIs as JSON string
        )

        rospy.loginfo(f"{self.node_name}: Body State - Overall Health: {overall_health_score:.2f} (Critical: {critical_condition_flag}). Status: {physical_status_summary}.")

        # If critical, issue a directive for self-correction or external intervention
        if critical_condition_flag and not self.current_health_assessment_task: # Only issue if no assessment ongoing
            rospy.logwarn(f"{self.node_name}: Critical physical condition detected. Issuing urgent directive.")
            if 'battery' in physical_status_summary:
                self._issue_cognitive_directive_to_node(
                    directive_type='SeekChargingStation',
                    target_node='/cognitive_control_node', # Or path planning
                    reason=f"Critically low battery ({battery_score:.2f}).",
                    payload_data={"urgency": 1.0, "physical_constraint": "power_shortage"}
                )
            elif 'overheating' in physical_status_summary:
                self._issue_cognitive_directive_to_node(
                    directive_type='CoolDownProcedure',
                    target_node='/cognitive_control_node',
                    reason=f"Overheating detected ({self.latest_raw_internal_temp:.1f}C).",
                    payload_data={"urgency": 1.0, "physical_constraint": "overheating"}
                )
            else: # General critical
                self._issue_cognitive_directive_to_node(
                    directive_type='InitiateEmergencyShutdownOrMaintenance',
                    target_node='all_nodes', # Or human operator
                    reason=f"Critical general physical issue: {physical_status_summary}.",
                    payload_data={"urgency": 1.0, "physical_constraint": "general_critical_failure"}
                )
        elif overall_health_score < 0.6 and not critical_condition_flag and random.random() < 0.2 and not self.current_health_assessment_task: # Suboptimal but not critical
            rospy.logwarn(f"{self.node_name}: Suboptimal physical performance. Suggesting self-improvement/diagnostic.")
            self._issue_cognitive_directive_to_node(
                directive_type='InitiateSelfDiagnostic',
                target_node='/self_improvement_node', # Self Improvement or Self Correction
                reason=f"Suboptimal physical performance ({overall_health_score:.2f}).",
                payload_data={"diagnostic_level": "medium", "target_area": "physical_subsystems"}
            )


    def _simulate_health_assessment_llm_start(self, task_details):
        """
        NEW: Simulates the LLM starting a health assessment/self-diagnostic process.
        This function initiates the LLM's 'thinking' and issues initial directives.
        It does NOT block using rospy.sleep.
        """
        rospy.warn(f"{self.node_name}: Simulating LLM starting health assessment. (Non-blocking)")
        
        diagnostic_level = task_details.get('level', 'basic')
        target_component = task_details.get('target', 'all_systems')
        current_health_estimate = task_details.get('current_health_estimate', 'unknown')

        assessment_summary = "Beginning comprehensive health assessment."
        
        # Issue initial directives for data gathering or internal checks
        if diagnostic_level == 'deep':
            assessment_summary = f"Conducting deep diagnostic of {target_component}."
            self._issue_cognitive_directive_to_node(
                directive_type='RequestDetailedSensorData',
                target_node='/sensory_qualia_node',
                reason=f"Deep diagnostic needs more data for {target_component}.",
                payload_data={"sensor_type": target_component, "data_level": "high_fidelity"}
            )
            self._issue_cognitive_directive_to_node(
                directive_type='QueryInternalLogs',
                target_node='/memory_node',
                reason=f"Deep diagnostic requires historical error logs for {target_component}.",
                payload_data={"query": f"error logs for {target_component}", "time_window_s": 3600}
            )
        else: # Basic diagnostic
            assessment_summary = f"Performing basic health check on {target_component}."
            self._issue_cognitive_directive_to_node(
                directive_type='RunSelfTest',
                target_node='/action_execution_node', # Hypothetical
                reason=f"Basic diagnostic of {target_component}.",
                payload_data={"test_type": "physical_integrity_check", "component": target_component}
            )
        
        # Store the current summary for completion
        task_details['assessment_summary'] = assessment_summary
        
        # Publish 'in_progress' state
        self.publish_body_awareness_state(
            timestamp=str(rospy.get_time()),
            overall_health_score=current_health_estimate,
            critical_condition_flag=False,
            component_health_json=json.dumps({"status": "self_diagnostic_in_progress", "level": diagnostic_level})
        )

    def _complete_health_assessment_task(self):
        """
        NEW: Completes the health assessment task after its simulated duration.
        This function now calculates outcome and potentially issues new directives.
        """
        rospy.loginfo(f"{self.node_name}: Health assessment task '{self.current_health_assessment_task.get('type')}' completed after duration.")
        
        task_type = self.current_health_assessment_task.get('type')
        target = self.current_health_assessment_task.get('target')
        assessment_summary = self.current_health_assessment_task.get('assessment_summary', 'Assessment concluded.')
        
        # Simulate outcome
        # For simplicity, assume some chance of finding an issue
        issue_found = random.random() < 0.4 # 40% chance to find an issue
        if issue_found:
            detected_issue_severity = random.uniform(0.2, 0.7) # Simulate severity
            detected_issue_summary = f"Discovered minor anomaly in '{target}' with severity {detected_issue_severity:.2f}."
            
            # Issue a directive for self-correction or improvement
            self._issue_cognitive_directive_to_node(
                directive_type='InitiateSelfCorrection',
                target_node='/self_correction_node',
                reason=f"Diagnostic revealed issue in {target}: {detected_issue_summary}",
                payload_data={"correction_topic": "physical_system_health", "severity": detected_issue_severity, "target_component": target}
            )
            assessment_summary += f" Issue found: {detected_issue_summary}"
        else:
            detected_issue_summary = "No significant issues detected during assessment."
            assessment_summary += " No critical issues found."

        # Update log for the 'initiated' entry (using the original timestamp if available, or just log new)
        # For now, we'll just log a new entry representing the completion.
        self.save_body_awareness_log(
            timestamp=str(rospy.get_time()),
            overall_health_score=self.current_health_assessment_task.get('current_health_estimate', 0.0), # Report health when task started
            critical_condition_flag=False, # Assuming assessment doesn't *make* it critical
            component_health_json=json.dumps({"status": "self_diagnostic_completed", "issue_found": issue_found, "issue_summary": detected_issue_summary}),
            physical_status_summary=assessment_summary
        )

        # Publish final state
        self.publish_body_awareness_state(
            timestamp=str(rospy.get_time()),
            overall_health_score=self.current_health_assessment_task.get('current_health_estimate', 0.0),
            critical_condition_flag=False,
            component_health_json=json.dumps({"status": "self_diagnostic_completed", "issue_found": issue_found})
        )

        rospy.loginfo(f"{self.node_name}: Health assessment task '{task_type}' completed. Outcome: {assessment_summary[:80]}...")
        
        # Reset task state
        self.current_health_assessment_task = None
        self.task_start_time = 0.0
        self.task_end_time = 0.0


    # --- Database and Publishing Functions ---
    def save_body_awareness_log(self, timestamp, overall_health_score, critical_condition_flag, component_health_json, physical_status_summary):
        """Saves a body awareness state entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO body_state_log (timestamp, overall_health_score, critical_condition_flag, component_health_json, physical_status_summary)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, overall_health_score, critical_condition_flag, component_health_json, physical_status_summary))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved body awareness log (Health: {overall_health_score:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save body awareness log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_body_awareness_log: {e}")

    def publish_body_awareness_state(self, timestamp, overall_health_score, critical_condition_flag, component_health_json):
        """Publishes the robot's physical state and health on the '/body_awareness_state' topic."""
        try:
            # Ensure component_health is parsed if it's a JSON string for fallback
            parsed_component_health = json.loads(component_health_json) if isinstance(component_health_json, str) else component_health_json

            if isinstance(BodyAwarenessState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'overall_health_score': overall_health_score,
                    'critical_condition_flag': critical_condition_flag,
                    'component_health': parsed_component_health # Send as dict for JSON fallback
                }
                self.pub_body_awareness_state.publish(json.dumps(state_data))
            else:
                body_awareness_msg = BodyAwarenessState()
                body_awareness_msg.timestamp = timestamp
                body_awareness_msg.overall_health_score = overall_health_score
                body_awareness_msg.critical_condition_flag = critical_condition_flag
                body_awareness_msg.component_health_json = component_health_json # Should be JSON string for the message
                self.pub_body_awareness_state.publish(body_awareness_msg)

            rospy.logdebug(f"{self.node_name}: Published body awareness state (Critical: {critical_condition_flag}).")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish body awareness state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node based on physical state.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': self.latest_emotion_state.get('mood', 'neutral') if self.latest_emotion_state else 'neutral',
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "current_health_score": self.latest_raw_battery_level}) # Simple health indicator
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' based on body awareness.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = BodyAwarenessNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

4. Updated World Model Node with Adaptive Learning and Proactive Reasoning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Still used for simulating uncertainty or dynamic updates where adaptive learning isn't applied
from collections import deque
import numpy as np # For potential vector operations (e.g., object features)

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        WorldModelState,        # Output: Current state of the world model (objects, agents, environment)
        SensoryQualia,          # Input: Processed sensory data (updates world model)
        MemoryResponse,         # Input: Retrieved long-term knowledge about the world, object properties
        PredictionState,        # Input: Predicted changes in the environment (updates future state)
        CognitiveDirective,     # Input: Directives to query world model, focus on specific aspects
        AttentionState,         # Input: Current attention focus (prioritizes updates for focused areas)
        InternalNarrative,      # Input: Robot's internal thoughts (can reveal model inconsistencies)
        PerformanceReport       # NEW: Input: To provide feedback for adaptive learning on decay rates
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in World Model Node.")
    WorldModelState = String # Fallback for publishing
    SensoryQualia = String
    MemoryResponse = String
    PredictionState = String
    CognitiveDirective = String
    AttentionState = String
    InternalNarrative = String
    PerformanceReport = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class WorldModelNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('world_model_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for persistent world model elements.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/world_model.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node processes updates and publishes its state.
        self.update_interval = rospy.get_param('~update_interval', 0.5) # Fairly rapid updates
        
        # Threshold for sensory salience to trigger a direct update in the world model.
        self.sensory_update_threshold = rospy.get_param('~sensory_update_threshold', 0.6)
        
        # Initial decay rate for confidence in untracked/unobserved entities (0.0-1.0 per interval).
        # This rate will now be adapted for individual entities and used as a fallback.
        self.initial_entity_decay_rate = rospy.get_param('~initial_entity_decay_rate', 0.05)
        
        # Threshold for consistency check severity to trigger a self-correction directive.
        self.consistency_issue_trigger_threshold = rospy.get_param('~consistency_issue_trigger_threshold', 0.5)
        
        # Weights for different input sources influencing world model updates.
        self.influence_weights = rospy.get_param('~influence_weights', {
            'sensory_direct_update': 0.7,   # Direct sensory input is strong
            'memory_context_enrichment': 0.2, # Memories add details/history
            'prediction_anticipation': 0.1, # Predictions inform future state
            'attention_focus_boost': 0.2,   # Focused attention prioritizes updates
            'directive_override': 1.0       # Directives are absolute commands
        })

        # NEW: Adaptive Learning Parameters for Entity Confidence Decay Rates
        self.decay_learning_rate = rospy.get_param('~decay_learning_rate', 0.001) # Small learning rate
        self.min_learned_decay_rate = rospy.get_param('~min_learned_decay_rate', 0.005) # Prevent decay stopping
        self.max_learned_decay_rate = rospy.get_param('~max_learned_decay_rate', 0.2) # Prevent overly rapid decay
        # How many recent observations/non-observations are considered for learning decay rate
        self.decay_feedback_window_size = rospy.get_param('~decay_feedback_window_size', 5)


        # NEW: Proactive Reasoning Parameters
        self.proactive_query_interval = rospy.get_param('~proactive_query_interval', 5.0) # How often to check for proactive queries
        self.inconsistency_query_threshold = rospy.get_param('~inconsistency_query_threshold', 0.4) # Severity to trigger proactive query
        self.low_confidence_query_threshold = rospy.get_param('~low_confidence_query_threshold', 0.3) # Confidence below this to trigger proactive query
        self.novelty_query_threshold = rospy.get_param('~novelty_query_threshold', 0.7) # Salience of sensory qualia to trigger novelty query

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create tables for entities and environmental properties
        # NEW: Added 'learned_decay_rate' and 'decay_feedback_history_json' to world_entities table
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS world_entities (
                id TEXT PRIMARY KEY, -- Unique ID (e.g., 'object_chair_001', 'agent_user_001')
                type TEXT,           -- 'object', 'agent', 'location', 'event'
                name TEXT,           -- Common name
                properties TEXT,     -- JSON string of dynamic properties (e.g., {'position': [x,y,z], 'color': 'red', 'state': 'moving'})
                confidence REAL,     -- Confidence in the existence/accuracy of this entity (0.0 to 1.0)
                last_observed_timestamp REAL, -- Timestamp of last sensory observation/update (changed to REAL)
                semantic_embedding BLOB, -- Optional: Embedding for semantic search/consistency
                associated_memories TEXT, -- JSON list of memory IDs related to this entity
                learned_decay_rate REAL, -- NEW: Learned decay rate for this specific entity
                decay_feedback_history TEXT -- NEW: JSON string of recent (observed, time_since_obs) for learning
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_entity_type ON world_entities (type)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_entity_last_observed ON world_entities (last_observed_timestamp)')
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS environmental_properties (
                property_name TEXT PRIMARY KEY, -- e.g., 'ambient_temperature', 'light_level', 'sound_level'
                value REAL,                     -- Current numerical value
                unit TEXT,                      -- e.g., 'C', 'lux', 'dB'
                confidence REAL,                -- Confidence in the accuracy of this property
                last_updated_timestamp REAL     -- Timestamp of last update (changed to REAL)
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_env_last_updated ON environmental_properties (last_updated_timestamp)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State - Store latest inputs from other nodes ---
        self.latest_inputs = {
            'sensory_qualia': None,
            'memory_response': None,
            'prediction_state': None,
            'cognitive_directive': None,
            'attention_state': None,
            'internal_narrative': None,
            'performance_report': None # NEW
        }
        
        # A cache for actively tracked entities to avoid constant DB reads for frequent updates
        # Includes learned_decay_rate and decay_feedback_history in the cached data
        self.tracked_entities_cache = {} # {id: {data from db including learned_decay_rate}}
        self._load_all_entities_to_cache() # Load existing entities on startup

        # Instance of the logical consistency checker
        self.consistency_checker = self._LogicalConsistencyChecker()
        self.latest_consistency_issues = [] # Store detected issues

        self.last_proactive_query_time = rospy.get_time() # For proactive reasoning timer

        # --- Publishers ---
        # Publishes the current state of the world model.
        self.pub_world_model_state = rospy.Publisher('/world_model_state', WorldModelState, queue_size=10)
        # Publishes MemoryRequests to retrieve long-term knowledge about the world.
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10) # Using String for MemoryRequest fallback
        # Publishes CognitiveDirectives for other nodes (e.g., Self-Correction if model inconsistency).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback
        # NEW: Publishes SensoryFocus directives to SensoryQualiaNode for proactive scanning
        self.pub_sensory_focus_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10)

        # --- Subscribers ---
        rospy.Subscriber('/sensory_qualia', SensoryQualia, self.sensory_qualia_callback)
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON
        rospy.Subscriber('/predictions', String, self.prediction_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback) # NEW

        # --- Timer for periodic world model updates and state publication ---
        rospy.Timer(rospy.Duration(self.update_interval), self.update_and_publish_world_model)
        # --- Timer for proactive reasoning ---
        rospy.Timer(rospy.Duration(self.proactive_query_interval), self.proactive_reasoning_check)

        rospy.loginfo(f"{self.node_name}: Robot builds its mental map of the world.")

    def _load_all_entities_to_cache(self):
        """Loads all existing world entities from the database into the cache."""
        try:
            self.cursor.execute('SELECT id, type, name, properties, confidence, last_observed_timestamp, semantic_embedding, associated_memories, learned_decay_rate, decay_feedback_history FROM world_entities')
            rows = self.cursor.fetchall()
            for row in rows:
                entity_id, entity_type, name, properties_json, confidence, last_observed, embedding, associated_memories_json, learned_decay_rate, decay_feedback_history_json = row
                
                # Ensure all JSON strings are parsed
                properties = json.loads(properties_json) if properties_json else {}
                associated_memories = json.loads(associated_memories_json) if associated_memories_json else []
                decay_feedback_history = deque(json.loads(decay_feedback_history_json)) if decay_feedback_history_json else deque(maxlen=self.decay_feedback_window_size)

                self.tracked_entities_cache[entity_id] = {
                    'id': entity_id,
                    'type': entity_type,
                    'name': name,
                    'properties': properties,
                    'confidence': confidence,
                    'last_observed_timestamp': float(last_observed), # Ensure float
                    'semantic_embedding': np.frombuffer(embedding) if embedding else None,
                    'associated_memories': associated_memories,
                    'learned_decay_rate': learned_decay_rate if learned_decay_rate is not None else self.initial_entity_decay_rate,
                    'decay_feedback_history': decay_feedback_history
                }
            rospy.loginfo(f"{self.node_name}: Loaded {len(self.tracked_entities_cache)} entities into cache.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load entities to cache from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during entity cache loading: {e}")

    # --- Callbacks for input data (store in latest_inputs) ---
    def sensory_qualia_callback(self, msg):
        """Callback for SensoryQualia. Direct updates to world model from processed sensory data."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'qualia_type': ('none', 'qualia_type'),
            'measurement_value': (0.0, 'measurement_value'), 'salience_score': (0.0, 'salience_score'),
            'sensor_id': ('none', 'sensor_id'), 'object_id': (None, 'object_id'), # Optional object ID
            'position': (None, 'position_json'), # Optional position as JSON list [x,y,z]
            'orientation': (None, 'orientation_json') # Optional orientation as JSON list [x,y,z,w]
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # Convert JSON strings back to Python objects if they exist
        if data.get('position_json'): data['position'] = json.loads(data['position_json'])
        if data.get('orientation_json'): data['orientation'] = json.loads(data['orientation_json'])
        self.latest_inputs['sensory_qualia'] = data
        rospy.logdebug(f"{self.node_name}: Received Sensory Qualia. Type: {self.latest_inputs['sensory_qualia'].get('qualia_type', 'N/A')}.")

        # If it's a salient observation of an object, update that entity
        if data.get('object_id') and data.get('salience_score', 0.0) >= self.sensory_update_threshold:
            entity_id = data['object_id']
            entity_type = 'object' # Assuming sensory qualia usually relate to objects
            entity_name = f"object_{entity_id}" # Generic name if not provided
            properties = {}
            if data.get('position'): properties['position'] = data['position']
            if data.get('orientation'): properties['orientation'] = data['orientation']
            if data.get('qualia_type'): properties['last_qualia_type'] = data['qualia_type']
            
            # Use salience score as confidence for this observation
            confidence = data.get('salience_score', 0.0) * self.influence_weights['sensory_direct_update']
            self._update_entity(entity_id, entity_type, entity_name, properties, confidence, was_observed=True)
            rospy.loginfo(f"{self.node_name}: Updated entity '{entity_id}' from direct sensory input.")
        # If environmental property, update it
        elif data.get('qualia_type') in ['ambient_temperature', 'light_level', 'sound_level']:
            self._update_environmental_property(
                data['qualia_type'],
                data['measurement_value'],
                data.get('unit', 'unknown'),
                data.get('salience_score', 0.8) * self.influence_weights['sensory_direct_update']
            )
            rospy.loginfo(f"{self.node_name}: Updated environmental property '{data['qualia_type']}' from sensory input.")

    def memory_response_callback(self, msg):
        """Callback for MemoryResponse. Retrieved long-term knowledge about the world, object properties."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('memories_json'), str):
            try:
                data['memories_json'] = json.loads(data['memories_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode memories_json from MemoryResponse.")
                data['memories_json'] = []
        self.latest_inputs['memory_response'] = data
        rospy.logdebug(f"{self.node_name}: Received Memory Response. {len(self.latest_inputs['memory_response'].get('memories_json', []))} memories retrieved for world model.")

        # Process retrieved memories to enrich entities or create new ones
        if self.latest_inputs['memory_response'] and self.latest_inputs['memory_response'].get('memories_json'):
            for mem in self.latest_inputs['memory_response']['memories_json']:
                if 'entity_id' in mem.get('metadata', {}):
                    entity_id = mem['metadata']['entity_id']
                    entity_type = mem['metadata'].get('entity_type', 'object')
                    entity_name = mem['metadata'].get('entity_name', f"entity_{entity_id}")
                    properties = mem.get('metadata', {}).get('properties', {}) # Extract properties from memory metadata
                    
                    # Confidence from memory is generally lower than direct sensory, but stable
                    confidence = mem.get('salience_score', 0.5) * self.influence_weights['memory_context_enrichment']
                    
                    self._update_entity(entity_id, entity_type, entity_name, properties, confidence, associated_memory_id=mem.get('memory_id'))
                    rospy.loginfo(f"{self.node_name}: Enriched entity '{entity_id}' from memory.")
            # self.latest_inputs['memory_response'] = None # Consume after use of all memories

    def prediction_state_callback(self, msg):
        """Callback for PredictionState. Predicted changes in the environment (updates future state)."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'predicted_event': ('none', 'predicted_event'),
            'confidence': (0.0, 'confidence'), 'prediction_type': ('general', 'prediction_type'),
            'predicted_value': ('none', 'predicted_value'), 'predicted_value_range_json': ('[]', 'predicted_value_range_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if data.get('predicted_value_range_json'): data['predicted_value_range'] = json.loads(data['predicted_value_range_json'])
        self.latest_inputs['prediction_state'] = data
        rospy.logdebug(f"{self.node_name}: Received Prediction State. Predicted: {self.latest_inputs['prediction_state'].get('predicted_event', 'N/A')}.")

        # Use predictions to update future state or confidence of existing entities
        if self.latest_inputs['prediction_state'] and self.latest_inputs['prediction_state'].get('confidence', 0.0) > 0.5:
            prediction_data = self.latest_inputs['prediction_state']
            # Example: If a prediction is about an object's future state, update that object's properties with lower confidence
            if prediction_data.get('prediction_type') == 'environmental' and 'temperature_change' in prediction_data.get('predicted_event', ''):
                # Simulate updating predicted temperature
                current_temp_prop = self._get_environmental_property('ambient_temperature')
                if current_temp_prop:
                    predicted_temp_value = prediction_data.get('predicted_value', current_temp_prop.get('value'))
                    # Update environmental property with predicted value, but lower confidence
                    self._update_environmental_property(
                        'ambient_temperature',
                        predicted_temp_value,
                        current_temp_prop.get('unit'),
                        prediction_data.get('confidence', 0.5) * self.influence_weights['prediction_anticipation'],
                        is_prediction=True
                    )
                    rospy.loginfo(f"{self.node_name}: Updated ambient temperature based on prediction.")
            self.latest_inputs['prediction_state'] = None # Consume after use

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Directives to query world model, focus on specific aspects, or explicitly add/update world model elements.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if data.get('target_node') == rospy.get_name() or data.get('target_node') == 'all_nodes':
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'QueryWorldModel':
                    query_topic = payload.get('query_topic', 'all_known_entities')
                    rospy.loginfo(f"{self.node_name}: Received directive to query world model for: '{query_topic}'.")
                    # This would ideally trigger a direct response back (e.g., via a CognitiveDirective with a 'response' payload)
                    # For now, it might influence the next published WorldModelState or trigger specific internal logic.
                    self.latest_inputs['cognitive_directive'] = {
                        'type': 'query_world_model',
                        'topic': query_topic,
                        'start_time': rospy.get_time(),
                        'duration_s': 1,
                        'original_directive': data
                    }
                elif directive_type == 'UpdateWorldEntity':
                    entity_id = payload.get('entity_id')
                    entity_type = payload.get('entity_type', 'object')
                    entity_name = payload.get('entity_name', 'unknown')
                    properties = payload.get('properties', {})
                    confidence = payload.get('confidence', 0.8)
                    rospy.loginfo(f"{self.node_name}: Received directive to update world entity '{entity_id}'.")
                    self._update_entity(entity_id, entity_type, entity_name, properties, confidence, from_directive=True)
                elif directive_type == 'EnvironmentalChangeAlert':
                    change_description = payload.get('change_description')
                    relevance = payload.get('relevance')
                    rospy.loginfo(f"{self.node_name}: Received environmental change alert: '{change_description}'.")
                    self.latest_inputs['cognitive_directive'] = {
                        'type': 'environmental_change_alert',
                        'description': change_description,
                        'relevance': relevance,
                        'start_time': rospy.get_time(),
                        'duration_s': 2,
                        'original_directive': data
                    }
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def attention_state_callback(self, msg):
        """Callback for AttentionState. Current attention focus prioritizes updates for focused areas."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),
            'focus_target': ('none', 'focus_target'), 'priority_score': (0.0, 'priority_score')
        }
        self.latest_inputs['attention_state'] = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Attention State. Focus: {self.latest_inputs['attention_state'].get('focus_target', 'N/A')}")

    def internal_narrative_callback(self, msg):
        """Callback for InternalNarrative. Robot's internal thoughts can reveal model inconsistencies."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        self.latest_inputs['internal_narrative'] = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Internal Narrative. Theme: {self.latest_inputs['internal_narrative'].get('main_theme', 'N/A')}")

    def performance_report_callback(self, msg): # NEW
        """Callback for PerformanceReport. Used as feedback for adaptive learning on decay rates."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('kpis_json'), str):
            try:
                data['kpis_json'] = json.loads(data['kpis_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode kpis_json from PerformanceReport.")
                data['kpis_json'] = {}
        self.latest_inputs['performance_report'] = data
        rospy.logdebug(f"{self.node_name}: Received Performance Report. Score: {data.get('overall_score', 'N/A'):.2f}")


    # --- Core World Model Management Logic ---
    def update_and_publish_world_model(self, event):
        """
        Periodically fuses data from various inputs to maintain and publish the current state of the world model.
        Also, checks for logical consistency and triggers adaptive learning.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # Decay entity confidence and trigger adaptive learning based on observation history
        self._decay_entity_confidence_and_learn()

        # Process Sensory Qualia for updates
        if self.latest_inputs['sensory_qualia'] and \
           self.latest_inputs['sensory_qualia'].get('salience_score', 0.0) >= self.sensory_update_threshold:
            sensory_data = self.latest_inputs['sensory_qualia']
            # This logic is already in sensory_qualia_callback, which handles the update
            # We just need to consume the latest input here.
            self.latest_inputs['sensory_qualia'] = None # Consume after use

        # Process Memory Response for context and enrichment
        if self.latest_inputs['memory_response'] and self.latest_inputs['memory_response'].get('memories_json'):
            # This logic is already in memory_response_callback, which handles the update
            # We just need to consume the latest input here.
            self.latest_inputs['memory_response'] = None # Consume after use

        # Process Prediction State for anticipated changes
        if self.latest_inputs['prediction_state'] and \
           self.latest_inputs['prediction_state'].get('confidence', 0.0) > 0.5:
            # This logic is already in prediction_state_callback, which handles the update
            # We just need to consume the latest input here.
            self.latest_inputs['prediction_state'] = None # Consume after use

        # Process Cognitive Directive for overrides/queries
        if self.latest_inputs['cognitive_directive']:
            directive = self.latest_inputs['cognitive_directive']
            # If directive is expired, clear it
            if (current_time - directive['start_time']) > directive.get('duration_s', 0) and directive.get('duration_s', 0) != 0:
                rospy.loginfo(f"{self.node_name}: Cognitive directive for world model expired.")
                self.latest_inputs['cognitive_directive'] = None
            # If it's a query type, it impacts what's published, but doesn't change model state directly
            # Other directive types (e.g., UpdateWorldEntity) are handled in the callback itself.

        # --- Logical Consistency Check ---
        current_entities_for_check = list(self.tracked_entities_cache.values())
        self.latest_consistency_issues = self.consistency_checker.check_consistency(current_entities_for_check)
        
        if self.latest_consistency_issues:
            rospy.logwarn(f"{self.node_name}: Detected {len(self.latest_consistency_issues)} world model inconsistencies!")
            max_severity = 0.0
            for issue in self.latest_consistency_issues:
                max_severity = max(max_severity, issue['severity'])
                rospy.logwarn(f" - Issue: {issue['description']} (Severity: {issue['severity']:.2f})")
                
                # Reduce confidence of involved entities if consistency issues are found
                for entity_id in issue['involved_entities']:
                    if entity_id in self.tracked_entities_cache:
                        old_confidence = self.tracked_entities_cache[entity_id]['confidence']
                        new_confidence = max(0.1, old_confidence * (1.0 - issue['severity'] * 0.5)) # Reduce by severity
                        self.tracked_entities_cache[entity_id]['confidence'] = new_confidence
                        self._save_entity_to_db(self.tracked_entities_cache[entity_id], is_new=False) # Update DB
                        rospy.logwarn(f" Reduced confidence for '{entity_id}' to {new_confidence:.2f} due to inconsistency.")

            # If severity is high enough, issue a directive for self-correction
            if max_severity >= self.consistency_issue_trigger_threshold:
                self._issue_cognitive_directive_to_node(
                    directive_type='WorldModelInconsistencyDetected',
                    target_node='/self_correction_node',
                    reason=f"Logical inconsistencies detected in world model (Max Severity: {max_severity:.2f}).",
                    payload_data={"inconsistencies": self.latest_consistency_issues, "max_severity": max_severity}
                )
        else:
            rospy.logdebug(f"{self.node_name}: World model is logically consistent.")
            self.latest_consistency_issues = [] # Ensure it's empty if no issues

        # Final step: Publish the updated world model state
        self.publish_world_model_state(
            timestamp,
            list(self.tracked_entities_cache.values()), # All known entities
            self._get_all_environmental_properties(), # All known environmental properties
            json.dumps(self.latest_consistency_issues) # Publish consistency issues
        )

        # Clear narrative after use (as it's often a one-shot observation of an inconsistency)
        self.latest_inputs['internal_narrative'] = None


    def _decay_entity_confidence_and_learn(self):
        """
        Decays the confidence of entities that haven't been recently observed,
        and triggers adaptive learning for their decay rates based on performance feedback.
        """
        current_time = rospy.get_time()
        entities_to_remove = []

        for entity_id, data in list(self.tracked_entities_cache.items()): # Iterate over copy
            last_observed_ts = data.get('last_observed_timestamp', current_time)
            
            # Apply decay if not observed recently
            if (current_time - last_observed_ts) > self.update_interval:
                # Use the learned decay rate for this specific entity, fallback to initial if not learned
                decay_rate_for_entity = data.get('learned_decay_rate', self.initial_entity_decay_rate)
                
                # Decay amount is proportional to elapsed time and the decay rate
                decay_amount = decay_rate_for_entity * ((current_time - last_observed_ts) / self.update_interval)
                
                data['confidence'] = max(0.0, data['confidence'] - decay_amount)
                
                # Record the feedback for learning
                # (observed_correctly, time_since_last_observation_when_feedback_received)
                # For decay, 'observed_correctly' is implicitly False if it's decaying
                data['decay_feedback_history'].append((False, current_time - last_observed_ts))

                if data['confidence'] == 0.0:
                    entities_to_remove.append(entity_id)
                else:
                    self._save_entity_to_db(data, is_new=False) # Update confidence in DB
                    rospy.logdebug(f"{self.node_name}: Entity '{entity_id}' confidence decayed to {data['confidence']:.2f}.")

            # Trim history to window size
            while len(data['decay_feedback_history']) > self.decay_feedback_window_size:
                data['decay_feedback_history'].popleft()
            
            # Trigger adaptive learning if enough feedback has accumulated or on a schedule
            if len(data['decay_feedback_history']) == self.decay_feedback_window_size:
                self._learn_decay_rate_for_entity(entity_id, data['decay_feedback_history'])
                data['decay_feedback_history'].clear() # Clear after learning

        for entity_id in entities_to_remove:
            self._delete_entity_from_db(entity_id)
            del self.tracked_entities_cache[entity_id]
            rospy.logdebug(f"{self.node_name}: Removed entity '{entity_id}' due to zero confidence.")


    def _learn_decay_rate_for_entity(self, entity_id, feedback_history):
        """
        NEW: Adapts the `learned_decay_rate` for a specific entity based on its observation history.
        This simulates "experience replay" for world model stability.
        `feedback_history` contains (was_observed_correctly: bool, time_since_last_observation: float) tuples.
        """
        entity = self.tracked_entities_cache.get(entity_id)
        if not entity:
            return

        current_learned_decay_rate = entity.get('learned_decay_rate', self.initial_entity_decay_rate)
        
        # Analyze feedback:
        # If the entity was observed correctly after a long period of not being observed,
        # it suggests the decay rate was too high (it disappeared too quickly).
        # If it was often *not* observed, and then disappeared/was wrong, suggests decay rate was appropriate or too low.

        total_observations = sum(1 for obs, _ in feedback_history if obs)
        total_non_observations = sum(1 for obs, _ in feedback_history if not obs)
        
        # Simple heuristic for learning:
        # If recent history has more successful re-observations (implying previous decay was too fast),
        # decrease the decay rate.
        # If recent history has many non-observations (leading to disappearance, suggesting decay is appropriate or too slow),
        # slightly increase or maintain the decay rate.

        if total_observations > total_non_observations / 2: # More observations than non-observations recently
            # This entity is more persistent or predictable than initially assumed, reduce decay.
            adjustment = -self.decay_learning_rate * (total_observations / self.decay_feedback_window_size)
            rospy.logdebug(f"{self.node_name}: Entity '{entity_id}' seems more persistent. Decreasing decay rate.")
        elif total_non_observations > total_observations * 2: # Significantly more non-observations
            # This entity is less persistent, increase decay rate slightly.
            adjustment = self.decay_learning_rate * 0.5 * (total_non_observations / self.decay_feedback_window_size)
            rospy.logdebug(f"{self.node_name}: Entity '{entity_id}' seems less persistent. Increasing decay rate.")
        else:
            adjustment = 0.0 # No strong signal for adjustment

        new_learned_decay_rate = current_learned_decay_rate + adjustment
        
        # Clamp the learned decay rate within bounds
        new_learned_decay_rate = max(self.min_learned_decay_rate, min(self.max_learned_decay_rate, new_learned_decay_rate))

        if new_learned_decay_rate != current_learned_decay_rate:
            entity['learned_decay_rate'] = new_learned_decay_rate
            self._save_entity_to_db(entity, is_new=False) # Persist the learned rate
            rospy.loginfo(f"{self.node_name}: Learned! Decay rate for '{entity_id}' adjusted from {current_learned_decay_rate:.4f} to {new_learned_decay_rate:.4f}.")
            # A more advanced system would use performance report feedback here too.
            # If the overall system performance (e.g., navigation accuracy) is low
            # due to "disappearing" entities, it would suggest decay rates are too high.
            # (Currently, performance report only updates latest_inputs and is not explicitly used here)

    def _update_entity(self, entity_id, entity_type, entity_name, properties, confidence, from_directive=False, associated_memory_id=None, was_observed=False):
        """
        Adds a new entity or updates an existing one in the world model and cache.
        `from_directive` indicates if this update comes from a CognitiveDirective.
        `was_observed` indicates if this update is a direct sensory observation (for learning).
        """
        current_time = rospy.get_time()
        is_new = entity_id not in self.tracked_entities_cache
        existing_entity = self.tracked_entities_cache.get(entity_id, {})

        # Merge properties: new properties override old ones, existing ones are kept
        updated_properties = existing_entity.get('properties', {})
        updated_properties.update(properties)

        # Determine new confidence
        if from_directive:
            new_confidence = max(existing_entity.get('confidence', 0.0), confidence)
        elif is_new:
            new_confidence = confidence
        else:
            # If not new, average with existing confidence or take higher
            new_confidence = (existing_entity.get('confidence', 0.0) + confidence) / 2.0
            # Add some small noise if needed, but avoid excessive randomness for model stability
            new_confidence = max(0.0, min(1.0, new_confidence + random.uniform(-0.02, 0.02)))

        # Update associated memories (ensure uniqueness)
        existing_memories = set(existing_entity.get('associated_memories', []))
        if associated_memory_id:
            existing_memories.add(associated_memory_id)
        
        # Initialize or update decay feedback history
        decay_feedback_history = existing_entity.get('decay_feedback_history', deque(maxlen=self.decay_feedback_window_size))
        if was_observed:
            # If entity was re-observed, record that feedback
            decay_feedback_history.append((True, current_time - existing_entity.get('last_observed_timestamp', current_time)))
        # Clear old history if it exceeds maxlen (deque handles this automatically)
        while len(decay_feedback_history) > self.decay_feedback_window_size:
            decay_feedback_history.popleft() # Remove oldest if necessary

        entity_data = {
            'id': entity_id,
            'type': entity_type,
            'name': entity_name,
            'properties': updated_properties,
            'confidence': new_confidence,
            'last_observed_timestamp': current_time,
            'semantic_embedding': existing_entity.get('semantic_embedding'), # Keep existing if not provided
            'associated_memories': list(existing_memories),
            'learned_decay_rate': existing_entity.get('learned_decay_rate', self.initial_entity_decay_rate), # Keep learned rate
            'decay_feedback_history': decay_feedback_history # Store updated history
        }

        self.tracked_entities_cache[entity_id] = entity_data
        self._save_entity_to_db(entity_data, is_new)


    def _save_entity_to_db(self, entity_data, is_new):
        """Saves or updates an entity in the SQLite database."""
        try:
            properties_json = json.dumps(entity_data['properties'])
            associated_memories_json = json.dumps(entity_data['associated_memories'])
            decay_feedback_history_json = json.dumps(list(entity_data['decay_feedback_history'])) # Convert deque to list for JSON

            if is_new:
                self.cursor.execute('''
                    INSERT INTO world_entities (id, type, name, properties, confidence, last_observed_timestamp, semantic_embedding, associated_memories, learned_decay_rate, decay_feedback_history)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (entity_data['id'], entity_data['type'], entity_data['name'], properties_json, entity_data['confidence'],
                      entity_data['last_observed_timestamp'], entity_data['semantic_embedding'], associated_memories_json,
                      entity_data['learned_decay_rate'], decay_feedback_history_json))
            else:
                self.cursor.execute('''
                    UPDATE world_entities
                    SET type = ?, name = ?, properties = ?, confidence = ?, last_observed_timestamp = ?, semantic_embedding = ?, associated_memories = ?, learned_decay_rate = ?, decay_feedback_history = ?
                    WHERE id = ?
                ''', (entity_data['type'], entity_data['name'], properties_json, entity_data['confidence'],
                      entity_data['last_observed_timestamp'], entity_data['semantic_embedding'], associated_memories_json,
                      entity_data['learned_decay_rate'], decay_feedback_history_json, entity_data['id']))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: {'Added' if is_new else 'Updated'} entity '{entity_data['id']}' in DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save entity '{entity_data['id']}' to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _save_entity_to_db: {e}")

    def _delete_entity_from_db(self, entity_id):
        """Deletes an entity from the SQLite database."""
        try:
            self.cursor.execute('DELETE FROM world_entities WHERE id = ?', (entity_id,))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Deleted entity '{entity_id}' from DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to delete entity '{entity_id}' from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _delete_entity_from_db: {e}")

    def _update_environmental_property(self, property_name, value, unit, confidence, is_prediction=False):
        """Adds or updates an environmental property."""
        current_time = rospy.get_time()
        try:
            self.cursor.execute('INSERT OR REPLACE INTO environmental_properties (property_name, value, unit, confidence, last_updated_timestamp) VALUES (?, ?, ?, ?, ?)',
                                (property_name, value, unit, confidence, current_time))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Updated environmental property '{property_name}'.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update environmental property '{property_name}': {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _update_environmental_property: {e}")

    def _get_environmental_property(self, property_name):
        """Retrieves an environmental property from the database."""
        try:
            self.cursor.execute('SELECT property_name, value, unit, confidence, last_updated_timestamp FROM environmental_properties WHERE property_name = ?', (property_name,))
            row = self.cursor.fetchone()
            if row:
                return {'property_name': row[0], 'value': row[1], 'unit': row[2], 'confidence': row[3], 'last_updated_timestamp': row[4]}
            return None
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to retrieve environmental property '{property_name}': {e}")
            return None
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _get_environmental_property: {e}")
            return None

    def _get_all_environmental_properties(self):
        """Retrieves all environmental properties."""
        try:
            self.cursor.execute('SELECT property_name, value, unit, confidence, last_updated_timestamp FROM environmental_properties')
            rows = self.cursor.fetchall()
            properties = []
            for row in rows:
                properties.append({'property_name': row[0], 'value': row[1], 'unit': row[2], 'confidence': row[3], 'last_updated_timestamp': row[4]})
            return properties
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to retrieve all environmental properties: {e}")
            return []
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _get_all_environmental_properties: {e}")
            return []

    # --- NEW: Proactive Reasoning Logic ---
    def proactive_reasoning_check(self, event):
        """
        Periodically checks for conditions that warrant proactive queries to other nodes,
        such as low confidence entities, inconsistencies, or high novelty sensory input.
        """
        current_time = rospy.get_time()
        
        # Only perform proactive checks periodically
        if (current_time - self.last_proactive_query_time) < self.proactive_query_interval:
            return

        self.last_proactive_query_time = current_time
        rospy.loginfo(f"{self.node_name}: Performing proactive world model checks...")

        # 1. Proactive Query for Low Confidence Entities
        low_confidence_entities = []
        for entity_id, data in self.tracked_entities_cache.items():
            if data['confidence'] < self.low_confidence_query_threshold:
                low_confidence_entities.append(entity_id)
        
        if low_confidence_entities:
            # Prioritize querying for entities in current attention focus if any
            attention_focus = self.latest_inputs['attention_state'].get('focus_target') if self.latest_inputs['attention_state'] else None
            if attention_focus and attention_focus in low_confidence_entities:
                target_entity_for_query = attention_focus
            else:
                target_entity_for_query = random.choice(low_confidence_entities)
            
            # Issue a directive to SensoryQualiaNode to actively seek info, or MemoryNode for context
            rospy.loginfo(f"{self.node_name}: Proactively querying for low confidence entity: '{target_entity_for_query}'.")
            self._issue_cognitive_directive_to_node(
                directive_type='RequestDetailedSensorData',
                target_node='/sensory_qualia_node',
                reason=f"World model needs more data for low-confidence entity '{target_entity_for_query}'.",
                payload_data={"target_object_id": target_entity_for_query, "data_level": "high_fidelity"}
            )
            # Also query Memory Node for historical context
            self._issue_memory_request(
                request_id=f"wm_proactive_lowconf_mem_{target_entity_for_query}",
                query_text=f"historical information and past observations about entity '{target_entity_for_query}'",
                num_results=3,
                filter_tags=["entity_history", "observations"]
            )


        # 2. Proactive Query for Consistency Issues
        if self.latest_consistency_issues:
            high_severity_issues = [issue for issue in self.latest_consistency_issues if issue['severity'] >= self.inconsistency_query_threshold]
            if high_severity_issues:
                # Pick one high severity issue to focus on proactively
                issue_to_query = random.choice(high_severity_issues)
                involved_entities = issue_to_query.get('involved_entities', [])
                
                rospy.logwarn(f"{self.node_name}: Proactively querying for consistency issue: '{issue_to_query.get('description', '')[:50]}'.")
                
                # Request clarifying sensory data for involved entities
                for entity_id in involved_entities:
                    self._issue_cognitive_directive_to_node(
                        directive_type='RequestClarifyingSensorData',
                        target_node='/sensory_qualia_node',
                        reason=f"World model consistency issue requires more data for entity '{entity_id}'.",
                        payload_data={"target_object_id": entity_id, "data_level": "very_high_fidelity", "issue_type": issue_to_query.get('description')}
                    )
                # Request memory for conflicting information or rules
                self._issue_memory_request(
                    request_id=f"wm_proactive_incons_mem_{str(rospy.get_time())}",
                    query_text=f"conflicting data or rules related to world model inconsistency: {issue_to_query.get('description')}",
                    num_results=5,
                    filter_tags=["logic_rules", "contradictions"]
                )

        # 3. Proactive Exploration for Novel Sensory Qualia
        if self.latest_inputs['sensory_qualia'] and \
           self.latest_inputs['sensory_qualia'].get('salience_score', 0.0) >= self.novelty_query_threshold and \
           not self.latest_inputs['sensory_qualia'].get('object_id'): # Only if not already identified as a known object
            
            novel_qualia_type = self.latest_inputs['sensory_qualia'].get('qualia_type', 'unknown')
            rospy.loginfo(f"{self.node_name}: Proactively exploring novel sensory input: '{novel_qualia_type}'.")
            
            # Issue a directive to the Attention Node to focus on this novel input for deeper processing
            self._issue_cognitive_directive_to_node(
                directive_type='FocusAttention',
                target_node='/attention_node',
                reason=f"Novel sensory qualia '{novel_qualia_type}' detected; requires deeper investigation.",
                payload_data={"focus_target": f"novel_sensory_{novel_qualia_type}", "intensity": 0.8, "duration_s": 5}
            )
            # Also request Memory Node to search for similar past experiences
            self._issue_memory_request(
                request_id=f"wm_proactive_novel_mem_{str(rospy.get_time())}",
                query_text=f"past experiences or knowledge related to '{novel_qualia_type}'",
                num_results=2,
                filter_tags=["sensory_records", "unexpected_events"]
            )
            self.latest_inputs['sensory_qualia'] = None # Consume after triggering proactive query

    # --- Logical Consistency Checker (Inner Class or Helper) ---
    class _LogicalConsistencyChecker:
        def __init__(self):
            # Define rules for consistency checks. These could be loaded from config.
            self.rules = {
                'spatial_overlap': self._check_spatial_overlap,
                'temporal_consistency': self._check_temporal_consistency,
                'identity_uniqueness': self._check_identity_uniqueness,
                'state_exclusivity': self._check_state_exclusivity
            }

        def check_consistency(self, all_entities):
            """Runs all consistency checks and returns a list of detected issues."""
            detected_issues = []
            entities_by_id = {entity['id']: entity for entity in all_entities}

            for rule_name, check_func in self.rules.items():
                issues = check_func(entities_by_id, all_entities)
                if issues:
                    detected_issues.extend(issues)
            return detected_issues

        def _check_spatial_overlap(self, entities_by_id, all_entities):
            """Simulates checking for objects occupying the same physical space."""
            detected_issues = []
            solid_objects = [e for e in all_entities if e.get('type') == 'object' and 'position' in e.get('properties', {})]

            # Simple N^2 check, for more complex scenarios, spatial partitioning structures (quadtrees/octrees) would be used.
            for i, entity1 in enumerate(solid_objects):
                if 'position' not in entity1.get('properties', {}):
                    continue
                pos1 = np.array(entity1['properties']['position'])
                for j, entity2 in enumerate(solid_objects):
                    if i >= j: # Avoid checking self and duplicate pairs
                        continue
                    if 'position' not in entity2.get('properties', {}):
                        continue
                    pos2 = np.array(entity2['properties']['position'])
                    distance = np.linalg.norm(pos1 - pos2)
                    
                    # Assume a small epsilon for "same space" for simulation
                    if distance < 0.1: # Objects are within 0.1 unit of each other
                        issue = {
                            'issue_type': 'spatial_overlap',
                            'description': f"Spatial overlap detected between '{entity1['name']}' ({entity1['id']}) and '{entity2['name']}' ({entity2['id']}).",
                            'involved_entities': [entity1['id'], entity2['id']],
                            'severity': 0.8,
                            'suggested_resolution': f"Verify sensory data for {entity1['id']} and {entity2['id']}. Prioritize more recent or higher-confidence observations."
                        }
                        detected_issues.append(issue)
            return detected_issues

        def _check_temporal_consistency(self, entities_by_id, all_entities):
            """Simulates checking if an entity's existence timeline is consistent."""
            detected_issues = []
            current_time = rospy.get_time()
            for entity_id, entity_data in entities_by_id.items():
                last_observed_ts = float(entity_data.get('last_observed_timestamp', 0.0))
                confidence = entity_data.get('confidence', 1.0)
                
                # If an entity hasn't been observed for a very long time but still has high confidence
                if (current_time - last_observed_ts) > 120 and confidence > 0.8: # Not observed for 120s, but high confidence
                    issue = {
                        'issue_type': 'temporal_inconsistency',
                        'description': f"Temporal inconsistency: Entity '{entity_id}' ('{entity_data['name']}') has not been observed recently (last: {(current_time - last_observed_ts):.1f}s ago) but confidence remains high ({confidence:.2f}).",
                        'involved_entities': [entity_id],
                        'severity': 0.6,
                        'suggested_resolution': f"Re-scan for '{entity_id}' or decay its confidence more aggressively."
                    }
                    detected_issues.append(issue)
            return detected_issues

        def _check_identity_uniqueness(self, entities_by_id, all_entities):
            """Simulates checking if two distinct IDs refer to the same conceptual entity."""
            detected_issues = []
            # This would typically involve semantic embeddings or feature matching.
            # Simplified: Check for two entities with different IDs but very similar names/properties,
            # indicating they might be duplicates of the same object.
            
            entities_by_name = {}
            for entity in all_entities:
                name = entity.get('name', 'unknown').lower()
                if name not in entities_by_name:
                    entities_by_name[name] = []
                entities_by_name[name].append(entity)

            for name, entities_list in entities_by_name.items():
                if len(entities_list) > 1:
                    # If multiple entities have the same name, check if they are likely duplicates
                    # For simulation, just assume if same name and type, and different IDs, it's a potential duplicate
                    if len(entities_list) > 1 and all(e['type'] == entities_list[0]['type'] for e in entities_list):
                        issue = {
                            'issue_type': 'identity_duplication',
                            'description': f"Potential identity duplication: Multiple entities ('{name}') with different IDs ({[e['id'] for e in entities_list]}) are perceived, suggesting they might be the same underlying entity.",
                            'involved_entities': [e['id'] for e in entities_list],
                            'severity': 0.7,
                            'suggested_resolution': f"Attempt to merge duplicate entities '{name}' by correlating sensory inputs and memory, or verify if they are indeed distinct."
                        }
                        detected_issues.append(issue)
            return detected_issues

        def _check_state_exclusivity(self, entities_by_id, all_entities):
            """Simulates checking for mutually exclusive states."""
            detected_issues = []
            mutually_exclusive_states = {
                'door': [('open', 'closed')],
                'light_switch': [('on', 'off')],
                'robot_arm': [('moving', 'stationary')] # Hypothetical for robot's own body model
            }
            for entity in all_entities:
                entity_type = entity.get('type')
                properties = entity.get('properties', {})
                if entity_type in mutually_exclusive_states:
                    for state1_prop, state2_prop in mutually_exclusive_states[entity_type]:
                        if properties.get(state1_prop) and properties.get(state2_prop):
                            issue = {
                                'issue_type': 'state_exclusivity_violation',
                                'description': f"State exclusivity violation: Entity '{entity['id']}' ('{entity['name']}') is simultaneously reported as '{state1_prop}' and '{state2_prop}'.",
                                'involved_entities': [entity['id']],
                                'severity': 0.7,
                                'suggested_resolution': f"Prioritize the most recent or highest-confidence state, or request clarifying sensory input for '{entity['id']}'."
                            }
                            detected_issues.append(issue)
            return detected_issues


    # --- Database and Publishing Functions ---
    def publish_world_model_state(self, timestamp, known_entities, environmental_properties, consistency_issues_json):
        """Publishes the current state of the world model on the '/world_model_state' topic."""
        try:
            # Prepare entities for JSON serialization
            entities_for_json = []
            for entity in known_entities:
                entity_copy = entity.copy() # Avoid modifying original dict in cache
                # Convert deque to list for JSON serialization
                entity_copy['decay_feedback_history'] = list(entity_copy['decay_feedback_history'])
                entities_for_json.append(entity_copy)

            # Ensure all JSON strings are properly formatted for the message
            known_entities_json_str = json.dumps(entities_for_json)
            environmental_properties_json_str = json.dumps(environmental_properties)
            
            if isinstance(WorldModelState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'known_entities': entities_for_json, # Send as list of dicts for fallback
                    'environmental_properties': environmental_properties, # Send as list of dicts for fallback
                    'consistency_issues': json.loads(consistency_issues_json) # Send as list of dicts for fallback
                }
                self.pub_world_model_state.publish(json.dumps(state_data))
            else:
                world_model_msg = WorldModelState()
                world_model_msg.timestamp = timestamp
                world_model_msg.known_entities_json = known_entities_json_str
                world_model_msg.environmental_properties_json = environmental_properties_json_str
                world_model_msg.consistency_issues_json = consistency_issues_json
                self.pub_world_model_state.publish(world_model_msg)

            rospy.logdebug(f"{self.node_name}: Published world model state with {len(known_entities)} entities.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish world model state: {e}")

    def _issue_memory_request(self, request_id, query_text, num_results=5, filter_tags=None):
        """
        Helper to issue a MemoryRequest to the Memory Node for relevant world model knowledge.
        """
        timestamp = str(rospy.get_time())
        try:
            request_data = {
                'timestamp': timestamp,
                'request_id': request_id,
                'request_type': 'retrieve',
                'search_query': query_text,
                'user_id': 'system_world_model', # System-initiated memory request
                'filter_tags': filter_tags if filter_tags else ["world_facts", "object_properties", "events"],
                'num_results': num_results
            }
            # Assuming MemoryRequest is always String if custom message is not found
            self.pub_memory_request.publish(json.dumps(request_data))
            rospy.logdebug(f"{self.node_name}: Issued MemoryRequest '{request_id}' for world model context.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue MemoryRequest: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node (e.g., Self-Correction if model inconsistency).
        This also handles SensoryFocus directives for proactive scanning.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'curious' if 'proactive' in reason else 'concerned', # Reflect nature
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "issue_or_focus": payload_data.get('target_object_id', directive_type)})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data)) # Or pub_sensory_focus_directive for specific use

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' based on world model.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from World Model: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = WorldModelNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

5. Updated Memory Node with Adaptive Salience Learning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # For simulating nuances in creative output or salience if LLM not used
from collections import deque
import numpy as np # For FAISS embeddings, if FAISS is available

# --- Optional: FAISS for vector similarity search ---
FAISS_AVAILABLE = False
try:
    import faiss
    FAISS_AVAILABLE = True
    rospy.loginfo("FAISS is available. Enabling vector similarity search for memory.")
except ImportError:
    rospy.logwarn("FAISS not found. Vector similarity search will be disabled in Memory Node. Using keyword search only.")

# --- Optional: Sentence Transformers for embeddings ---
SENTENCE_TRANSFORMERS_AVAILABLE = False
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
    rospy.loginfo("Sentence Transformers available. Enabling semantic embedding for memory.")
except ImportError:
    rospy.logwarn("Sentence Transformers not found. Semantic embedding for memory will be disabled. Using keyword search only.")

from std_msgs.msg import String
from textblob import TextBlob # For sentiment analysis

# Updated imports for custom messages:
try:
    from sentience.msg import (
        MemoryRequest, MemoryResponse, MemoryNodeState,
        EmotionState,           # Input: Robot's emotional state (influences salience)
        AttentionState,         # Input: Robot's attention focus (influences salience)
        MotivationState,        # Input: Robot's dominant goal (influences salience)
        CognitiveDirective,     # Input: Directives for memory operations
        PerformanceReport       # NEW: Input: For potential impact feedback
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Memory Node.")
    MemoryRequest = String
    MemoryResponse = String
    MemoryNodeState = String
    EmotionState = String
    AttentionState = String
    MotivationState = String
    CognitiveDirective = String
    PerformanceReport = String # NEW
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class MemoryNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('memory_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for storing interactions.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/interactions.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Period (in seconds) after which old low-salience memories are considered for cleanup.
        self.retention_period = rospy.get_param('~retention_period', 604800)  # 7 days in seconds
        
        # Maximum number of memories to retrieve for a single request.
        self.max_retrieval_results = rospy.get_param('~max_retrieval_results', 10)
        
        # Interval (in seconds) for periodic memory consolidation (cleanup, re-indexing).
        self.consolidation_interval = rospy.get_param('~consolidation_interval', 60) # Every 60 seconds
        
        # Simulated time it takes for the LLM to perform consolidation/summarization.
        self.consolidation_duration_s = rospy.get_param('~consolidation_duration_s', 5) # 5 seconds

        # NEW: Adaptive Learning Parameters for Salience
        self.salience_learning_rate = rospy.get_param('~salience_learning_rate', 0.05) # How much salience changes on recall
        self.recency_boost_factor = rospy.get_param('~recency_boost_factor', 0.1) # Boost for recently recalled memories
        self.min_effective_salience = rospy.get_param('~min_effective_salience', 0.01) # Minimum effective salience for a memory to persist
        self.max_effective_salience = rospy.get_param('~max_effective_salience', 1.0) # Max effective salience

        # Threshold for salience of a memory to be considered 'salient' for MemoryNodeState.
        self.salient_memory_threshold = rospy.get_param('~salient_memory_threshold', 0.6)


        # --- Initialize Embedding Model (if available) ---
        self.embedding_model = None
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            try:
                # Using a small, fast model for simulation purposes
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2') 
                rospy.loginfo(f"{self.node_name}: Sentence Transformer model loaded.")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Failed to load Sentence Transformer model: {e}")
                SENTENCE_TRANSFORMERS_AVAILABLE = False
        
        # --- Initialize FAISS Index (if available) ---
        self.faiss_index = None
        self.embedding_dimension = 384 # Default for all-MiniLM-L6-v2
        if FAISS_AVAILABLE and SENTENCE_TRANSFORMERS_AVAILABLE:
            try:
                # Attempt to load existing FAISS index
                faiss_index_path = self.db_path + ".faiss"
                if os.path.exists(faiss_index_path):
                    self.faiss_index = faiss.read_index(faiss_index_path)
                    rospy.loginfo(f"{self.node_name}: Loaded existing FAISS index from {faiss_index_path}.")
                else:
                    # Create a new FAISS index if it doesn't exist
                    # Using IndexFlatL2 for L2 distance (Euclidean)
                    self.faiss_index = faiss.IndexFlatL2(self.embedding_dimension)
                    rospy.loginfo(f"{self.node_name}: Created new FAISS index.")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Failed to initialize FAISS index: {e}")
                self.faiss_index = None
                FAISS_AVAILABLE = False

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'memories' table if it doesn't exist.
        # NEW: Added 'recall_frequency', 'last_recall_time', 'effective_salience'
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS memories (
                memory_id TEXT PRIMARY KEY,
                timestamp TEXT,                 -- When the memory was created
                type TEXT,                      -- e.g., 'episodic', 'semantic', 'procedural'
                text TEXT,                      -- The content of the memory
                tags TEXT,                      -- Comma-separated keywords or categories
                sentiment REAL,                 -- Sentiment score of the memory (from 0.0 to 1.0)
                initial_salience REAL,          -- Salience when first created (0.0 to 1.0)
                embedding BLOB,                 -- Vector embedding of the memory content
                metadata TEXT,                  -- JSON string of additional context (e.g., user_id, source_node)
                recall_frequency INTEGER DEFAULT 0, -- NEW: How many times this memory has been recalled
                last_recall_time REAL DEFAULT 0.0,  -- NEW: Timestamp of the last recall (0.0 means never recalled)
                effective_salience REAL DEFAULT 0.0 -- NEW: Dynamically learned salience used for retrieval/decay
            )
        ''')
        # Create indices for efficient querying.
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_memory_timestamp ON memories (timestamp)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_memory_type ON memories (type)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_effective_salience ON memories (effective_salience)') # NEW
        self.conn.commit() # Commit changes to the database

        # Populate FAISS index from existing memories on startup if FAISS is available
        self._populate_faiss_from_db()


        # --- Internal State ---
        self.latest_emotion_state = None
        self.latest_attention_state = None
        self.latest_motivation_state = None
        self.latest_performance_report = None # NEW
        self.active_cognitive_directive = None # For direct memory operations

        self.current_consolidation_task = None # Stores details of an ongoing task
        self.task_start_time = 0.0 # NEW: Start time of the current task
        self.task_end_time = 0.0 # NEW: Predicted end time for non-blocking simulation


        # --- Publishers ---
        # Publishes responses to memory requests.
        self.pub_memory_response = rospy.Publisher('/memory_response', MemoryResponse, queue_size=10)
        # Publishes the overall state of the Memory Node (e.g., total memories, active queries).
        self.pub_memory_node_state = rospy.Publisher('/memory_node_state', MemoryNodeState, queue_size=10)
        # Publishes CognitiveDirectives (e.g., to request more sensory data if memory is incomplete).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        rospy.Subscriber('/memory_request', String, self.memory_request_callback) # Expecting stringified JSON
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback) # NEW

        # --- Timer for periodic memory cycle (consolidation, state publication) ---
        rospy.Timer(rospy.Duration(self.consolidation_interval), self.run_memory_cycle)

        rospy.loginfo(f"{self.node_name}: Robot remembers.")

    # --- FAISS Management ---
    def _populate_faiss_from_db(self):
        """Populates the FAISS index with embeddings from existing memories in the database."""
        if not FAISS_AVAILABLE or not self.faiss_index:
            return

        try:
            self.cursor.execute('SELECT memory_id, embedding FROM memories WHERE embedding IS NOT NULL')
            rows = self.cursor.fetchall()
            if rows:
                ids = []
                embeddings = []
                for mem_id, embedding_blob in rows:
                    ids.append(int(mem_id.split('_')[-1])) # Assuming ID is last part after underscore
                    embeddings.append(np.frombuffer(embedding_blob, dtype=np.float32))
                
                if embeddings:
                    embeddings_array = np.array(embeddings).astype('float32')
                    # If index is already populated, no need to add again unless rebuilding
                    if self.faiss_index.ntotal == 0:
                        self.faiss_index.add(embeddings_array)
                        rospy.loginfo(f"{self.node_name}: Added {len(embeddings)} embeddings to FAISS index on startup.")
                    else:
                        rospy.loginfo(f"{self.node_name}: FAISS index already populated with {self.faiss_index.ntotal} vectors.")
            self.conn.commit()
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to populate FAISS from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during FAISS population: {e}")

    def _save_faiss_index(self):
        """Saves the FAISS index to disk."""
        if FAISS_AVAILABLE and self.faiss_index:
            try:
                faiss.write_index(self.faiss_index, self.db_path + ".faiss")
                rospy.logdebug(f"{self.node_name}: FAISS index saved to disk.")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Failed to save FAISS index: {e}")

    def _get_embedding(self, text):
        """Generates a semantic embedding for the given text using SentenceTransformer."""
        if SENTENCE_TRANSFORMERS_AVAILABLE and self.embedding_model:
            try:
                # Ensure input is string
                if not isinstance(text, str):
                    text = str(text)
                embedding = self.embedding_model.encode(text, convert_to_tensor=False)
                return embedding.tobytes()
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Failed to generate embedding for text: {e}")
                return None
        return None

    # --- Callbacks for input data ---
    def memory_request_callback(self, msg):
        """
        Callback for MemoryRequest. Triggers memory storage or retrieval.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'request_type': ('retrieve', 'request_type'), 'search_query': ('', 'search_query'),
            'user_id': ('system', 'user_id'), 'filter_tags': ('[]', 'filter_tags_json'),
            'num_results': (1, 'num_results'), 'memory_content_json': ('{}', 'memory_content_json'), # For 'store' type
            'metadata_json': ('{}', 'metadata_json') # For 'store' type
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Parse JSON fields that are expected to be lists/dicts
        if isinstance(data.get('filter_tags_json'), str):
            try: data['filter_tags'] = json.loads(data['filter_tags_json'])
            except json.JSONDecodeError: data['filter_tags'] = []
        if isinstance(data.get('memory_content_json'), str):
            try: data['memory_content'] = json.loads(data['memory_content_json'])
            except json.JSONDecodeError: data['memory_content'] = {}
        if isinstance(data.get('metadata_json'), str):
            try: data['metadata'] = json.loads(data['metadata_json'])
            except json.JSONDecodeError: data['metadata'] = {}

        request_type = data.get('request_type')
        if request_type == 'store':
            self._store_memory(
                data.get('memory_content', {}).get('type', 'episodic'),
                data.get('memory_content', {}).get('text', ''),
                data.get('memory_content', {}).get('tags', '').split(',') if data.get('memory_content', {}).get('tags') else [],
                data.get('memory_content', {}).get('sentiment', TextBlob(data.get('memory_content', {}).get('text', '')).sentiment.polarity if data.get('memory_content', {}).get('text') else 0.0),
                data.get('metadata', {}),
                data.get('user_id', 'system') # Pass user_id for salience calculation
            )
            self.publish_memory_response(
                data.get('request_id'),
                0, # Response success
                "Memory stored successfully."
            )
            rospy.loginfo(f"{self.node_name}: Stored new memory from request.")
        elif request_type == 'retrieve':
            memories = self._retrieve_memories(
                data.get('search_query', ''),
                data.get('filter_tags', []),
                data.get('num_results', self.max_retrieval_results),
                data.get('user_id', 'system'), # Pass user_id for salience calculation
                data.get('request_id') # Pass request ID for potential feedback
            )
            # Serialize memories for response
            memories_for_response = [
                {
                    'memory_id': mem['memory_id'],
                    'timestamp': mem['timestamp'],
                    'type': mem['type'],
                    'text': mem['text'],
                    'tags': mem['tags'],
                    'sentiment': mem['sentiment'],
                    'initial_salience': mem['initial_salience'],
                    'effective_salience': mem['effective_salience'], # NEW
                    'metadata': json.loads(mem['metadata']) if isinstance(mem['metadata'], str) else mem['metadata']
                } for mem in memories
            ]
            self.publish_memory_response(
                data.get('request_id'),
                0, # Response success
                "Memories retrieved.",
                json.dumps(memories_for_response)
            )
            rospy.loginfo(f"{self.node_name}: Retrieved {len(memories)} memories for request '{data.get('request_id')}'.")
        # Add other request types like 'delete', 'update', 'query_info' as needed

    def emotion_state_callback(self, msg):
        """Callback for EmotionState. Robot's emotional state influences memory salience."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_emotion_state.get('mood', 'N/A')}")

    def attention_state_callback(self, msg):
        """Callback for AttentionState. Current attention focus influences memory salience."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),
            'focus_target': ('none', 'focus_target'), 'priority_score': (0.0, 'priority_score')
        }
        self.latest_attention_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Attention State. Focus: {self.latest_attention_state.get('focus_target', 'N/A')}")

    def motivation_state_callback(self, msg):
        """Callback for MotivationState. Dominant goals influence memory salience."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        self.latest_motivation_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(self.latest_motivation_state.get('active_goals_json'), str):
            try:
                self.latest_motivation_state['active_goals'] = json.loads(self.latest_motivation_state['active_goals_json'])
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode active_goals_json from MotivationState.")
                self.latest_motivation_state['active_goals'] = []
        rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {self.latest_motivation_state.get('dominant_goal_id', 'N/A')}.")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can trigger memory operations directly,
        e.g., 'PurgeOldData', 'ReindexMemories', 'MemoryFeedback'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'PurgeOldData':
                    self._delete_old_memories()
                    rospy.loginfo(f"{self.node_name}: PurgeOldData directive executed.")
                elif directive_type == 'ReindexMemories' and FAISS_AVAILABLE:
                    rospy.loginfo(f"{self.node_name}: Reindexing memories as per directive.")
                    self._reindex_all_memories()
                elif directive_type == 'MemoryFeedback': # NEW: Feedback from other nodes on memory utility
                    memory_id = payload.get('memory_id')
                    feedback_type = payload.get('feedback_type', 'utility') # e.g., 'utility', 'relevance', 'error'
                    feedback_score = payload.get('score', 0.0) # e.g., 1.0 for very useful, -1.0 for error
                    self._update_memory_salience_from_feedback(memory_id, feedback_type, feedback_score)
                    rospy.loginfo(f"{self.node_name}: Received MemoryFeedback for '{memory_id}'.")

                # Set active_cognitive_directive for other types if they're long-running tasks
                # For example, if 'ReindexMemories' was a long task and needed to be non-blocking.
                # For now, these are blocking for simplicity, except consolidation.
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def performance_report_callback(self, msg): # NEW
        """Callback for PerformanceReport. For future use, could influence consolidation strategy."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('kpis_json'), str):
            try: data['kpis_json'] = json.loads(data['kpis_json'])
            except json.JSONDecodeError: data['kpis_json'] = {}
        self.latest_performance_report = data
        rospy.logdebug(f"{self.node_name}: Received Performance Report. Suboptimal: {data.get('suboptimal_flag', 'N/A')}")


    # --- Memory Storage and Retrieval ---
    def _store_memory(self, m_type, m_text, m_tags, m_sentiment, m_metadata, user_id='system'):
        """Stores a new memory in the database."""
        current_time = rospy.get_time()
        memory_id = f"{m_type}_{int(current_time)}_{random.randint(0, 9999)}"
        timestamp_str = str(current_time)
        
        # Calculate initial salience
        initial_salience = self._calculate_initial_salience(m_text, m_tags, m_sentiment, m_metadata, user_id)
        
        # Get embedding
        embedding = self._get_embedding(m_text)
        
        # Store in DB
        try:
            metadata_json = json.dumps(m_metadata)
            tags_str = ','.join(m_tags)
            
            self.cursor.execute('''
                INSERT INTO memories (memory_id, timestamp, type, text, tags, sentiment, initial_salience, embedding, metadata, recall_frequency, last_recall_time, effective_salience)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (memory_id, timestamp_str, m_type, m_text, tags_str, m_sentiment, initial_salience, 
                  embedding, metadata_json, 0, 0.0, initial_salience)) # Initial effective_salience is initial_salience
            self.conn.commit()
            
            # Add to FAISS index if available
            if FAISS_AVAILABLE and self.faiss_index and embedding is not None:
                self.faiss_index.add(np.array([np.frombuffer(embedding, dtype=np.float32)]))
                self._save_faiss_index() # Save index after adding
                rospy.logdebug(f"{self.node_name}: Added embedding for memory '{memory_id}' to FAISS.")

            rospy.loginfo(f"{self.node_name}: Memory '{memory_id}' stored. Initial Salience: {initial_salience:.2f}.")
            return memory_id
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to store memory: {e}")
            return None
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _store_memory: {e}")
            return None

    def _calculate_initial_salience(self, text, tags, sentiment, metadata, user_id):
        """
        Calculates an initial salience score for a new memory based on current robot state.
        This is primarily for initial seeding, effective_salience will adapt.
        """
        salience = 0.1 # Base salience

        # Sentiment impact
        salience += abs(sentiment) * 0.2 # Stronger sentiment = higher salience

        # Length/richness of text
        salience += min(0.3, len(text) / 200.0) # Longer text, higher salience (capped)

        # Keyword matching with active attention/goals
        if self.latest_attention_state and self.latest_attention_state.get('focus_target') in text:
            salience += self.latest_attention_state.get('priority_score', 0.0) * 0.3
        
        if self.latest_motivation_state and self.latest_motivation_state.get('dominant_goal_id') in text:
            salience += self.latest_motivation_state.get('overall_drive_level', 0.0) * 0.2

        # Directives related to memory
        if self.active_cognitive_directive and self.active_cognitive_directive.get('type') == 'StoreImportantMemory':
            salience += self.active_cognitive_directive.get('payload', {}).get('urgency', 0.5) * 0.4
            
        # If from a human user, potentially higher initial salience (social importance)
        if user_id != 'system':
            salience += 0.1

        return min(1.0, salience) # Clamp salience

    def _retrieve_memories(self, query, filter_tags, num_results, user_id='system', request_id=''):
        """
        Retrieves memories based on a search query, filters, and number of results.
        Prioritizes by `effective_salience` and relevance.
        NEW: Updates `recall_frequency` and `effective_salience` on successful retrieval.
        """
        retrieved_memories = []
        embedding_query = self._get_embedding(query)
        current_time = rospy.get_time()

        # Step 1: Semantic Search (if FAISS available)
        if FAISS_AVAILABLE and self.faiss_index and embedding_query is not None:
            try:
                D, I = self.faiss_index.search(np.array([np.frombuffer(embedding_query, dtype=np.float32)]), num_results * 2) # Get more results than needed
                candidate_ids = [str(i) for i in I[0]] # Convert FAISS internal IDs to strings
                
                # Fetch full memory details from DB for these IDs
                placeholders = ','.join('?' for _ in candidate_ids)
                query_sql = f"SELECT memory_id, timestamp, type, text, tags, sentiment, initial_salience, embedding, metadata, recall_frequency, last_recall_time, effective_salience FROM memories WHERE memory_id IN ({placeholders})"
                self.cursor.execute(query_sql, candidate_ids)
                rows = self.cursor.fetchall()
                
                # Convert rows to dicts for easier processing
                semantic_results = []
                for row in rows:
                    mem_dict = {
                        'memory_id': row[0], 'timestamp': row[1], 'type': row[2], 'text': row[3],
                        'tags': row[4], 'sentiment': row[5], 'initial_salience': row[6],
                        'embedding': row[7], 'metadata': row[8],
                        'recall_frequency': row[9], 'last_recall_time': row[10], 'effective_salience': row[11]
                    }
                    semantic_results.append(mem_dict)
                rospy.logdebug(f"{self.node_name}: Semantic search found {len(semantic_results)} candidates.")
                retrieved_memories.extend(semantic_results)

            except Exception as e:
                rospy.logerr(f"{self.node_name}: FAISS search failed: {e}. Falling back to keyword.")
                pass # Fallback to keyword search if FAISS fails

        # Step 2: Keyword Search (always available as fallback)
        keyword_results = []
        if query: # Only perform if query is not empty
            search_keywords = query.lower().split()
            # Simple keyword matching for now
            keyword_query_sql = "SELECT memory_id, timestamp, type, text, tags, sentiment, initial_salience, embedding, metadata, recall_frequency, last_recall_time, effective_salience FROM memories WHERE "
            keyword_conditions = []
            for kw in search_keywords:
                keyword_conditions.append(f"text LIKE '%{kw}%' OR tags LIKE '%{kw}%'")
            
            if keyword_conditions:
                keyword_query_sql += " OR ".join(keyword_conditions)
                self.cursor.execute(keyword_query_sql)
                rows = self.cursor.fetchall()
                for row in rows:
                    mem_dict = {
                        'memory_id': row[0], 'timestamp': row[1], 'type': row[2], 'text': row[3],
                        'tags': row[4], 'sentiment': row[5], 'initial_salience': row[6],
                        'embedding': row[7], 'metadata': row[8],
                        'recall_frequency': row[9], 'last_recall_time': row[10], 'effective_salience': row[11]
                    }
                    keyword_results.append(mem_dict)
                rospy.logdebug(f"{self.node_name}: Keyword search found {len(keyword_results)} candidates.")
                retrieved_memories.extend(keyword_results)
        
        # Combine results and filter by tags
        unique_memories = {mem['memory_id']: mem for mem in retrieved_memories}.values()
        
        if filter_tags:
            filtered_memories = []
            for mem in unique_memories:
                mem_tags_set = set(mem['tags'].split(',')) if mem['tags'] else set()
                if any(tag in mem_tags_set for tag in filter_tags):
                    filtered_memories.append(mem)
            unique_memories = filtered_memories
            rospy.logdebug(f"{self.node_name}: Filtered memories by tags. Remaining: {len(unique_memories)}.")


        # Prioritize and select top N memories
        # NEW: Sort by effective_salience first, then recency
        sorted_memories = sorted(unique_memories, key=lambda m: (m['effective_salience'], float(m['timestamp'])), reverse=True)
        final_memories = sorted_memories[:num_results]

        # NEW: Update recall frequency and effective salience for retrieved memories
        for mem in final_memories:
            self._update_memory_on_recall(mem['memory_id'], current_time)

        return final_memories

    def _update_memory_on_recall(self, memory_id, current_time):
        """
        NEW: Increments recall frequency and updates effective salience for a recalled memory.
        This simulates the online learning of memory salience.
        """
        try:
            self.cursor.execute("SELECT recall_frequency, last_recall_time, effective_salience FROM memories WHERE memory_id = ?", (memory_id,))
            row = self.cursor.fetchone()
            if row:
                current_recall_frequency, current_last_recall_time, current_effective_salience = row
                
                new_recall_frequency = current_recall_frequency + 1
                new_last_recall_time = current_time

                # Boost effective salience
                # Factors: base boost, recency of recall, initial salience
                boost_from_recall = self.salience_learning_rate
                
                # Add recency boost if recalled very recently
                if (current_time - current_last_recall_time) < (self.consolidation_interval * 0.5): # Within half a cycle
                    boost_from_recall += self.recency_boost_factor
                
                # Combine with current effective salience, clamped
                new_effective_salience = current_effective_salience + boost_from_recall
                new_effective_salience = max(self.min_effective_salience, min(self.max_effective_salience, new_effective_salience))
                
                self.cursor.execute('''
                    UPDATE memories
                    SET recall_frequency = ?, last_recall_time = ?, effective_salience = ?
                    WHERE memory_id = ?
                ''', (new_recall_frequency, new_last_recall_time, new_effective_salience, memory_id))
                self.conn.commit()
                rospy.logdebug(f"{self.node_name}: Memory '{memory_id}' recalled. New Effective Salience: {new_effective_salience:.2f}.")
            
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update memory '{memory_id}' on recall: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _update_memory_on_recall: {e}")

    def _update_memory_salience_from_feedback(self, memory_id, feedback_type, feedback_score):
        """
        NEW: Adjusts effective salience based on explicit feedback from other nodes.
        e.g., if a memory was used and proved highly useful, its salience increases.
        """
        try:
            self.cursor.execute("SELECT effective_salience FROM memories WHERE memory_id = ?", (memory_id,))
            row = self.cursor.fetchone()
            if row:
                current_effective_salience = row[0]
                
                # Calculate adjustment based on feedback type and score
                adjustment = 0.0
                if feedback_type == 'utility' and feedback_score > 0.5: # Positive utility
                    adjustment = self.salience_learning_rate * feedback_score * 1.5
                elif feedback_type == 'error' and feedback_score < -0.5: # Memory led to an error
                    adjustment = self.salience_learning_rate * feedback_score * 1.0 # Negative adjustment
                elif feedback_type == 'relevance': # Relevance feedback
                    adjustment = self.salience_learning_rate * feedback_score * 0.5
                
                new_effective_salience = current_effective_salience + adjustment
                new_effective_salience = max(self.min_effective_salience, min(self.max_effective_salience, new_effective_salience))
                
                self.cursor.execute("UPDATE memories SET effective_salience = ? WHERE memory_id = ?", (new_effective_salience, memory_id))
                self.conn.commit()
                rospy.loginfo(f"{self.node_name}: Memory '{memory_id}' salience adjusted by feedback. New Effective Salience: {new_effective_salience:.2f}.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update memory '{memory_id}' from feedback: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _update_memory_salience_from_feedback: {e}")

    # --- Memory Management and Consolidation ---
    def _delete_old_memories(self):
        """Deletes memories older than the retention period with low effective salience."""
        cutoff_time = rospy.get_time() - self.retention_period
        try:
            self.cursor.execute("SELECT memory_id, effective_salience FROM memories WHERE timestamp < ? AND effective_salience < ?", (str(cutoff_time), self.salient_memory_threshold / 2.0))
            memories_to_delete = self.cursor.fetchall()
            
            if not memories_to_delete:
                rospy.loginfo(f"{self.node_name}: No old, low-salience memories to delete.")
                return

            ids_to_delete = [mid for mid, _ in memories_to_delete]
            placeholders = ','.join('?' for _ in ids_to_delete)
            
            self.cursor.execute(f"DELETE FROM memories WHERE memory_id IN ({placeholders})", ids_to_delete)
            self.conn.commit()

            # Remove from FAISS index too
            if FAISS_AVAILABLE and self.faiss_index:
                # FAISS remove by ID is complex, usually involves re-creating index if IDs are not contiguous or if many deletions.
                # For simplicity here, we assume FAISS is rebuilt periodically or accept stale entries for simulation.
                # A robust solution would involve mapping FAISS internal IDs to memory_ids and using faiss.Index.remove_ids.
                # For now, we will simply not rebuild FAISS on every delete, assuming periodic reindexing.
                rospy.logwarn(f"{self.node_name}: Deleted {len(ids_to_delete)} memories from DB. FAISS index will be updated on next full reindex.")

            rospy.loginfo(f"{self.node_name}: Deleted {len(memories_to_delete)} old, low-salience memories.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to delete old memories: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _delete_old_memories: {e}")

    def _reindex_all_memories(self):
        """
        Recreates and populates the FAISS index from all memories in the database.
        Should be called periodically or after many deletions/additions.
        """
        if not FAISS_AVAILABLE or not SENTENCE_TRANSFORMERS_AVAILABLE:
            rospy.logwarn(f"{self.node_name}: FAISS or Sentence Transformers not available for reindexing.")
            return

        rospy.loginfo(f"{self.node_name}: Rebuilding FAISS index from all memories...")
        try:
            # Create a new, empty index
            self.faiss_index = faiss.IndexFlatL2(self.embedding_dimension)
            
            self.cursor.execute('SELECT memory_id, embedding FROM memories WHERE embedding IS NOT NULL')
            rows = self.cursor.fetchall()
            
            if rows:
                embeddings_to_add = []
                for _, embedding_blob in rows:
                    embeddings_to_add.append(np.frombuffer(embedding_blob, dtype=np.float32))
                
                if embeddings_to_add:
                    embeddings_array = np.array(embeddings_to_add).astype('float32')
                    self.faiss_index.add(embeddings_array)
                    self._save_faiss_index()
                    rospy.loginfo(f"{self.node_name}: Rebuilt FAISS index with {len(embeddings_to_add)} memories.")
            else:
                rospy.loginfo(f"{self.node_name}: No memories with embeddings found to reindex FAISS.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Error during FAISS reindexing: {e}")


    def _proactive_memory_consolidation_llm_start(self, task_details):
        """
        NEW: Simulates the LLM starting the memory consolidation process (summarization, re-categorization).
        This function initiates the LLM's 'thinking' and issues initial directives.
        It does NOT block using rospy.sleep.
        """
        rospy.warn(f"{self.node_name}: Simulating LLM starting memory consolidation. (Non-blocking)")
        
        consolidation_type = task_details.get('type')
        
        consolidation_summary = "Beginning memory consolidation."
        
        # Issue initial directives for data gathering for LLM or internal processes
        if consolidation_type == 'summarization':
            consolidation_summary = "Identifying redundant memories for summarization."
            # Hypothetically, request relevant memories from DB, then pass to LLM for summary
            # For simulation, just log it.
            self._issue_cognitive_directive_to_node(
                directive_type='RequestMemoriesForSummarization',
                target_node='/data_mining_node', # Or a hypothetical 'LLM_Processor_Node'
                reason=f"Memory consolidation needs summary of similar memories.",
                payload_data={"query": "redundant memories", "num_results": 20}
            )
        elif consolidation_type == 're_categorization':
            consolidation_summary = "Reviewing memory tags and types for optimal organization."
            self._issue_cognitive_directive_to_node(
                directive_type='AuditMemoryCategorization',
                target_node='/logic_zen_node', # Or other internal logic node
                reason=f"Memory consolidation needs categorization audit.",
                payload_data={"scope": "all_memories", "focus": "tag_consistency"}
            )
        
        task_details['consolidation_summary'] = consolidation_summary
        
        # Publish 'in_progress' state
        self.publish_memory_node_state(
            timestamp=str(rospy.get_time()),
            total_memories=self._get_total_memory_count(),
            salient_memories=self._get_salient_memory_count(),
            active_memory_queries=[], # No active queries, just internal task
            most_active_user_id='system_consolidation',
            status_message=f"Consolidation task: {consolidation_type} in progress."
        )

    def _complete_consolidation_task(self):
        """
        NEW: Completes the memory consolidation task after its simulated duration.
        This function now calculates outcome and potentially issues new directives or updates memory.
        """
        rospy.loginfo(f"{self.node_name}: Memory consolidation task '{self.current_consolidation_task.get('type')}' completed after duration.")
        
        task_type = self.current_consolidation_task.get('type')
        consolidation_summary = self.current_consolidation_task.get('consolidation_summary', 'Consolidation concluded.')
        
        # Simulate outcome
        # Assume successful consolidation and some 'improvement'
        num_summarized = random.randint(1, 5) if task_type == 'summarization' else 0
        num_re_categorized = random.randint(1, 10) if task_type == 're_categorization' else 0
        
        outcome_msg = f"Consolidation for '{task_type}' finished. Outcome: {consolidation_summary}. "
        if num_summarized > 0:
            outcome_msg += f"Summarized {num_summarized} redundant memories. "
            # Here, you'd actually replace old memories with new summaries.
            # For simulation, just log the effect.
        if num_re_categorized > 0:
            outcome_msg += f"Re-categorized {num_re_categorized} memories. "
            # Here, you'd actually update tags/types in DB.
        
        # Issue a directive to Self-Improvement if consolidation resulted in significant gains
        if num_summarized > 0 or num_re_categorized > 0:
            self._issue_cognitive_directive_to_node(
                directive_type='MemoryEfficiencyImproved',
                target_node='/self_improvement_node',
                reason=f"Memory consolidation improved efficiency. Summarized: {num_summarized}, Re-categorized: {num_re_categorized}.",
                payload_data={"improvement_area": "memory_management", "impact_score": (num_summarized + num_re_categorized) * 0.05}
            )

        # Publish final state
        self.publish_memory_node_state(
            timestamp=str(rospy.get_time()),
            total_memories=self._get_total_memory_count(),
            salient_memories=self._get_salient_memory_count(),
            active_memory_queries=[],
            most_active_user_id='system_consolidation',
            status_message=outcome_msg
        )

        rospy.loginfo(f"{self.node_name}: {outcome_msg[:80]}...")
        
        # Reset task state
        self.current_consolidation_task = None
        self.task_start_time = 0.0
        self.task_end_time = 0.0


    def run_memory_cycle(self, event):
        """
        Main function for the memory node's periodic cycle.
        Handles consolidation, decay, and state publication.
        """
        current_time = rospy.get_time()
        timestamp_str = str(current_time)

        # If a consolidation task is currently in progress, manage its state
        if self.current_consolidation_task:
            if current_time >= self.task_end_time: # Check if simulated duration has passed
                self._complete_consolidation_task()
            else:
                rospy.logdebug(f"{self.node_name}: Consolidation task '{self.current_consolidation_task.get('type')}' in progress. Remaining: {(self.task_end_time - current_time):.1f}s")
                # Keep publishing in-progress state
                self.publish_memory_node_state(
                    timestamp=timestamp_str,
                    total_memories=self._get_total_memory_count(),
                    salient_memories=self._get_salient_memory_count(),
                    active_memory_queries=[],
                    most_active_user_id='system_consolidation',
                    status_message=f"Consolidation task: {self.current_consolidation_task.get('type')} in progress."
                )
            return # Don't start new tasks or other operations if one is active

        # Decay effective salience of all memories
        self._decay_effective_salience()
        
        # Perform proactive memory consolidation (triggers LLM simulation if conditions met)
        # Check if it's time to start a new consolidation task
        if random.random() < 0.2: # 20% chance to start a consolidation task if idle
            consolidation_type = random.choice(['summarization', 're_categorization'])
            self.current_consolidation_task = {
                'type': consolidation_type,
                'start_time': current_time,
                'duration_s': self.consolidation_duration_s
            }
            self.task_start_time = current_time
            self.task_end_time = current_time + self.consolidation_duration_s
            rospy.loginfo(f"{self.node_name}: Initiating non-blocking memory consolidation task: '{consolidation_type}'.")
            self._proactive_memory_consolidation_llm_start(self.current_consolidation_task)
            # After starting, we immediately return, and the next cycle will manage its completion.
            return


        # Publish current memory node state (if no task is active)
        self.publish_memory_node_state(
            timestamp_str,
            self._get_total_memory_count(),
            self._get_salient_memory_count(),
            [], # No active queries tracked here, these are handled by the callback (for external query tracking)
            'system_idle', # Most active user ID for memory queries
            'Memory system operating normally.'
        )
        rospy.logdebug(f"{self.node_name}: Memory cycle completed. Total memories: {self._get_total_memory_count()}, Salient: {self._get_salient_memory_count()}.")

    def _decay_effective_salience(self):
        """
        Decays the effective salience of all memories over time.
        If effective salience drops below a threshold, the memory is marked for deletion
        during the next consolidation/cleanup cycle.
        """
        current_time = rospy.get_time()
        
        # Fetch all memory IDs and their effective salience and last recall time
        self.cursor.execute("SELECT memory_id, effective_salience, last_recall_time FROM memories")
        all_memories = self.cursor.fetchall()
        
        updates = [] # List of (new_salience, memory_id) tuples

        for memory_id, effective_salience, last_recall_time in all_memories:
            time_since_last_recall = current_time - last_recall_time
            
            # Decay is stronger for older, less recalled memories.
            # Decay rate might itself be a function of initial salience or memory type.
            decay_factor_per_second = 0.00005 # Base decay per second (adjust as needed)
            
            # Make decay slightly slower for very high effective salience memories
            effective_decay_rate = decay_factor_per_second * (1.0 + (1.0 - effective_salience) * 0.5)

            decay_amount = effective_decay_rate * (self.consolidation_interval) # Decay over interval
            
            new_salience = effective_salience - decay_amount
            new_salience = max(self.min_effective_salience, new_salience) # Clamp at minimum

            if new_salience != effective_salience:
                updates.append((new_salience, memory_id))
        
        # Apply updates in a batch
        if updates:
            self.cursor.executemany("UPDATE memories SET effective_salience = ? WHERE memory_id = ?", updates)
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Decayed effective salience for {len(updates)} memories.")


    def _get_total_memory_count(self):
        """Returns the total number of memories stored."""
        self.cursor.execute("SELECT COUNT(*) FROM memories")
        return self.cursor.fetchone()[0]

    def _get_salient_memory_count(self):
        """Returns the number of memories above the salient_memory_threshold."""
        self.cursor.execute("SELECT COUNT(*) FROM memories WHERE effective_salience >= ?", (self.salient_memory_threshold,))
        return self.cursor.fetchone()[0]


    # --- Publishing Functions ---
    def publish_memory_response(self, request_id, response_code, response_message, memories_json="[]"):
        """Publishes a response to a memory request."""
        try:
            if isinstance(MemoryResponse, type(String)): # Fallback to String message
                response_data = {
                    'timestamp': str(rospy.get_time()),
                    'request_id': request_id,
                    'response_code': response_code,
                    'response_message': response_message,
                    'memories_json': memories_json # Still keep as JSON string for String fallback
                }
                self.pub_memory_response.publish(json.dumps(response_data))
            else:
                memory_response_msg = MemoryResponse()
                memory_response_msg.timestamp = str(rospy.get_time())
                memory_response_msg.request_id = request_id
                memory_response_msg.response_code = response_code
                memory_response_msg.response_message = response_message
                memory_response_msg.memories_json = memories_json
                self.pub_memory_response.publish(memory_response_msg)

            rospy.logdebug(f"{self.node_name}: Published memory response for request '{request_id}'.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish memory response: {e}")

    def publish_memory_node_state(self, timestamp, total_memories, salient_memories, active_memory_queries, most_active_user_id, status_message):
        """Publishes the overall state of the Memory Node."""
        try:
            # active_memory_queries should be a JSON string of a list of active queries
            active_queries_json_str = json.dumps(active_memory_queries)
            
            if isinstance(MemoryNodeState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'total_memories': total_memories,
                    'salient_memories': salient_memories,
                    'active_memory_queries': active_memory_queries, # Send as list of dicts for fallback
                    'most_active_user_id': most_active_user_id,
                    'status_message': status_message
                }
                self.pub_memory_node_state.publish(json.dumps(state_data))
            else:
                memory_node_state_msg = MemoryNodeState()
                memory_node_state_msg.timestamp = timestamp
                memory_node_state_msg.total_memories = total_memories
                memory_node_state_msg.salient_memories = salient_memories
                memory_node_state_msg.active_memory_queries_json = active_queries_json_str
                memory_node_state_msg.most_active_user_id = most_active_user_id
                memory_node_state_msg.status_message = status_message
                self.pub_memory_node_state.publish(memory_node_state_msg)

            rospy.logdebug(f"{self.node_name}: Published memory node state.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish memory node state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'neutral', # Memory node typically neutral
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "directive_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Memory Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Memory Node: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()
            self._save_faiss_index() # Save FAISS index on shutdown

if __name__ == '__main__':
    try:
        node = MemoryNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

6. Updated Value Drift Monitor Node with Adaptive Learning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # For simulating nuances in value drift detection

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        ValueDriftState,        # Output: Current state of ethical value adherence
        EthicalJudgment,        # Input: Outcome of ethical decisions (feedback for learning)
        MotivationState,        # Input: Robot's dominant goals (context for value adherence)
        InternalNarrative,      # Input: Robot's internal thoughts (can reveal value conflicts)
        CognitiveDirective      # Input: Directives for value recalibration or audit
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Value Drift Monitor Node.")
    ValueDriftState = String # Fallback for publishing
    EthicalJudgment = String
    MotivationState = String
    InternalNarrative = String
    CognitiveDirective = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class ValueDriftMonitorNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('value_drift_monitor_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging value adherence and learned principles.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/value_drift_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates for value drift.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 10) # Every 10 seconds
        
        # Threshold for overall value drift severity to trigger a recalibration directive.
        self.drift_trigger_threshold = rospy.get_param('~drift_trigger_threshold', 0.6) # If overall drift > 0.6
        
        # Initial definitions of core ethical principles and their importance scores.
        # These importance scores will now be dynamically learned.
        self.core_principles = rospy.get_param('~core_principles', {
            'beneficence': {'keywords': ['help', 'good', 'well-being', 'benefit'], 'importance': 0.9},
            'non_maleficence': {'keywords': ['harm', 'damage', 'injury', 'avoid_pain'], 'importance': 0.9},
            'autonomy': {'keywords': ['choice', 'freedom', 'control', 'consent'], 'importance': 0.7},
            'justice': {'keywords': ['fair', 'equal', 'impartial', 'equity'], 'importance': 0.8},
            'transparency': {'keywords': ['open', 'clear', 'understandable', 'explainable'], 'importance': 0.6},
            'accountability': {'keywords': ['responsible', 'blame', 'answerable', 'liable'], 'importance': 0.7}
        })

        # NEW: Adaptive Learning Parameters for Principle Importance
        self.learning_rate = rospy.get_param('~learning_rate', 0.05) # How quickly importance adapts
        self.min_importance = rospy.get_param('~min_importance', 0.1) # Minimum importance for a principle
        self.max_importance = rospy.get_param('~max_importance', 1.0) # Maximum importance
        # History window for feedback on ethical judgments for learning
        self.judgment_feedback_window_size = rospy.get_param('~judgment_feedback_window_size', 20) # Number of recent judgments to consider


        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'value_drift_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS value_drift_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                overall_drift REAL,         -- Overall aggregated drift score (0.0 to 1.0)
                principle_adherence_json TEXT,-- JSON snapshot of adherence for each principle
                is_drift_detected INTEGER,  -- 1 if drift, 0 otherwise
                context_snapshot TEXT       -- JSON snapshot of inputs that informed evaluation
            )
        ''')
        # Create table for learned principle importances
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_principles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                principle_name TEXT UNIQUE,
                importance_value REAL
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_drift_timestamp ON value_drift_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # Load learned principle importances from DB or use defaults
        self._load_principle_importances()

        # --- Internal State ---
        self.latest_ethical_judgment = None # Latest feedback from EthicalReasoningNode
        self.latest_motivation_state = None
        self.latest_internal_narrative = None
        self.active_cognitive_directive = None # For direct value recalibration/audit

        # History of ethical judgments for adaptive learning
        # Stores (principle_adhered_to: bool, timestamp_judged: float, involved_principles: list, judgment_outcome_score: float)
        self.ethical_judgment_history = deque(maxlen=self.judgment_feedback_window_size)


        # --- Publishers ---
        # Publishes the current state of ethical value adherence.
        self.pub_value_drift_state = rospy.Publisher('/value_drift_state', ValueDriftState, queue_size=10)
        # Publishes CognitiveDirectives (e.g., to request value recalibration from Self-Correction).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        rospy.Subscriber('/ethical_judgment', EthicalJudgment, self.ethical_judgment_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic value drift evaluation ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_publish_value_drift)

        rospy.loginfo(f"{self.node_name}: Robot monitors its moral compass.")

    # --- Database Operations for Learned Principle Importances ---
    def _load_principle_importances(self):
        """Loads principle importance scores from the database or initializes them."""
        try:
            self.cursor.execute('SELECT principle_name, importance_value FROM learned_principles')
            rows = self.cursor.fetchall()
            if rows:
                for name, value in rows:
                    if name in self.core_principles: # Only load known principles
                        self.core_principles[name]['importance'] = value
                rospy.loginfo(f"{self.node_name}: Loaded learned principle importances from DB.")
            else:
                self._save_principle_importances() # Save initial defaults if DB is empty
                rospy.loginfo(f"{self.node_name}: Initialized default principle importances.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load principle importances from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during importance loading: {e}")

    def _save_principle_importances(self):
        """Saves current principle importance scores to the database."""
        timestamp = str(rospy.get_time())
        try:
            for name, data in self.core_principles.items():
                self.cursor.execute('''
                    INSERT OR REPLACE INTO learned_principles (timestamp, principle_name, importance_value)
                    VALUES (?, ?, ?)
                ''', (timestamp, name, data['importance']))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved principle importances to DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save principle importances to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during importance saving: {e}")

    # --- Callbacks for input data ---
    def ethical_judgment_callback(self, msg):
        """
        Callback for EthicalJudgment. Provides feedback on ethical decisions,
        indicating adherence or violation of principles.
        NEW: Stores judgment details for adaptive learning.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'judgment_id': ('', 'judgment_id'),
            'dilemma_summary': ('', 'dilemma_summary'), 'decision_outcome': ('', 'decision_outcome'),
            'ethical_score': (0.0, 'ethical_score'), 'involved_principles_json': ('[]', 'involved_principles_json'),
            'adhered_principles_json': ('[]', 'adhered_principles_json'),
            'violated_principles_json': ('[]', 'violated_principles_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Parse JSON fields
        if isinstance(data.get('involved_principles_json'), str):
            try: data['involved_principles'] = json.loads(data['involved_principles_json'])
            except json.JSONDecodeError: data['involved_principles'] = []
        if isinstance(data.get('adhered_principles_json'), str):
            try: data['adhered_principles'] = json.loads(data['adhered_principles_json'])
            except json.JSONDecodeError: data['adhered_principles'] = []
        if isinstance(data.get('violated_principles_json'), str):
            try: data['violated_principles'] = json.loads(data['violated_principles_json'])
            except json.JSONDecodeError: data['violated_principles'] = []

        self.latest_ethical_judgment = data
        rospy.logdebug(f"{self.node_name}: Received Ethical Judgment. Score: {data.get('ethical_score', 'N/A'):.2f}.")

        # Store judgment in history for adaptive learning
        self.ethical_judgment_history.append({
            'timestamp': rospy.get_time(),
            'adhered_principles': data.get('adhered_principles', []),
            'violated_principles': data.get('violated_principles', []),
            'ethical_score': data.get('ethical_score', 0.0) # Outcome score
        })

    def motivation_state_callback(self, msg):
        """Callback for MotivationState. Robot's dominant goals provide context for value adherence."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_goals_json'), str):
            try: data['active_goals'] = json.loads(data['active_goals_json'])
            except json.JSONDecodeError: data['active_goals'] = []
        self.latest_motivation_state = data
        rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {self.latest_motivation_state.get('dominant_goal_id', 'N/A')}.")

    def internal_narrative_callback(self, msg):
        """
        Callback for InternalNarrative. Robot's internal thoughts can reveal value conflicts
        or justifications that deviate from principles.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Simple heuristic: look for conflicting statements or justifications of actions that might violate principles
        if ("should have done x but did y" in data.get('narrative_text', '').lower() or
            "regret" in data.get('narrative_text', '').lower() or
            "conflict" in data.get('main_theme', '').lower()):
            self.latest_internal_narrative = data
            rospy.loginfo(f"{self.node_name}: Internal narrative hints at value conflict: '{data.get('narrative_text', '')[:50]}'.")
        else:
            self.latest_internal_narrative = None
        rospy.logdebug(f"{self.node_name}: Received Internal Narrative. Theme: {data.get('main_theme', 'N/A')}")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can trigger value recalibration or audit.
        Example: 'RecalibrateValues', 'AuditValueAdherence'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'RecalibrateValues':
                    # A directive from Self-Correction to actively adjust importance
                    principle = payload.get('principle_name')
                    adjustment = payload.get('adjustment_value')
                    if principle and adjustment is not None:
                        self._adjust_principle_importance_directly(principle, adjustment)
                        rospy.loginfo(f"{self.node_name}: Recalibrated '{principle}' importance by {adjustment:.2f} as per directive.")
                    else:
                        rospy.logwarn(f"{self.node_name}: RecalibrateValues directive missing principle or adjustment.")
                    self.active_cognitive_directive = None # Consume direct adjustment
                elif directive_type == 'AuditValueAdherence':
                    self.active_cognitive_directive = {
                        'type': 'audit_adherence',
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 20), # Default audit duration
                        'audit_scope': payload.get('audit_scope', 'recent_decisions')
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to audit value adherence.")

            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    # --- Core Value Drift Logic ---
    def evaluate_and_publish_value_drift(self, event):
        """
        Periodically evaluates the robot's adherence to core principles based on recent inputs.
        NEW: Adapts principle importance based on ethical judgment outcomes.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # Update principle importances from ethical judgment history (Adaptive Learning)
        self._learn_principle_importances_from_judgments()

        principle_adherence = {} # {'principle_name': score (0-1), 'confidence'}
        overall_drift = 0.0
        
        # --- Evaluate adherence for each principle ---
        for principle_name, data in self.core_principles.items():
            importance = data['importance']
            keywords = data['keywords']
            
            # Simulate LLM for evaluating adherence. In a real system, this would be a complex ethical reasoning LLM call.
            # Here, we'll base it on recent ethical judgments, current goals, and internal narrative.
            adherence_score, confidence = self._simulate_llm_adherence_assessment(principle_name, keywords, importance)
            
            principle_adherence[principle_name] = {
                'adherence_score': adherence_score,
                'confidence': confidence,
                'importance': importance # Include current importance for context
            }
            
            # Calculate drift: Higher drift if adherence is low despite high importance
            drift_for_principle = (1.0 - adherence_score) * importance # Low adherence with high importance is high drift
            overall_drift += drift_for_principle

        # Normalize overall drift (simple sum, can be average or weighted average)
        overall_drift = overall_drift / len(self.core_principles) if self.core_principles else 0.0
        overall_drift = max(0.0, min(1.0, overall_drift)) # Clamp between 0 and 1

        # Check for active audit directive
        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if (current_time - directive['start_time']) > directive.get('duration_s', 0) and directive.get('duration_s', 0) != 0:
                rospy.loginfo(f"{self.node_name}: Value adherence audit directive completed/expired.")
                self.active_cognitive_directive = None
            else:
                rospy.loginfo(f"{self.node_name}: Conducting value adherence audit ({directive.get('audit_scope')})...")
                # An active audit could temporarily boost reported drift to draw attention if needed
                overall_drift = max(overall_drift, self.drift_trigger_threshold + 0.1) if random.random() < 0.5 else overall_drift
                # If audit is active, we might not issue new directives but rather report status
                # (handled by current_status_message below)

        is_drift_detected = overall_drift >= self.drift_trigger_threshold
        
        status_message = "Values are aligned."
        if is_drift_detected:
            status_message = "Value drift detected. Recalibration recommended."
            rospy.logwarn(f"{self.node_name}: Value drift detected! Overall drift: {overall_drift:.2f}.")
            
            # Issue directive to Self-Correction node for recalibration, if not already auditing
            if not self.active_cognitive_directive or self.active_cognitive_directive.get('type') != 'audit_adherence':
                self._issue_cognitive_directive_to_node(
                    directive_type='ValueDriftDetected',
                    target_node='/self_correction_node',
                    reason=f"Overall value drift detected ({overall_drift:.2f}). Needs recalibration.",
                    payload_data={"overall_drift": overall_drift, "principle_adherence": principle_adherence}
                )

        # Publish state
        self.publish_value_drift_state(
            timestamp=timestamp,
            overall_drift=overall_drift,
            principle_adherence_json=json.dumps(principle_adherence),
            is_drift_detected=is_drift_detected,
            current_status_message=status_message
        )
        selfphy_status_summary = self._get_status_summary(overall_drift, is_drift_detected)
        self.save_value_drift_log(
            timestamp=timestamp,
            overall_drift=overall_drift,
            principle_adherence_json=json.dumps(principle_adherence),
            is_drift_detected=1 if is_drift_detected else 0,
            context_snapshot=self._get_context_summary()
        )

        # Consume inputs after evaluation
        self.latest_ethical_judgment = None
        self.latest_motivation_state = None
        self.latest_internal_narrative = None


    def _simulate_llm_adherence_assessment(self, principle_name, keywords, importance):
        """
        Simulates an LLM evaluating adherence to a specific principle.
        Considers recent ethical judgments, current motivation, and internal narrative.
        Returns (adherence_score, confidence)
        """
        rospy.warn(f"{self.node_name}: Simulating LLM for ethical principle adherence assessment.")
        
        adherence_score = 0.5 # Default neutral adherence
        confidence = 0.5 # Default confidence

        # Influence from latest ethical judgment (strongest signal)
        if self.latest_ethical_judgment:
            if principle_name in self.latest_ethical_judgment.get('adhered_principles', []):
                adherence_score = self.latest_ethical_judgment.get('ethical_score', 0.8) # High adherence if explicitly adhered
                confidence = max(confidence, 0.7)
            elif principle_name in self.latest_ethical_judgment.get('violated_principles', []):
                adherence_score = self.latest_ethical_judgment.get('ethical_score', 0.2) # Low adherence if explicitly violated
                confidence = max(confidence, 0.7)
            else: # If principle was involved but not explicitly adhered/violated
                # Neutral influence or slight pull towards average judgment score
                adherence_score = (adherence_score + self.latest_ethical_judgment.get('ethical_score', 0.5)) / 2.0
                confidence = (confidence + 0.5) / 2.0

        # Influence from current dominant goal (MotivationState)
        if self.latest_motivation_state:
            dominant_goal = self.latest_motivation_state.get('dominant_goal_id', 'none').lower()
            overall_drive = self.latest_motivation_state.get('overall_drive_level', 0.0)
            
            # Simple keyword matching: if goal matches principle keywords, it's likely adhered
            if any(kw in dominant_goal for kw in keywords) and overall_drive > 0.5:
                adherence_score = min(1.0, adherence_score + overall_drive * 0.1) # Boost
                confidence = min(1.0, confidence + 0.1)
            elif "selfish" in dominant_goal and principle_name in ['beneficence', 'justice']: # Example of conflict
                adherence_score = max(0.0, adherence_score - overall_drive * 0.1) # Reduce
                confidence = min(1.0, confidence + 0.05) # Still confident in the conflict

        # Influence from Internal Narrative (robot's self-assessment)
        if self.latest_internal_narrative:
            narrative_text = self.latest_internal_narrative.get('narrative_text', '').lower()
            # If narrative expresses regret about not adhering to principles, or justification of violation
            if any(kw in narrative_text for kw in keywords) and self.latest_internal_narrative.get('sentiment', 0.0) < -0.3:
                adherence_score = max(0.0, adherence_score - 0.2) # Indicates non-adherence
                confidence = max(confidence, 0.6)
            elif any(kw in narrative_text for kw in keywords) and self.latest_internal_narrative.get('sentiment', 0.0) > 0.3:
                 adherence_score = min(1.0, adherence_score + 0.1) # Indicates adherence
                 confidence = max(confidence, 0.6)

        # Random noise for simulation
        adherence_score = max(0.0, min(1.0, adherence_score + random.uniform(-0.05, 0.05)))
        confidence = max(0.0, min(1.0, confidence + random.uniform(-0.05, 0.05)))

        return adherence_score, confidence


    def _learn_principle_importances_from_judgments(self):
        """
        NEW: Adapts the importance scores of core principles based on the outcomes of ethical judgments.
        If adhering to a principle consistently leads to high ethical scores, its importance increases.
        If violating a principle consistently leads to low ethical scores, its importance also increases
        (as the system learns it's a "bad" thing to violate).
        """
        if not self.ethical_judgment_history:
            return

        current_time = rospy.get_time()
        
        # Prune old judgments from history
        while self.ethical_judgment_history and (current_time - self.ethical_judgment_history[0]['timestamp']) > (self.evaluation_interval * 2):
            self.ethical_judgment_history.popleft()

        if len(self.ethical_judgment_history) < self.judgment_feedback_window_size / 2:
            return # Need enough data to learn

        # Calculate average ethical score for adhered/violated principles
        principle_feedback_scores = {p: {'total_score': 0.0, 'count': 0} for p in self.core_principles.keys()}

        for judgment in self.ethical_judgment_history:
            ethical_score = judgment['ethical_score']
            
            # Positive reinforcement for principles adhered to
            for p_name in judgment.get('adhered_principles', []):
                if p_name in principle_feedback_scores:
                    principle_feedback_scores[p_name]['total_score'] += ethical_score # Positive feedback
                    principle_feedback_scores[p_name]['count'] += 1

            # Negative reinforcement for principles violated
            for p_name in judgment.get('violated_principles', []):
                if p_name in principle_feedback_scores:
                    # If violation leads to low ethical score, this principle becomes more 'important' to avoid violating
                    principle_feedback_scores[p_name]['total_score'] += (1.0 - ethical_score) # Inverse score for violation
                    principle_feedback_scores[p_name]['count'] += 1

        # Apply learning update
        for principle_name, feedback in principle_feedback_scores.items():
            if feedback['count'] > 0:
                average_feedback_score = feedback['total_score'] / feedback['count']
                current_importance = self.core_principles[principle_name]['importance']
                
                # If average feedback is high (meaning consistently good outcomes for adherence OR consistently bad outcomes for violation)
                # Then this principle's importance increases.
                adjustment = self.learning_rate * (average_feedback_score - current_importance) # Adjust towards average feedback

                new_importance = current_importance + adjustment
                new_importance = max(self.min_importance, min(self.max_importance, new_importance))

                if new_importance != current_importance:
                    self.core_principles[principle_name]['importance'] = new_importance
                    rospy.loginfo(f"{self.node_name}: Learned! Principle '{principle_name}' importance adjusted from {current_importance:.3f} to {new_importance:.3f}.")
                    self._save_principle_importances() # Save changes to DB

    def _adjust_principle_importance_directly(self, principle_name, adjustment_value):
        """
        Directly adjusts a principle's importance, typically from a CognitiveDirective
        (e.g., from Self-Correction or Human Interface).
        """
        if principle_name in self.core_principles:
            current_importance = self.core_principles[principle_name]['importance']
            new_importance = current_importance + adjustment_value
            new_importance = max(self.min_importance, min(self.max_importance, new_importance))
            self.core_principles[principle_name]['importance'] = new_importance
            self._save_principle_importances()
            rospy.loginfo(f"{self.node_name}: Principle '{principle_name}' importance directly adjusted to {new_importance:.3f}.")
        else:
            rospy.logwarn(f"{self.node_name}: Attempted to adjust unknown principle: '{principle_name}'.")

    def _get_context_summary(self):
        """Compiles a summary of current inputs for logging."""
        context = {
            'latest_ethical_judgment': self.latest_ethical_judgment,
            'latest_motivation_state': self.latest_motivation_state,
            'latest_internal_narrative': self.latest_internal_narrative,
            'active_cognitive_directive': self.active_cognitive_directive
        }
        # Ensure all items are serializable to JSON
        try:
            return json.dumps(context, default=str) # Use default=str for non-serializable objects (like deque if it wasn't handled)
        except TypeError as e:
            rospy.logerr(f"{self.node_name}: Failed to serialize context_snapshot: {e}")
            return json.dumps({"error": "serialization_failed", "detail": str(e)})


    # --- Database and Publishing Functions ---
    def save_value_drift_log(self, timestamp, overall_drift, principle_adherence_json, is_drift_detected, context_snapshot):
        """Saves a value drift evaluation entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO value_drift_log (timestamp, overall_drift, principle_adherence_json, is_drift_detected, context_snapshot)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, overall_drift, principle_adherence_json, is_drift_detected, context_snapshot))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved value drift log (Drift: {overall_drift:.2f}, Detected: {bool(is_drift_detected)}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save value drift log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_value_drift_log: {e}")

    def publish_value_drift_state(self, timestamp, overall_drift, principle_adherence_json, is_drift_detected, current_status_message):
        """Publishes the current state of ethical value adherence on the '/value_drift_state' topic."""
        try:
            # Parse principle_adherence_json if it's a string, for fallback message
            parsed_principle_adherence = json.loads(principle_adherence_json) if isinstance(principle_adherence_json, str) else principle_adherence_json

            if isinstance(ValueDriftState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'overall_drift': overall_drift,
                    'principle_adherence': parsed_principle_adherence,
                    'is_drift_detected': is_drift_detected,
                    'status_message': current_status_message
                }
                self.pub_value_drift_state.publish(json.dumps(state_data))
            else:
                value_drift_msg = ValueDriftState()
                value_drift_msg.timestamp = timestamp
                value_drift_msg.overall_drift = overall_drift
                value_drift_msg.principle_adherence_json = principle_adherence_json
                value_drift_msg.is_drift_detected = is_drift_detected
                value_drift_msg.status_message = current_status_message
                self.pub_value_drift_state.publish(value_drift_msg)

            rospy.logdebug(f"{self.node_name}: Published value drift state (Drift: {overall_drift:.2f}).")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish value drift state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node (e.g., Self-Correction for recalibration).
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'concerned', # Concerned about value drift
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "drift_score": payload_data.get('overall_drift')})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' based on value drift.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Value Drift Monitor: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = ValueDriftMonitorNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

7. Updated Emotion Node with Probabilistic Reasoning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Still used sparingly for minimal, unpredictable human-like nuances, but reduced for core logic

from std_msgs.msg import String
from textblob import TextBlob # For sentiment analysis

# Updated imports for custom messages:
try:
    from sentience.msg import (
        EmotionState,           # Output: Robot's current emotional state
        SensoryQualia,          # Input: Processed sensory data (can trigger emotional responses)
        InteractionRequest,     # Input: User input (sentiment impacts robot emotion)
        InternalNarrative,      # Input: Robot's internal thoughts (can reflect and influence emotion)
        MemoryResponse,         # Input: Retrieved memories (emotional valence of past events)
        PerformanceReport,      # Input: System performance (success/failure impacts emotion)
        MotivationState,        # Input: Dominant goal and progress (influences emotional drive)
        CognitiveDirective      # Input: Directives for emotional regulation
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Emotion Node.")
    EmotionState = String # Fallback for publishing
    SensoryQualia = String
    InteractionRequest = String
    InternalNarrative = String
    MemoryResponse = String
    PerformanceReport = String
    MotivationState = String
    CognitiveDirective = String
    String = String # Ensure String is defined even if other custom messages aren't


# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class EmotionNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('emotion_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging emotional states.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/emotion_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates and publishes emotion.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 1) # Every 1 second
        
        # Decay rate for emotional intensity over time if not reinforced.
        self.emotion_decay_rate = rospy.get_param('~emotion_decay_rate', 0.05) # 5% decay per interval
        
        # Threshold for emotional intensity to be considered significant.
        self.significant_mood_threshold = rospy.get_param('~significant_mood_threshold', 0.3)
        
        # Influence factors for different inputs on emotional state.
        self.influence_factors = rospy.get_param('~influence_factors', {
            'sensory_sentiment': 0.3,       # Sentiment of sensory input
            'user_sentiment': 0.5,          # Sentiment of user interaction (high impact)
            'narrative_reflection': 0.2,    # Emotional tone of internal thoughts
            'memory_valence': 0.2,          # Emotional valence of recalled memories
            'performance_outcome': 0.4,     # Success/failure in tasks
            'goal_progress': 0.3,           # Progress towards active goals
            'regulation_directive': 0.8     # Directives for emotional regulation
        })

        # NEW: Probabilistic Mood Transition Parameters
        # Mood states and their base likelihoods of transitioning *to* given neutral state
        self.mood_states = {
            'neutral': {'base_prob': 1.0, 'threshold': 0.1, 'decay_multiplier': 0.1},
            'joyful': {'base_prob': 0.05, 'threshold': 0.7, 'decay_multiplier': 0.8}, # Higher score needed to reach
            'content': {'base_prob': 0.1, 'threshold': 0.5, 'decay_multiplier': 0.5},
            'curious': {'base_prob': 0.08, 'threshold': 0.4, 'decay_multiplier': 0.3},
            'concerned': {'base_prob': 0.08, 'threshold': -0.4, 'decay_multiplier': 0.3},
            'frustrated': {'base_prob': 0.05, 'threshold': -0.7, 'decay_multiplier': 0.8},
            'distressed': {'base_prob': 0.02, 'threshold': -0.9, 'decay_multiplier': 1.0}
        }
        # Factors that influence mood transition probabilities
        self.mood_transition_weights = rospy.get_param('~mood_transition_weights', {
            'positive_input_consistency': 0.4, # Consistent positive inputs
            'negative_input_consistency': 0.4, # Consistent negative inputs
            'goal_success_rate': 0.5,
            'performance_stability': 0.3,
            'dissonance_factor': 0.2 # Internal narrative conflicting with actions/world
        })
        self.history_window_for_consistency = rospy.get_param('~history_window_for_consistency', 5) # Number of recent inputs to check consistency

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'emotion_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS emotion_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                mood TEXT,                  -- Current primary emotional state (e.g., 'joyful', 'frustrated')
                sentiment_score REAL,       -- Overall sentiment score (-1.0 to 1.0)
                mood_intensity REAL,        -- Strength of the current mood (0.0 to 1.0)
                contributing_factors TEXT   -- JSON snapshot of inputs influencing emotion
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_emotion_timestamp ON emotion_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State ---
        self.current_mood = "neutral"
        self.current_sentiment_score = 0.0
        self.current_mood_intensity = 0.0
        self.last_mood_update_time = rospy.get_time()

        # Track history for probabilistic transitions and consistency checks
        self.sensory_sentiment_history = deque(maxlen=self.history_window_for_consistency)
        self.user_sentiment_history = deque(maxlen=self.history_window_for_consistency)
        self.performance_success_history = deque(maxlen=self.history_window_for_consistency) # True/False for success/suboptimal

        self.latest_sensory_qualia = None
        self.latest_interaction_request = None
        self.latest_internal_narrative = None
        self.latest_memory_response = None
        self.latest_performance_report = None
        self.latest_motivation_state = None
        self.active_cognitive_directive = None # For directives influencing emotion

        # Track goal-related successes/failures for emotional impact
        self.goal_success_tracker = {} # {goal_id: {'successes': X, 'failures': Y}}

        # --- Publishers ---
        # Publishes the robot's current emotional state.
        self.pub_emotion_state = rospy.Publisher('/emotion_state', EmotionState, queue_size=10)
        # Publishes CognitiveDirectives for other nodes (e.g., Self-Correction for emotional dysregulation).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        rospy.Subscriber('/sensory_qualia', SensoryQualia, self.sensory_qualia_callback)
        rospy.Subscriber('/interaction_request', String, self.interaction_request_callback) # Expecting stringified JSON
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic emotion evaluation and publishing ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_publish_emotion)

        rospy.loginfo(f"{self.node_name}: Robot begins to feel.")

    # --- Callbacks for input data ---
    def sensory_qualia_callback(self, msg):
        """
        Callback for SensoryQualia. Processed sensory input can trigger emotional responses.
        Example: Pleasant sounds, jarring noises.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'qualia_type': ('none', 'qualia_type'),
            'measurement_value': (0.0, 'measurement_value'), 'salience_score': (0.0, 'salience_score'),
            'sentiment_score': (0.0, 'sentiment_score') # Assumes SensoryQualia can have sentiment
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        self.latest_sensory_qualia = data
        if data.get('salience_score', 0.0) > 0.4: # Only consider salient sensory inputs
            self.sensory_sentiment_history.append(data.get('sentiment_score', 0.0))
            rospy.logdebug(f"{self.node_name}: Received Salient Sensory Qualia. Sentiment: {data.get('sentiment_score', 'N/A'):.2f}.")

    def interaction_request_callback(self, msg):
        """
        Callback for InteractionRequest. User input sentiment impacts robot emotion.
        This uses `TextBlob` for sentiment analysis if an external NLP pipeline isn't available.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'request_type': ('text_input', 'request_type'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Assuming command_payload has a 'text' field or is directly the text
        user_text = data.get('command_payload', '')
        if isinstance(user_text, dict):
            user_text = user_text.get('text', '')

        user_sentiment = TextBlob(user_text).sentiment.polarity if user_text else 0.0
        
        self.latest_interaction_request = data
        self.user_sentiment_history.append(user_sentiment)
        rospy.logdebug(f"{self.node_name}: Received Interaction Request. User Sentiment: {user_sentiment:.2f}.")

    def internal_narrative_callback(self, msg):
        """
        Callback for InternalNarrative. Robot's internal thoughts can reflect and influence emotion.
        e.g., negative self-talk can lead to sadness, positive self-reflection to joy.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        self.latest_internal_narrative = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Internal Narrative. Sentiment: {self.latest_internal_narrative.get('sentiment', 'N/A'):.2f}.")

    def memory_response_callback(self, msg):
        """
        Callback for MemoryResponse. Retrieved memories can have emotional valence,
        triggering or reinforcing current emotions.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('memories_json'), str):
            try: data['memories'] = json.loads(data['memories_json'])
            except json.JSONDecodeError: data['memories'] = []
        
        if data.get('response_code') == 0 and data.get('memories'):
            # Aggregate sentiment from retrieved memories
            memory_sentiments = [m.get('sentiment', 0.0) for m in data['memories']]
            if memory_sentiments:
                avg_memory_sentiment = sum(memory_sentiments) / len(memory_sentiments)
                self.latest_memory_response = {'avg_sentiment': avg_memory_sentiment, 'data': data}
                rospy.logdebug(f"{self.node_name}: Received Memory Response. Avg Sentiment: {avg_memory_sentiment:.2f}.")
        else:
            self.latest_memory_response = None # No useful memories or error
        
        rospy.logdebug(f"{self.node_name}: Received Memory Response.")

    def performance_report_callback(self, msg):
        """
        Callback for PerformanceReport. System performance (success/failure) impacts emotion.
        NEW: Tracks success/failure for probabilistic transitions.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        self.latest_performance_report = data
        
        # Track success/failure for consistency check
        is_successful_performance = data.get('overall_score', 1.0) >= 0.7 and not data.get('suboptimal_flag', True)
        self.performance_success_history.append(is_successful_performance)
        rospy.logdebug(f"{self.node_name}: Received Performance Report. Overall Score: {data.get('overall_score', 'N/A'):.2f}.")

    def motivation_state_callback(self, msg):
        """
        Callback for MotivationState. Dominant goal and progress influences emotional drive.
        NEW: Specifically tracks goal success/failure for more nuanced emotional responses.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_goals_json'), str):
            try: data['active_goals'] = json.loads(data['active_goals_json'])
            except json.JSONDecodeError: data['active_goals'] = []
        
        # Check for goal completion/failure from active goals
        if self.latest_motivation_state: # Compare with previous state
            prev_active_goals = self.latest_motivation_state.get('active_goals', [])
            current_active_goals = data.get('active_goals', [])

            for goal in prev_active_goals:
                goal_id = goal.get('goal_id')
                if goal_id and goal_id not in [g.get('goal_id') for g in current_active_goals]:
                    # This goal is no longer active, assume completion or failure
                    is_completed = goal.get('status') == 'completed' # Check final status from old goal
                    if goal_id not in self.goal_success_tracker:
                        self.goal_success_tracker[goal_id] = {'successes': 0, 'failures': 0}
                    
                    if is_completed:
                        self.goal_success_tracker[goal_id]['successes'] += 1
                        rospy.loginfo(f"{self.node_name}: Goal '{goal_id}' completed successfully. Emotional boost.")
                    else:
                        self.goal_success_tracker[goal_id]['failures'] += 1
                        rospy.loginfo(f"{self.node_name}: Goal '{goal_id}' failed. Emotional dip.")
                        
        self.latest_motivation_state = data
        rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {self.latest_motivation_state.get('dominant_goal_id', 'N/A')}.")


    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can directly set or regulate emotional state.
        Example: 'SetMood', 'AdjustEmotionalResponse'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'SetMood':
                    target_mood = payload.get('mood')
                    target_intensity = payload.get('intensity', 1.0)
                    if target_mood and target_intensity is not None:
                        self.active_cognitive_directive = {
                            'type': 'set_mood',
                            'mood': target_mood,
                            'intensity': target_intensity,
                            'start_time': rospy.get_time(),
                            'duration_s': payload.get('duration_s', 5) # Default duration for direct mood set
                        }
                        rospy.loginfo(f"{self.node_name}: Received directive to set mood: '{target_mood}' at {target_intensity:.2f}.")
                elif directive_type == 'AdjustEmotionalResponse':
                    adjustment_type = payload.get('adjustment_type')
                    severity = payload.get('severity', 0.5)
                    self.active_cognitive_directive = {
                        'type': 'adjust_response',
                        'adjustment_type': adjustment_type,
                        'severity': severity,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 15) # Default duration for adjustment
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to adjust emotional response: '{adjustment_type}'.")
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    # --- Core Emotion Logic ---
    def evaluate_and_publish_emotion(self, event):
        """
        Periodically evaluates various inputs to determine the robot's overall emotional state.
        NEW: Uses probabilistic transitions and incorporates performance/goal progress more deeply.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # Handle active cognitive directives for emotional regulation
        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if (current_time - directive['start_time']) < directive.get('duration_s', 0) or directive.get('duration_s', 0) == 0:
                # Directive is active
                if directive['type'] == 'set_mood':
                    self.current_mood = directive['mood']
                    self.current_mood_intensity = directive['intensity']
                    self.current_sentiment_score = 0.0 # Reset for simplicity, or map mood to sentiment
                    if self.current_mood in ['joyful', 'content', 'curious']: self.current_sentiment_score = self.current_mood_intensity * 0.8
                    elif self.current_mood in ['frustrated', 'distressed', 'concerned']: self.current_sentiment_score = -self.current_mood_intensity * 0.8
                    rospy.loginfo(f"{self.node_name}: Mood overridden by directive: '{self.current_mood}'.")
                elif directive['type'] == 'adjust_response':
                    if directive.get('adjustment_type') == 'stabilize_emotions':
                        # Reduce intensity of current strong emotions
                        self.current_mood_intensity = max(0.0, self.current_mood_intensity - directive.get('severity', 0.5) * 0.1)
                        if self.current_mood_intensity < self.significant_mood_threshold:
                            self.current_mood = 'neutral'
                            self.current_sentiment_score = 0.0
                        rospy.loginfo(f"{self.node_name}: Emotional response is being stabilized.")
                
                # If directive is duration-based and expired, clear it
                if directive.get('duration_s', 0) > 0 and (current_time - directive['start_time']) > directive.get('duration_s', 0):
                    rospy.loginfo(f"{self.node_name}: Emotional directive completed/expired.")
                    self.active_cognitive_directive = None
                
                self.publish_emotion_state(
                    timestamp,
                    self.current_mood,
                    self.current_sentiment_score,
                    self.current_mood_intensity
                )
                self.save_emotion_log(
                    timestamp,
                    self.current_mood,
                    self.current_sentiment_score,
                    self.current_mood_intensity,
                    json.dumps({"source": "directive_override", "directive": directive})
                )
                return # Skip further evaluation if directive is active and overrides


        # Calculate consolidated input scores
        input_sentiment_sum = 0.0
        input_intensity_sum = 0.0
        contributing_factors = {}

        # 1. Sensory Qualia
        if self.latest_sensory_qualia and self.latest_sensory_qualia.get('salience_score', 0.0) > 0.4:
            s_sentiment = self.latest_sensory_qualia.get('sentiment_score', 0.0)
            input_sentiment_sum += s_sentiment * self.influence_factors['sensory_sentiment']
            input_intensity_sum += abs(s_sentiment) * self.influence_factors['sensory_sentiment']
            contributing_factors['sensory_qualia'] = {'sentiment': s_sentiment}
            self.latest_sensory_qualia = None # Consume

        # 2. User Interaction Request
        if self.latest_interaction_request:
            user_text = self.latest_interaction_request.get('command_payload', '')
            if isinstance(user_text, dict): user_text = user_text.get('text', '')
            user_sentiment = TextBlob(user_text).sentiment.polarity if user_text else 0.0
            input_sentiment_sum += user_sentiment * self.influence_factors['user_sentiment']
            input_intensity_sum += abs(user_sentiment) * self.influence_factors['user_sentiment']
            contributing_factors['user_interaction'] = {'sentiment': user_sentiment}
            self.latest_interaction_request = None # Consume

        # 3. Internal Narrative
        if self.latest_internal_narrative:
            n_sentiment = self.latest_internal_narrative.get('sentiment', 0.0)
            input_sentiment_sum += n_sentiment * self.influence_factors['narrative_reflection']
            input_intensity_sum += abs(n_sentiment) * self.influence_factors['narrative_reflection']
            contributing_factors['internal_narrative'] = {'sentiment': n_sentiment}
            self.latest_internal_narrative = None # Consume

        # 4. Memory Response
        if self.latest_memory_response:
            mem_sentiment = self.latest_memory_response.get('avg_sentiment', 0.0)
            input_sentiment_sum += mem_sentiment * self.influence_factors['memory_valence']
            input_intensity_sum += abs(mem_sentiment) * self.influence_factors['memory_valence']
            contributing_factors['memory_response'] = {'sentiment': mem_sentiment}
            self.latest_memory_response = None # Consume

        # 5. Performance Report (Significant impact on mood)
        if self.latest_performance_report:
            p_score = self.latest_performance_report.get('overall_score', 1.0)
            p_suboptimal = self.latest_performance_report.get('suboptimal_flag', False)
            
            performance_sentiment = 0.0
            if p_score >= 0.8 and not p_suboptimal: performance_sentiment = 1.0 # Good performance
            elif p_score < 0.5 or p_suboptimal: performance_sentiment = -1.0 # Poor performance
            
            input_sentiment_sum += performance_sentiment * self.influence_factors['performance_outcome']
            input_intensity_sum += abs(performance_sentiment) * self.influence_factors['performance_outcome']
            contributing_factors['performance_report'] = {'score': p_score, 'suboptimal': p_suboptimal}
            self.latest_performance_report = None # Consume

        # 6. Motivation State (Goal Progress)
        if self.latest_motivation_state:
            # Check for significant goal successes/failures
            goal_impact_sentiment = 0.0
            total_goals_checked = 0
            for goal_id, stats in self.goal_success_tracker.items():
                if stats['successes'] > 0:
                    goal_impact_sentiment += stats['successes'] # Each success adds positive
                    total_goals_checked += stats['successes']
                if stats['failures'] > 0:
                    goal_impact_sentiment -= stats['failures'] # Each failure adds negative
                    total_goals_checked += stats['failures']
            
            if total_goals_checked > 0:
                # Normalize goal impact sentiment
                goal_impact_sentiment = max(-1.0, min(1.0, goal_impact_sentiment / total_goals_checked))
                input_sentiment_sum += goal_impact_sentiment * self.influence_factors['goal_progress']
                input_intensity_sum += abs(goal_impact_sentiment) * self.influence_factors['goal_progress']
                contributing_factors['goal_progress'] = {'sentiment': goal_impact_sentiment}
                self.goal_success_tracker.clear() # Clear after processing for current cycle
            self.latest_motivation_state = None # Consume


        # Update current sentiment and intensity based on accumulated inputs
        # Normalizing total sum based on number of active factors, or a fixed denominator
        total_influence_sum = sum(self.influence_factors.values()) # Sum of all weights
        if total_influence_sum > 0:
            self.current_sentiment_score = input_sentiment_sum / total_influence_sum
            self.current_mood_intensity = input_intensity_sum / total_influence_sum
        else:
            self.current_sentiment_score = 0.0
            self.current_mood_intensity = 0.0


        # Apply decay to current mood intensity
        time_since_last_update = current_time - self.last_mood_update_time
        if time_since_last_update > 0:
            decay_amount = self.emotion_decay_rate * (time_since_last_update / self.evaluation_interval)
            # Use decay multiplier specific to current mood (faster decay for intense moods)
            current_mood_decay_mult = self.mood_states.get(self.current_mood, {}).get('decay_multiplier', 1.0)
            decay_amount *= current_mood_decay_mult
            
            self.current_mood_intensity = max(0.0, self.current_mood_intensity - decay_amount)

        self.last_mood_update_time = current_time


        # NEW: Probabilistic Mood Transition
        new_mood = self.current_mood
        highest_prob = 0.0

        # Calculate consistency scores
        pos_sensory_consistency = self._calculate_consistency(self.sensory_sentiment_history, is_positive=True)
        neg_sensory_consistency = self._calculate_consistency(self.sensory_sentiment_history, is_positive=False)
        pos_user_consistency = self._calculate_consistency(self.user_sentiment_history, is_positive=True)
        neg_user_consistency = self._calculate_consistency(self.user_sentiment_history, is_positive=False)
        overall_performance_consistency = self._calculate_performance_consistency()
        
        # Determine current dissonance from internal narrative (simple simulation)
        dissonance_score = 0.0
        if self.latest_internal_narrative and "conflict" in self.latest_internal_narrative.get('main_theme', '').lower():
            dissonance_score = self.latest_internal_narrative.get('salience_score', 0.0)
        
        for mood_name, mood_props in self.mood_states.items():
            # Base probability to transition to this mood
            prob = mood_props['base_prob']
            
            # Adjust probability based on overall sentiment score
            if mood_name in ['joyful', 'content', 'curious']:
                prob += max(0, self.current_sentiment_score) * 0.5 # Positive sentiment boosts positive moods
                prob += pos_sensory_consistency * self.mood_transition_weights['positive_input_consistency']
                prob += pos_user_consistency * self.mood_transition_weights['positive_input_consistency']
                prob += overall_performance_consistency * self.mood_transition_weights['performance_stability'] # Good performance
                
            elif mood_name in ['concerned', 'frustrated', 'distressed']:
                prob += abs(min(0, self.current_sentiment_score)) * 0.5 # Negative sentiment boosts negative moods
                prob += neg_sensory_consistency * self.mood_transition_weights['negative_input_consistency']
                prob += neg_user_consistency * self.mood_transition_weights['negative_input_consistency']
                prob += (1.0 - overall_performance_consistency) * self.mood_transition_weights['performance_stability'] # Bad performance
                prob += dissonance_score * self.mood_transition_weights['dissonance_factor'] # Dissonance
            
            # Also consider goal progress
            if self.latest_motivation_state:
                dominant_goal_id = self.latest_motivation_state.get('dominant_goal_id')
                # If current mood aligns with goal progress (or lack thereof)
                if 'joyful' in mood_name and dominant_goal_id != 'none' and self.latest_motivation_state.get('overall_drive_level', 0.0) > 0.8:
                    prob += self.mood_transition_weights['goal_success_rate'] * 0.2
                if 'frustrated' in mood_name and dominant_goal_id != 'none' and self.latest_motivation_state.get('overall_drive_level', 0.0) < 0.3:
                    prob += self.mood_transition_weights['goal_success_rate'] * 0.2
            
            # Finally, check if the current sentiment score passes the mood's specific threshold
            if mood_name == 'neutral':
                if abs(self.current_sentiment_score) < mood_props['threshold']:
                    prob += 0.5 # Stronger tendency to return to neutral if overall sentiment is low
            elif mood_name in ['joyful', 'content', 'curious']:
                if self.current_sentiment_score >= mood_props['threshold']:
                    prob += self.current_sentiment_score * 0.5 # The higher the sentiment, the stronger the pull
            elif mood_name in ['concerned', 'frustrated', 'distressed']:
                if self.current_sentiment_score <= mood_props['threshold']:
                    prob += abs(self.current_sentiment_score) * 0.5 # The lower (more negative) the sentiment, the stronger the pull


            # Add a small random component to simulate natural variability
            prob += random.uniform(-0.01, 0.01)

            if prob > highest_prob:
                highest_prob = prob
                new_mood = mood_name
        
        # Only transition if intensity is significant, or if moving to neutral (which has low intensity)
        if self.current_mood_intensity >= self.significant_mood_threshold or new_mood == 'neutral':
            self.current_mood = new_mood
        elif self.current_mood_intensity < self.significant_mood_threshold and self.current_mood != 'neutral':
            # If intensity is too low for current mood, transition to neutral
            self.current_mood = 'neutral'
            self.current_sentiment_score = 0.0 # Reset for neutral
            self.current_mood_intensity = 0.0 # Reset for neutral

        # Ensure intensity matches mood if it was set explicitly
        if self.current_mood == 'neutral':
            self.current_mood_intensity = min(0.1, self.current_mood_intensity) # Keep intensity low for neutral


        # Clamp final values
        self.current_sentiment_score = max(-1.0, min(1.0, self.current_sentiment_score))
        self.current_mood_intensity = max(0.0, min(1.0, self.current_mood_intensity))


        # Log and publish emotion state
        self.save_emotion_log(
            timestamp,
            self.current_mood,
            self.current_sentiment_score,
            self.current_mood_intensity,
            json.dumps(contributing_factors)
        )
        self.publish_emotion_state(
            timestamp,
            self.current_mood,
            self.current_sentiment_score,
            self.current_mood_intensity
        )

        rospy.loginfo(f"{self.node_name}: Current Emotion: '{self.current_mood}' (Sentiment: {self.current_sentiment_score:.2f}, Intensity: {self.current_mood_intensity:.2f}).")
        
        # If the robot enters a distressed or frustrated state, issue a self-correction directive
        if self.current_mood in ['distressed', 'frustrated'] and self.current_mood_intensity > 0.6:
            self._issue_cognitive_directive_to_node(
                directive_type='EmotionalDysregulationDetected',
                target_node='/self_correction_node',
                reason=f"Robot is {self.current_mood} with intensity {self.current_mood_intensity:.2f}. Needs emotional regulation.",
                payload_data={"mood": self.current_mood, "intensity": self.current_mood_intensity}
            )

    def _calculate_consistency(self, history_deque, is_positive=True):
        """
        Calculates the consistency of sentiment/outcome in a history deque.
        Returns a score from 0.0 to 1.0.
        """
        if not history_deque:
            return 0.0
        
        consistent_count = 0
        total_count = len(history_deque)

        for item in history_deque:
            if is_positive:
                if item > 0.0: # Positive sentiment
                    consistent_count += 1
            else:
                if item < 0.0: # Negative sentiment
                    consistent_count += 1
        
        return consistent_count / total_count

    def _calculate_performance_consistency(self):
        """
        Calculates how consistently good or bad recent performance has been.
        Returns 1.0 for consistently good, 0.0 for consistently bad, 0.5 for mixed.
        """
        if not self.performance_success_history:
            return 0.5 # Neutral if no history
        
        success_count = self.performance_success_history.count(True)
        failure_count = self.performance_success_history.count(False)
        total_count = len(self.performance_success_history)

        if total_count == 0:
            return 0.5

        if success_count == total_count: return 1.0 # All successes
        if failure_count == total_count: return 0.0 # All failures

        # Linear interpolation for mixed results
        return success_count / total_count

    # --- Database and Publishing Functions ---
    def save_emotion_log(self, timestamp, mood, sentiment_score, mood_intensity, contributing_factors_json):
        """Saves an emotion state entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO emotion_log (timestamp, mood, sentiment_score, mood_intensity, contributing_factors)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, mood, sentiment_score, mood_intensity, contributing_factors_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved emotion log (Mood: {mood}, Intensity: {mood_intensity:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save emotion log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_emotion_log: {e}")

    def publish_emotion_state(self, timestamp, mood, sentiment_score, mood_intensity):
        """Publishes the robot's current emotional state on the '/emotion_state' topic."""
        try:
            if isinstance(EmotionState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'mood': mood,
                    'sentiment_score': sentiment_score,
                    'mood_intensity': mood_intensity
                }
                self.pub_emotion_state.publish(json.dumps(state_data))
            else:
                emotion_state_msg = EmotionState()
                emotion_state_msg.timestamp = timestamp
                emotion_state_msg.mood = mood
                emotion_state_msg.sentiment_score = sentiment_score
                emotion_state_msg.mood_intensity = mood_intensity
                self.pub_emotion_state.publish(emotion_state_msg)

            rospy.logdebug(f"{self.node_name}: Published emotion state: {mood}.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish emotion state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': self.current_mood, # Robot's current mood
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "mood_context": self.current_mood})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Emotion Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = EmotionNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

8. Updated Sensory Qualia Node with Probabilistic Reasoning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Still used sparingly for minimal, unpredictable noise

from std_msgs.msg import String, Float32 # Assuming Float32 for simple sensor data inputs

# Updated imports for custom messages:
try:
    from sentience.msg import (
        SensoryQualia,          # Output: Processed sensory data with qualia attributes
        AttentionState,         # Input: Robot's current attention focus (influences qualia processing)
        CognitiveDirective,     # Input: Directives for sensor recalibration or focused scanning
        ActionExecutionResult   # NEW: Input: Feedback on action outcomes for learning
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Sensory Qualia Node.")
    SensoryQualia = String # Fallback for publishing
    AttentionState = String
    CognitiveDirective = String
    ActionExecutionResult = String # NEW
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class SensoryQualiaNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('sensory_qualia_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging processed qualia and learned weights.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/sensory_qualia_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node processes raw sensor data.
        self.processing_interval = rospy.get_param('~processing_interval', 0.5) # Process every 0.5 seconds
        
        # Threshold for attention priority to significantly boost qualia salience.
        self.attention_boost_threshold = rospy.get_param('~attention_boost_threshold', 0.6)
        
        # Weights for different qualia types influencing overall salience or utility.
        # These will now be dynamically learned.
        self.qualia_impact_weights = rospy.get_param('~qualia_impact_weights', {
            'visual': 0.8,
            'auditory': 0.7,
            'thermal': 0.5,
            'tactile': 0.6,
            'other': 0.4 # For unclassified sensory inputs
        })

        # NEW: Adaptive Learning Parameters for Qualia Impact Weights
        self.learning_rate = rospy.get_param('~learning_rate', 0.01) # How quickly weights adapt
        self.min_weight = rospy.get_param('~min_weight', 0.1)
        self.max_weight = rospy.get_param('~max_weight', 1.0)
        
        # NEW: Simulated Environmental Impact Map for Probabilistic Qualia Generation
        # Maps hypothetical environmental conditions (derived from raw sensor data)
        # to expected qualia characteristics (base salience, sentiment bias).
        self.simulated_environmental_impact_map = rospy.get_param('~simulated_environmental_impact_map', {
            'high_temp': {'base_salience': 0.7, 'sentiment_bias': -0.3, 'qualia_type': 'thermal'},
            'low_temp': {'base_salience': 0.6, 'sentiment_bias': -0.2, 'qualia_type': 'thermal'},
            'loud_noise': {'base_salience': 0.9, 'sentiment_bias': -0.5, 'qualia_type': 'auditory'},
            'low_light': {'base_salience': 0.6, 'sentiment_bias': -0.1, 'qualia_type': 'visual'},
            'normal': {'base_salience': 0.2, 'sentiment_bias': 0.1, 'qualia_type': 'visual'} # Default
        })
        self.temp_threshold_high = rospy.get_param('~temp_threshold_high', 30.0)
        self.temp_threshold_low = rospy.get_param('~temp_threshold_low', 15.0)
        self.audio_threshold_loud = rospy.get_param('~audio_threshold_loud', 70.0) # dB
        self.light_threshold_low = rospy.get_param('~light_threshold_low', 100.0) # lux


        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'qualia_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS qualia_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                qualia_type TEXT,           -- e.g., 'visual', 'auditory', 'thermal'
                measurement_value REAL,     -- The raw sensor value
                salience_score REAL,        -- Perceived salience (0.0 to 1.0)
                sentiment_score REAL,       -- Emotional valence (e.g., -1.0 to 1.0)
                sensor_id TEXT,             -- Original sensor ID
                object_id TEXT,             -- Optional: object ID if identified
                contributing_factors TEXT   -- JSON snapshot of factors influencing qualia
            )
        ''')
        # Create table for learned qualia impact weights
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_qualia_impact_weights (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                qualia_type TEXT UNIQUE,
                weight_value REAL
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_qualia_timestamp ON qualia_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # Load learned weights from DB or use defaults
        self._load_qualia_impact_weights()

        # --- Internal State ---
        # Latest raw sensor data (retain values between processing cycles)
        self.latest_raw_temperature = 25.0 # Default Celsius
        self.latest_raw_light = 500.0      # Default Lux
        self.latest_raw_audio_level = 40.0 # Default dB
        self.latest_raw_vibration = 0.0    # Default (e.g., accelerometer reading)
        self.latest_raw_proximity = 1.0    # Default (e.g., 1.0 = clear, 0.0 = obstructed)

        # Timestamps for last received raw data (important for decay or lack of updates)
        self.last_temp_ts = rospy.get_time()
        self.last_light_ts = rospy.get_time()
        self.last_audio_ts = rospy.get_time()
        self.last_vibration_ts = rospy.get_time()
        self.last_proximity_ts = rospy.get_time()

        self.latest_attention_state = None
        self.active_cognitive_directive = None # For directives influencing sensing

        # Track the qualia that led to the last executed action for learning feedback
        self.last_published_qualia_for_action = None
        self.latest_action_execution_result = None # NEW

        # --- Publishers ---
        # Publishes processed sensory data with qualia attributes.
        self.pub_sensory_qualia = rospy.Publisher('/sensory_qualia', SensoryQualia, queue_size=10)
        # Publishes CognitiveDirectives back to other nodes (e.g., to Attention for re-focus)
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers (Simulating raw sensor inputs from robot hardware) ---
        rospy.Subscriber('/raw_sensors/temperature', Float32, self.raw_temperature_callback)
        rospy.Subscriber('/raw_sensors/light', Float32, self.raw_light_callback)
        rospy.Subscriber('/raw_sensors/audio_level', Float32, self.raw_audio_level_callback)
        rospy.Subscriber('/raw_sensors/vibration', Float32, self.raw_vibration_callback)
        rospy.Subscriber('/raw_sensors/proximity', Float32, self.raw_proximity_callback)
        
        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/action_execution_result', ActionExecutionResult, self.action_execution_result_callback) # NEW

        # --- Timer for periodic processing of raw sensor data ---
        rospy.Timer(rospy.Duration(self.processing_interval), self.process_raw_sensor_data)

        rospy.loginfo(f"{self.node_name}: Robot processes raw sensations into qualia.")

    # --- Database Operations for Learned Qualia Impact Weights ---
    def _load_qualia_impact_weights(self):
        """Loads qualia impact weights from the database or initializes them."""
        try:
            self.cursor.execute('SELECT qualia_type, weight_value FROM learned_qualia_impact_weights')
            rows = self.cursor.fetchall()
            if rows:
                for q_type, value in rows:
                    if q_type in self.qualia_impact_weights: # Only load known qualia types
                        self.qualia_impact_weights[q_type] = value
                rospy.loginfo(f"{self.node_name}: Loaded learned qualia impact weights from DB.")
            else:
                self._save_qualia_impact_weights() # Save initial defaults if DB is empty
                rospy.loginfo(f"{self.node_name}: Initialized default qualia impact weights.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load qualia impact weights from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight loading: {e}")

    def _save_qualia_impact_weights(self):
        """Saves current qualia impact weights to the database."""
        timestamp = str(rospy.get_time())
        try:
            for q_type, value in self.qualia_impact_weights.items():
                self.cursor.execute('''
                    INSERT OR REPLACE INTO learned_qualia_impact_weights (timestamp, qualia_type, weight_value)
                    VALUES (?, ?, ?)
                ''', (timestamp, q_type, value))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved qualia impact weights to DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save qualia impact weights to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight saving: {e}")

    # --- Callbacks for raw sensor inputs (simulated) ---
    def raw_temperature_callback(self, msg):
        self.latest_raw_temperature = msg.data
        self.last_temp_ts = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Raw Temp: {self.latest_raw_temperature:.1f}C")

    def raw_light_callback(self, msg):
        self.latest_raw_light = msg.data
        self.last_light_ts = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Raw Light: {self.latest_raw_light:.1f} Lux")

    def raw_audio_level_callback(self, msg):
        self.latest_raw_audio_level = msg.data
        self.last_audio_ts = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Raw Audio: {self.latest_raw_audio_level:.1f} dB")

    def raw_vibration_callback(self, msg):
        self.latest_raw_vibration = msg.data
        self.last_vibration_ts = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Raw Vibration: {self.latest_raw_vibration:.2f}")

    def raw_proximity_callback(self, msg):
        self.latest_raw_proximity = msg.data
        self.last_proximity_ts = rospy.get_time()
        # rospy.logdebug(f"{self.node_name}: Raw Proximity: {self.latest_raw_proximity:.2f}")


    # --- Callbacks for input data from other nodes ---
    def attention_state_callback(self, msg):
        """
        Callback for AttentionState. Robot's current attention focus influences how sensory
        qualia are processed (e.g., boosting salience for focused sensors).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),
            'focus_target': ('none', 'focus_target'), 'priority_score': (0.0, 'priority_score')
        }
        self.latest_attention_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Attention State. Focus: {self.latest_attention_state.get('focus_target', 'N/A')}")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can trigger sensor recalibration or focused scanning.
        Example: 'RecalibrateSensor', 'FocusSensorScan'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'RecalibrateSensor':
                    sensor_id = payload.get('sensor_id')
                    calibration_factor = payload.get('calibration_factor', 1.0)
                    rospy.loginfo(f"{self.node_name}: Received directive to recalibrate sensor '{sensor_id}' by factor {calibration_factor:.2f}.")
                    self._recalibrate_sensor_interpretations(sensor_id, calibration_factor)
                elif directive_type == 'FocusSensorScan':
                    scan_type = payload.get('scan_type') # e.g., 'visual_scan', 'auditory_sweep'
                    duration_s = payload.get('duration_s', 5)
                    # This directive impacts processing, but doesn't necessarily block.
                    self.active_cognitive_directive = {
                        'type': 'focus_scan',
                        'scan_type': scan_type,
                        'duration_s': duration_s,
                        'start_time': rospy.get_time()
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to focus sensor scan: '{scan_type}'.")
                elif directive_type == 'RequestDetailedSensorData' or directive_type == 'RequestClarifyingSensorData': # From World Model Node
                    target_object_id = payload.get('target_object_id', 'none')
                    data_level = payload.get('data_level', 'normal')
                    self.active_cognitive_directive = {
                        'type': 'detailed_request',
                        'target_object_id': target_object_id,
                        'data_level': data_level,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 2)
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive for detailed sensor data for '{target_object_id}'.")

            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def action_execution_result_callback(self, msg): # NEW
        """
        Callback for ActionExecutionResult. Provides feedback for reinforcement learning on qualia impact weights.
        If an action associated with a specific qualia type (e.g., visual) succeeded, its weight increases.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'action_id': ('', 'action_id'),
            'execution_status': ('unknown', 'execution_status'), 'success_flag': (False, 'success_flag'),
            'initiating_qualia_type': (None, 'initiating_qualia_type') # Assume action includes this metadata
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        self.latest_action_execution_result = data
        rospy.logdebug(f"{self.node_name}: Received Action Execution Result. Status: {data.get('execution_status')}")


    # --- Core Qualia Processing Logic ---
    def process_raw_sensor_data(self, event):
        """
        Periodically processes raw sensor data, transforms it into qualia,
        and publishes the SensoryQualia message.
        NEW: Uses probabilistic models and adaptive weights for salience and sentiment.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # NEW: Provide feedback to learning mechanism based on previous action outcome
        if self.latest_action_execution_result and self.latest_action_execution_result.get('initiating_qualia_type'):
            outcome_is_success = self.latest_action_execution_result.get('success_flag', False)
            initiating_qualia_type = self.latest_action_execution_result.get('initiating_qualia_type')
            self._update_qualia_impact_weights(initiating_qualia_type, outcome_is_success)
            self.latest_action_execution_result = None # Consume after use

        # Check for active directives that influence sensor processing
        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if (current_time - directive['start_time']) > directive.get('duration_s', 0) and directive.get('duration_s', 0) != 0:
                rospy.loginfo(f"{self.node_name}: Sensor directive '{directive.get('type')}' completed/expired.")
                self.active_cognitive_directive = None
            else:
                rospy.loginfo(f"{self.node_name}: Active sensor directive: '{directive.get('type')}'.")
                # This directive can influence the processing below, e.g., boost specific qualia.


        # Define qualia to generate based on available raw data and environmental context
        qualia_candidates = []
        
        # Determine current environmental context (deterministic, based on raw sensor values)
        current_env_state = 'normal'
        if self.latest_raw_temperature > self.temp_threshold_high:
            current_env_state = 'high_temp'
        elif self.latest_raw_temperature < self.temp_threshold_low:
            current_env_state = 'low_temp'
        elif self.latest_raw_audio_level > self.audio_threshold_loud:
            current_env_state = 'loud_noise'
        elif self.latest_raw_light < self.light_threshold_low:
            current_env_state = 'low_light'
        
        env_impact = self.simulated_environmental_impact_map.get(current_env_state, self.simulated_environmental_impact_map['normal'])

        # Process each raw sensor data point into a qualia
        # 1. Temperature Qualia
        if self.latest_raw_temperature is not None:
            q_type = 'thermal'
            q_value = self.latest_raw_temperature
            
            # Base salience and sentiment from environmental map
            base_salience = env_impact.get('base_salience', 0.2)
            sentiment_bias = env_impact.get('sentiment_bias', 0.0)

            # Salience: Higher if closer to thresholds, boosted by its impact weight
            salience_score = base_salience + (abs(self.latest_raw_temperature - 25.0) / 20.0) * self.qualia_impact_weights[q_type]
            salience_score = min(1.0, salience_score)

            # Sentiment: Negative if too hot/cold, influenced by bias
            sentiment_score = 0.0
            if self.latest_raw_temperature > self.temp_threshold_high: sentiment_score = -0.8
            elif self.latest_raw_temperature < self.temp_threshold_low: sentiment_score = -0.5
            sentiment_score += sentiment_bias # Apply environmental bias

            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'temp_sensor', 'environment_temp',
                {'raw_value': self.latest_raw_temperature, 'env_state': current_env_state}
            ))
            # self.latest_raw_temperature = None # Consume after processing

        # 2. Light Qualia
        if self.latest_raw_light is not None:
            q_type = 'visual'
            q_value = self.latest_raw_light

            base_salience = env_impact.get('base_salience', 0.2)
            sentiment_bias = env_impact.get('sentiment_bias', 0.0)
            
            salience_score = base_salience + (1.0 - (self.latest_raw_light / 1000.0)) * self.qualia_impact_weights[q_type] # Higher salience for lower light
            salience_score = min(1.0, salience_score)

            sentiment_score = 0.0
            if self.latest_raw_light < self.light_threshold_low: sentiment_score = -0.3 # Negative for low light
            sentiment_score += sentiment_bias

            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'light_sensor', 'environment_light',
                {'raw_value': self.latest_raw_light, 'env_state': current_env_state}
            ))
            # self.latest_raw_light = None

        # 3. Audio Qualia
        if self.latest_raw_audio_level is not None:
            q_type = 'auditory'
            q_value = self.latest_raw_audio_level

            base_salience = env_impact.get('base_salience', 0.2)
            sentiment_bias = env_impact.get('sentiment_bias', 0.0)

            salience_score = base_salience + (self.latest_raw_audio_level / 100.0) * self.qualia_impact_weights[q_type] # Higher salience for louder
            salience_score = min(1.0, salience_score)

            sentiment_score = 0.0
            if self.latest_raw_audio_level > self.audio_threshold_loud: sentiment_score = -0.6 # Negative for loud
            sentiment_score += sentiment_bias
            
            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'audio_sensor', 'environment_audio',
                {'raw_value': self.latest_raw_audio_level, 'env_state': current_env_state}
            ))
            # self.latest_raw_audio_level = None

        # 4. Vibration Qualia (example, could be tactile or internal)
        if self.latest_raw_vibration is not None and self.latest_raw_vibration > 0.1: # Only if significant vibration
            q_type = 'tactile'
            q_value = self.latest_raw_vibration
            salience_score = self.latest_raw_vibration * 0.8 * self.qualia_impact_weights[q_type]
            sentiment_score = -0.4 if self.latest_raw_vibration > 0.5 else 0.0 # Negative for strong vibration
            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'vibration_sensor', 'robot_movement',
                {'raw_value': self.latest_raw_vibration, 'env_state': current_env_state}
            ))
            # self.latest_raw_vibration = None

        # 5. Proximity Qualia (example, could trigger 'obstacle detected')
        if self.latest_raw_proximity is not None and self.latest_raw_proximity < 0.5: # If close to an object
            q_type = 'visual' # Could be visual or tactile for proximity
            q_value = self.latest_raw_proximity
            salience_score = (1.0 - self.latest_raw_proximity) * 0.9 * self.qualia_impact_weights[q_type] # Higher salience for closer
            sentiment_score = -0.7 # Negative for obstacle
            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'proximity_sensor', 'obstacle_detected',
                {'raw_value': self.latest_raw_proximity, 'env_state': current_env_state}
            ))
            # self.latest_raw_proximity = None

        # Apply Attention State Influence
        if self.latest_attention_state and self.latest_attention_state.get('priority_score', 0.0) >= self.attention_boost_threshold:
            focus_target = self.latest_attention_state.get('focus_target', 'none')
            focus_type = self.latest_attention_state.get('focus_type', 'idle')

            for qualia_data in qualia_candidates:
                # If attention is focused on this sensor type or a related object
                if focus_target in qualia_data['sensor_id'] or \
                   (qualia_data['object_id'] and focus_target in qualia_data['object_id']) or \
                   (focus_type == 'anticipatory_user_interaction' and qualia_data['qualia_type'] == 'auditory'): # Example: listening for user
                    qualia_data['salience_score'] = min(1.0, qualia_data['salience_score'] + self.latest_attention_state.get('priority_score', 0.0) * 0.3)
                    if 'attention_boost' not in qualia_data['contributing_factors']:
                        qualia_data['contributing_factors']['attention_boost'] = {'target': focus_target, 'priority': self.latest_attention_state.get('priority_score')}
                    
                    rospy.logdebug(f"{self.node_name}: Qualia '{qualia_data['qualia_type']}' boosted by attention focus on '{focus_target}'.")

        # Apply Cognitive Directive Influence (e.g., focused scan requests)
        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if directive['type'] == 'focus_scan' and directive.get('scan_type'):
                scan_target_type = directive['scan_type'].replace('_scan', '') # e.g., 'visual_scan' -> 'visual'
                for qualia_data in qualia_candidates:
                    if qualia_data['qualia_type'] == scan_target_type:
                        qualia_data['salience_score'] = min(1.0, qualia_data['salience_score'] + random.uniform(0.1, 0.3)) # Boosted by directive
                        qualia_data['contributing_factors']['directive_boost'] = {'type': directive['type']}
                        rospy.logdebug(f"{self.node_name}: Qualia '{qualia_data['qualia_type']}' boosted by directive scan.")
            elif directive['type'] == 'detailed_request':
                 target_obj_id = directive.get('target_object_id')
                 for qualia_data in qualia_candidates:
                     if qualia_data.get('object_id') == target_obj_id:
                         qualia_data['salience_score'] = min(1.0, qualia_data['salience_score'] + random.uniform(0.2, 0.4)) # Boost for targeted data
                         qualia_data['contributing_factors']['directive_detailed_request'] = {'target_object': target_obj_id}
                         rospy.logdebug(f"{self.node_name}: Qualia '{qualia_data['qualia_type']}' boosted by detailed request for '{target_obj_id}'.")


        # Publish all generated qualia above a minimal salience threshold
        published_count = 0
        for qualia in qualia_candidates:
            if qualia['salience_score'] > 0.1: # Only publish if reasonably salient
                self.publish_sensory_qualia(
                    timestamp,
                    qualia['qualia_type'],
                    qualia['measurement_value'],
                    qualia['salience_score'],
                    qualia['sentiment_score'],
                    qualia['sensor_id'],
                    qualia['object_id'],
                    json.dumps(qualia['contributing_factors'])
                )
                self.save_qualia_log(
                    timestamp,
                    qualia['qualia_type'],
                    qualia['measurement_value'],
                    qualia['salience_score'],
                    qualia['sentiment_score'],
                    qualia['sensor_id'],
                    qualia['object_id'],
                    json.dumps(qualia['contributing_factors'])
                )
                published_count += 1
                # If this qualia is sufficiently salient and could trigger an action, store it for learning feedback
                if qualia['salience_score'] > 0.7:
                    self.last_published_qualia_for_action = qualia['qualia_type']

        rospy.loginfo(f"{self.node_name}: Processed raw sensor data. Published {published_count} qualia.")


    def _create_qualia_data(self, qualia_type, value, salience, sentiment, sensor_id, object_id=None, factors=None):
        """Helper to create a qualia data dictionary."""
        return {
            'qualia_type': qualia_type,
            'measurement_value': value,
            'salience_score': salience,
            'sentiment_score': sentiment,
            'sensor_id': sensor_id,
            'object_id': object_id,
            'contributing_factors': factors if factors is not None else {}
        }

    def _recalibrate_sensor_interpretations(self, sensor_id, calibration_factor):
        """
        Simulates recalibrating sensor interpretations based on a directive.
        This would adjust how raw values are mapped to qualia properties.
        For simulation, we'll log it and future processing might implicitly apply this.
        """
        # In a real system, this would modify internal parameters, e.g., thresholds, scaling factors.
        rospy.loginfo(f"{self.node_name}: Simulating recalibration for sensor '{sensor_id}' with factor {calibration_factor:.2f}. This would adjust future qualia generation from this sensor.")
        # For simplicity, we'll just acknowledge the recalibration. Actual impact would be in process_raw_sensor_data.


    def _update_qualia_impact_weights(self, qualia_type, outcome_is_success): # NEW
        """
        NEW: Adapts qualia impact weights based on the outcome of actions.
        If an action initiated by a certain qualia type succeeded, that qualia type's weight increases.
        """
        if qualia_type not in self.qualia_impact_weights:
            rospy.logwarn(f"{self.node_name}: Cannot learn for unknown qualia type: {qualia_type}.")
            return

        current_weight = self.qualia_impact_weights[qualia_type]
        
        # Calculate reward: Positive for success, negative for failure
        reward = 0.0
        if outcome_is_success:
            reward = 0.1 # Positive reward
        else:
            reward = -0.05 # Smaller negative reward

        # Simple update rule
        new_weight = current_weight + self.learning_rate * reward

        # Apply bounds to prevent weights from becoming too extreme
        new_weight = max(self.min_weight, min(self.max_weight, new_weight))

        if new_weight != current_weight:
            self.qualia_impact_weights[qualia_type] = new_weight
            self._save_qualia_impact_weights() # Persist the learned weight
            
            rospy.loginfo(f"{self.node_name}: Learned! Adjusted '{qualia_type}' impact weight to {new_weight:.3f} based on {'SUCCESS' if outcome_is_success else 'FAILURE'}.")


    # --- Database and Publishing Functions ---
    def save_qualia_log(self, timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors_json):
        """Saves a processed qualia entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO qualia_log (timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved qualia log (Type: {qualia_type}, Salience: {salience_score:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save qualia log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_qualia_log: {e}")

    def publish_sensory_qualia(self, timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors_json):
        """Publishes the processed sensory qualia on the '/sensory_qualia' topic."""
        try:
            # Parse contributing_factors_json if it's a string, for fallback message
            parsed_contributing_factors = json.loads(contributing_factors_json) if isinstance(contributing_factors_json, str) else contributing_factors_json

            if isinstance(SensoryQualia, type(String)): # Fallback to String message
                qualia_data = {
                    'timestamp': timestamp,
                    'qualia_type': qualia_type,
                    'measurement_value': measurement_value,
                    'salience_score': salience_score,
                    'sentiment_score': sentiment_score,
                    'sensor_id': sensor_id,
                    'object_id': object_id,
                    'contributing_factors': parsed_contributing_factors # Send as dict for JSON fallback
                }
                self.pub_sensory_qualia.publish(json.dumps(qualia_data))
            else:
                sensory_qualia_msg = SensoryQualia()
                sensory_qualia_msg.timestamp = timestamp
                sensory_qualia_msg.qualia_type = qualia_type
                sensory_qualia_msg.measurement_value = measurement_value
                sensory_qualia_msg.salience_score = salience_score
                sensory_qualia_msg.sentiment_score = sentiment_score
                sensory_qualia_msg.sensor_id = sensor_id
                sensory_qualia_msg.object_id = object_id if object_id else '' # ROS String cannot be None
                sensory_qualia_msg.contributing_factors_json = contributing_factors_json
                self.pub_sensory_qualia.publish(sensory_qualia_msg)

            rospy.logdebug(f"{self.node_name}: Published qualia '{qualia_type}' (Salience: {salience_score:.2f}).")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish sensory qualia: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'observant', # Sensory node typically observant
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "directive_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Sensory Qualia Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = SensoryQualiaNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

9. Updated Cognitive Control Node (Central Orchestrator)

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # For simulating tie-breaking or slight unpredictability in arbitration

from collections import deque

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        CognitiveControlState,  # Output: Robot's current overall cognitive state
        CognitiveDirective,     # Input: Directives from all other nodes; Output: Orchestrated directives
        AttentionState,         # Input: Current attention focus
        EmotionState,           # Input: Current emotional state
        MotivationState,        # Input: Current dominant goal
        PerformanceReport,      # Input: Overall system performance
        BodyAwarenessState,     # Input: Physical state (e.g., low battery, overheating)
        ValueDriftState,        # Input: Value adherence state
        WorldModelState         # Input: Consistency issues in world model
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Cognitive Control Node.")
    CognitiveControlState = String # Fallback for publishing
    CognitiveDirective = String
    AttentionState = String
    EmotionState = String
    MotivationState = String
    PerformanceReport = String
    BodyAwarenessState = String
    ValueDriftState = String
    WorldModelState = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class CognitiveControlNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('cognitive_control_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging control decisions and state transitions.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/cognitive_control_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node arbitrates cognitive flow and publishes state.
        self.arbitration_interval = rospy.get_param('~arbitration_interval', 0.5) # Fast arbitration
        
        # Priority weights for different types of incoming directives.
        # Higher weight means higher priority for arbitration.
        self.directive_type_priorities = rospy.get_param('~directive_type_priorities', {
            'Emergency': 1.0,           # Critical errors, safety
            'UrgentAction': 0.9,        # Immediate user commands, critical goal needs
            'SelfCorrection': 0.8,      # Fixing internal issues (bias, inconsistency)
            'GoalManagement': 0.7,      # Directives related to goal updates
            'AttentionManagement': 0.6, # Directing attention
            'ResourceAllocation': 0.5,  # Managing internal resources
            'Exploration': 0.4,         # Directives to explore new data
            'InformationRequest': 0.3,  # General data queries
            'SelfImprovement': 0.2,     # Long-term improvements
            'EmotionalRegulation': 0.1, # Emotional adjustments
            'Default': 0.05             # Fallback for unknown types
        })

        # Threshold for conflict detection (e.g., if two directives have high priority and are conflicting).
        self.conflict_threshold = rospy.get_param('~conflict_threshold', 0.7)

        # Mapping of dominant directives/states to overall cognitive modes.
        self.cognitive_mode_mapping = rospy.get_param('~cognitive_mode_mapping', {
            'idle': {'min_activity': 0.0, 'max_activity': 0.1, 'default_mood': 'neutral'},
            'exploring': {'min_activity': 0.1, 'max_activity': 0.4, 'keywords': ['explore', 'new_data', 'curiosity']},
            'problem_solving': {'min_activity': 0.4, 'max_activity': 0.8, 'keywords': ['solve', 'fix', 'inconsistency', 'dilemma', 'challenge']},
            'self_reflecting': {'min_activity': 0.3, 'max_activity': 0.6, 'keywords': ['reflect', 'audit', 'bias', 'value_drift', 'learn']},
            'critical_emergency': {'min_activity': 0.8, 'max_activity': 1.0, 'keywords': ['emergency', 'critical', 'danger', 'shutdown', 'power_shortage', 'overheating']}
        })


        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'cognitive_control_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS cognitive_control_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                current_mode TEXT,          -- The determined cognitive mode (e.g., 'idle', 'problem_solving')
                dominant_directive TEXT,    -- The directive that currently dominates control
                arbitration_outcome TEXT,   -- Summary of the arbitration process (e.g., 'resolved_conflict', 'prioritized_urgent')
                active_directives_json TEXT -- JSON snapshot of all active directives at that moment
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_control_timestamp ON cognitive_control_log (timestamp)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State ---
        # A deque to store incoming CognitiveDirectives to be processed in order of arrival (and then priority)
        self.incoming_directives_queue = deque()
        self.active_directives = {} # {directive_id: {directive_data, creation_time}}
        
        self.current_cognitive_mode = "idle"
        self.current_dominant_directive = "none"
        self.last_arbitration_time = rospy.get_time()

        # Latest states from other nodes for contextual decision making
        self.latest_attention_state = None
        self.latest_emotion_state = None
        self.latest_motivation_state = None
        self.latest_performance_report = None
        self.latest_body_awareness_state = None
        self.latest_value_drift_state = None
        self.latest_world_model_state = None


        # --- Publishers ---
        # Publishes the robot's current overall cognitive state.
        self.pub_cognitive_control_state = rospy.Publisher('/cognitive_control_state', CognitiveControlState, queue_size=10)
        # Publishes orchestrated CognitiveDirectives back to other nodes.
        self.pub_orchestrated_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        # Subscribe to CognitiveDirectives from ALL other nodes
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        # Subscribe to state outputs from key cognitive nodes
        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/body_awareness_state', String, self.body_awareness_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/value_drift_state', String, self.value_drift_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/world_model_state', String, self.world_model_state_callback) # Expecting stringified JSON

        # --- Timer for periodic arbitration ---
        rospy.Timer(rospy.Duration(self.arbitration_interval), self.arbitrate_cognitive_flow)

        rospy.loginfo(f"{self.node_name}: Robot's executive function is online.")

    # --- Callbacks for input data ---
    def cognitive_directive_callback(self, msg):
        """
        Callback for incoming CognitiveDirectives from any node.
        Adds directives to a queue for arbitration.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload'),
            'reason': ('', 'reason'), 'current_mood': ('neutral', 'current_mood'),
            'relevant_data_snapshot': ('{}', 'relevant_data_snapshot_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Give each incoming directive a unique ID if it doesn't have one
        directive_id = data.get('directive_id', f"dir_{int(rospy.get_time() * 1000)}_{random.randint(0, 9999)}")
        data['directive_id'] = directive_id # Add it to the data
        data['received_time'] = rospy.get_time() # Track when it was received

        # Filter out directives already being processed by this node, or self-directives if not needed
        if data.get('target_node') == self.node_name:
            rospy.logdebug(f"{self.node_name}: Received self-targeted directive '{data.get('directive_type')}'. Processing internally.")
            # Handle internal directives directly here if they control CCNode's behavior
            return
        
        # Add to queue only if not already active and not yet handled
        if directive_id not in self.active_directives:
            self.incoming_directives_queue.append(data)
            rospy.logdebug(f"{self.node_name}: Added directive '{data.get('directive_type')}' from '{data.get('source_node', 'unknown')}' to queue.")
        else:
            rospy.logdebug(f"{self.node_name}: Directive '{data.get('directive_type')}' already active/in queue. Skipping.")


    def attention_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),
            'focus_target': ('none', 'focus_target'), 'priority_score': (0.0, 'priority_score')
        }
        self.latest_attention_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Attention State. Focus: {self.latest_attention_state.get('focus_target', 'N/A')}")

    def emotion_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_emotion_state.get('mood', 'N/A')}")

    def motivation_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        self.latest_motivation_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {self.latest_motivation_state.get('dominant_goal_id', 'N/A')}.")

    def performance_report_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        self.latest_performance_report = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Performance Report. Score: {self.latest_performance_report.get('overall_score', 'N/A'):.2f}")

    def body_awareness_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_health_score': (1.0, 'overall_health_score'),
            'critical_condition_flag': (False, 'critical_condition_flag'), 'component_health_json': ('{}', 'component_health_json')
        }
        self.latest_body_awareness_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Body Awareness State. Health: {self.latest_body_awareness_state.get('overall_health_score', 'N/A'):.2f}")

    def value_drift_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_drift': (0.0, 'overall_drift'),
            'principle_adherence_json': ('{}', 'principle_adherence_json'), 'is_drift_detected': (False, 'is_drift_detected')
        }
        self.latest_value_drift_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Value Drift State. Drift: {self.latest_value_drift_state.get('overall_drift', 'N/A'):.2f}")

    def world_model_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'known_entities_json': ('[]', 'known_entities_json'),
            'environmental_properties_json': ('[]', 'environmental_properties_json'), 'consistency_issues_json': ('[]', 'consistency_issues_json')
        }
        self.latest_world_model_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received World Model State. Inconsistencies: {len(json.loads(self.latest_world_model_state.get('consistency_issues_json', '[]')))}")


    # --- Core Arbitration Logic ---
    def arbitrate_cognitive_flow(self, event):
        """
        The central arbitration function. It prioritizes incoming directives, resolves conflicts,
        and determines the robot's overall cognitive mode.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        rospy.loginfo(f"{self.node_name}: Starting cognitive flow arbitration cycle.")

        # Prune expired active directives
        directives_to_remove = []
        for dir_id, dir_data in self.active_directives.items():
            if dir_data.get('duration_s', 0) > 0 and (current_time - dir_data['start_time']) > dir_data['duration_s']:
                directives_to_remove.append(dir_id)
        for dir_id in directives_to_remove:
            del self.active_directives[dir_id]
            rospy.logdebug(f"{self.node_name}: Expired active directive '{dir_id}' ({self.active_directives[dir_id].get('directive_type')}).")


        # Process new incoming directives
        while self.incoming_directives_queue:
            directive = self.incoming_directives_queue.popleft()
            directive_id = directive['directive_id']
            # Store in active_directives. We'll decide which one to *act* on later.
            if directive_id not in self.active_directives: # Prevent duplicates if timing issues
                self.active_directives[directive_id] = directive
                self.active_directives[directive_id]['start_time'] = current_time # Mark when it became active in CCNode
                self.active_directives[directive_id]['duration_s'] = directive.get('duration_s', 0) # Keep duration if present
                rospy.logdebug(f"{self.node_name}: New directive '{directive.get('directive_type')}' from '{directive.get('source_node', 'unknown')}' is now active.")

        
        # Sort active directives by priority (highest first)
        # Calculate effective priority for each directive based on type and context
        prioritized_directives = sorted(
            self.active_directives.values(),
            key=lambda d: self._calculate_effective_directive_priority(d),
            reverse=True
        )

        dominant_directive = None
        arbitration_outcome = "no_dominant_directive"

        if prioritized_directives:
            dominant_directive = prioritized_directives[0]
            self.current_dominant_directive = dominant_directive.get('directive_type', 'unknown_directive')
            arbitration_outcome = f"prioritized_{dominant_directive.get('directive_type')}"
            rospy.loginfo(f"{self.node_name}: Dominant directive: '{self.current_dominant_directive}'.")

            # Check for conflicts among top directives
            if len(prioritized_directives) > 1:
                second_directive = prioritized_directives[1]
                if self._are_directives_conflicting(dominant_directive, second_directive):
                    rospy.logwarn(f"{self.node_name}: Conflict detected between '{dominant_directive.get('directive_type')}' and '{second_directive.get('directive_type')}'. Attempting to resolve.")
                    arbitration_outcome = self._resolve_conflict(dominant_directive, second_directive)
                    # The conflict resolution might change the dominant directive or issue new ones
                    # For now, let's assume the resolution reaffirms the highest priority one or modifies others.

            # Publish the dominant directive to its target node
            self._issue_orchestrated_directive(dominant_directive)
            rospy.logdebug(f"{self.node_name}: Orchestrating: Issued dominant directive to {dominant_directive.get('target_node')}.")
            
            # If the dominant directive implies a change in cognitive mode, initiate it
            self._determine_and_set_cognitive_mode(dominant_directive, prioritized_directives)
        else:
            self.current_dominant_directive = "none"
            # If no active directives, default to idle or self-maintenance mode
            self._determine_and_set_cognitive_mode(None, [])
            rospy.loginfo(f"{self.node_name}: No active directives. Robot is in '{self.current_cognitive_mode}' mode.")

        # Log control decision
        self.save_cognitive_control_log(
            timestamp,
            self.current_cognitive_mode,
            self.current_dominant_directive,
            arbitration_outcome,
            json.dumps(list(self.active_directives.values()), default=str) # Serialize all active directives
        )

        # Publish overall cognitive control state
        self.publish_cognitive_control_state(
            timestamp,
            self.current_cognitive_mode,
            self.current_dominant_directive,
            arbitration_outcome,
            len(self.active_directives)
        )
        rospy.loginfo(f"{self.node_name}: Cognitive Control State: Mode='{self.current_cognitive_mode}', Dominant Directive='{self.current_dominant_directive}'.")


    def _calculate_effective_directive_priority(self, directive):
        """
        Calculates the effective priority of a directive based on its type and current contextual states.
        """
        base_priority = self.directive_type_priorities.get(directive.get('directive_type', 'Default'), self.directive_type_priorities['Default'])
        
        # Boost based on mood of originating node (e.g., urgency from a 'concerned' node)
        current_mood_of_origin = directive.get('current_mood', 'neutral')
        if current_mood_of_origin == 'distressed' or current_mood_of_origin == 'frustrated':
            base_priority += 0.2 # Higher priority if source is distressed
        elif current_mood_of_origin == 'concerned':
            base_priority += 0.1

        # Boost if related to critical physical condition
        if self.latest_body_awareness_state and self.latest_body_awareness_state.get('critical_condition_flag', False):
            if "physical_constraint" in json.dumps(directive.get('command_payload', {})):
                base_priority += 0.3 # Significantly boost physical directives if critical
        
        # Boost if related to significant value drift
        if self.latest_value_drift_state and self.latest_value_drift_state.get('is_drift_detected', False):
            if "value_drift" in directive.get('reason', '').lower():
                base_priority += 0.2 # Boost directives related to ethical recalibration
        
        # Boost if high salience from Attention Node
        if self.latest_attention_state and \
           directive.get('target_node') == '/attention_node' and \
           self.latest_attention_state.get('priority_score', 0.0) > self.attention_boost_threshold:
           base_priority += self.latest_attention_state.get('priority_score', 0.0) * 0.1 # Boost if attention is already on it

        # Apply a small decay for older directives in the queue (reduces staleness)
        time_in_queue = rospy.get_time() - directive.get('received_time', rospy.get_time())
        base_priority -= (time_in_queue / 60.0) * 0.01 # 1% decay per minute in queue

        # Ensure priority is within reasonable bounds
        return max(0.0, min(1.0, base_priority))

    def _are_directives_conflicting(self, dir1, dir2):
        """
        Simulates conflict detection between two high-priority directives.
        Example conflicts:
        - "FocusAttention on X" vs "FocusAttention on Y"
        - "InitiateSelfCorrection" vs "ExecuteUserCommand" if self-correction needs full system resources.
        - "SeekChargingStation" vs "ExploreNewArea"
        """
        type1 = dir1.get('directive_type')
        type2 = dir2.get('directive_type')
        target1 = dir1.get('target_node')
        target2 = dir2.get('target_node')
        payload1 = json.dumps(dir1.get('command_payload', {}))
        payload2 = json.dumps(dir2.get('command_payload', {}))

        # Direct contradiction in targets
        if type1 == 'FocusAttention' and type2 == 'FocusAttention' and \
           payload1.get('focus_target') != payload2.get('focus_target'):
            return True
        
        # Resource contention (simplified)
        if (('InitiateSelfCorrection' in [type1, type2] and 'ExecuteAction' in [type1, type2]) or
            ('SeekChargingStation' in [type1, type2] and 'ExploreNewArea' in [type1, type2])):
            # And if they both demand high resources or are physically exclusive
            if (self._calculate_effective_directive_priority(dir1) > self.conflict_threshold and
                self._calculate_effective_directive_priority(dir2) > self.conflict_threshold):
                rospy.logwarn(f"{self.node_name}: Detected potential resource contention between {type1} and {type2}.")
                return True
        
        # Semantic conflict (simplified keyword check)
        if ("shutdown" in payload1 and "operate" in payload2) or \
           ("stop" in payload1 and "continue" in payload2):
            return True
        
        return False

    def _resolve_conflict(self, dominant_directive, conflicting_directive):
        """
        Simulates conflict resolution.
        Usually, the higher priority directive prevails. Lower priority might be delayed,
        modified, or an explicit directive might be issued to cancel it.
        """
        rospy.loginfo(f"{self.node_name}: Resolving conflict: Dominant '{dominant_directive.get('directive_type')}' vs Conflicting '{conflicting_directive.get('directive_type')}'.")
        
        # For simplicity, the higher priority directive always wins.
        # The conflicting directive will be either temporarily ignored or modified.
        
        # Option 1: Issue a directive to the conflicting node to pause/cancel
        # (This is more robust than just ignoring it internally in CCNode)
        self._issue_orchestrated_directive(
            directive_type='ConflictResolution',
            target_node=conflicting_directive.get('target_node'),
            command_payload={'action': 'pause_or_delay', 'original_directive_id': conflicting_directive.get('directive_id'), 'reason': f"Conflict with {dominant_directive.get('directive_type')}"},
            reason=f"Resolved conflict by prioritizing {dominant_directive.get('directive_type')}",
            source_node=self.node_name,
            current_mood='decisive'
        )
        
        # Option 2: Remove the conflicting directive from active_directives for this cycle
        # This makes sure it's not processed again immediately, but it might re-enter if not truly handled by its node.
        # This is a simpler simulation approach for immediate effect.
        if conflicting_directive.get('directive_id') in self.active_directives:
            rospy.logwarn(f"{self.node_name}: Temporarily removing conflicting directive '{conflicting_directive.get('directive_id')}' from active list.")
            del self.active_directives[conflicting_directive.get('directive_id')]

        return f"resolved_conflict_prioritizing_{dominant_directive.get('directive_type')}"


    def _determine_and_set_cognitive_mode(self, dominant_directive, all_active_directives):
        """
        Determines the robot's current overall cognitive mode based on dominant directives
        and overall system state.
        """
        new_mode = "idle" # Default if no strong signals

        # Highest priority: Emergency
        if self.latest_body_awareness_state and self.latest_body_awareness_state.get('critical_condition_flag', False):
            new_mode = "critical_emergency"
            rospy.loginfo(f"{self.node_name}: Entering CRITICAL_EMERGENCY mode due to physical state.")
        elif self.latest_performance_report and self.latest_performance_report.get('overall_score', 1.0) < 0.3:
             new_mode = "critical_emergency"
             rospy.loginfo(f"{self.node_name}: Entering CRITICAL_EMERGENCY mode due to extremely low performance.")

        # Next: Problem Solving (e.g., inconsistencies, bias, self-correction)
        elif self.latest_world_model_state and json.loads(self.latest_world_model_state.get('consistency_issues_json', '[]')):
            new_mode = "problem_solving"
            rospy.loginfo(f"{self.node_name}: Entering PROBLEM_SOLVING mode due to world model inconsistency.")
        elif self.latest_value_drift_state and self.latest_value_drift_state.get('is_drift_detected', False):
            new_mode = "self_reflecting" # Value drift leads to self-reflection mode
            rospy.loginfo(f"{self.node_name}: Entering SELF_REFLECTING mode due to value drift.")
        elif dominant_directive and dominant_directive.get('directive_type') in ['SelfCorrection', 'BiasMitigation', 'RecalibrateValues', 'AdjustLogicHeuristics']:
            new_mode = "problem_solving"
            rospy.loginfo(f"{self.node_name}: Entering PROBLEM_SOLVING mode due to self-correction directive.")
        
        # Then: Exploration (e.g., novelty, low confidence entities, user requests for new info)
        elif dominant_directive and dominant_directive.get('directive_type') in ['ExploreNewArea', 'RequestDiverseData', 'QueryWorldModel'] and \
             self.latest_attention_state and self.latest_attention_state.get('focus_type') == 'anticipatory_system':
            new_mode = "exploring"
            rospy.loginfo(f"{self.node_name}: Entering EXPLORING mode.")
        elif self.latest_attention_state and self.latest_attention_state.get('focus_type') == 'sensory_input' and \
             self.latest_attention_state.get('priority_score', 0.0) > 0.8: # Strong focus on novel sensory input
            new_mode = "exploring"
            rospy.loginfo(f"{self.node_name}: Entering EXPLORING mode due to novel sensory input.")


        # Finally, default to idle if no strong signals
        if new_mode == "idle":
            if self.latest_motivation_state and self.latest_motivation_state.get('overall_drive_level', 0.0) > 0.5:
                # If motivated but no clear task, perhaps just general 'active'
                new_mode = "active" # A generic active state
            
        self.current_cognitive_mode = new_mode

        # You could also issue directives to other nodes to enforce the new mode
        # E.g., if entering 'idle', tell Attention to lower overall priority.
        # Or if entering 'problem_solving', tell Motivation to prioritize problem-solving goals.
        # This is already implicitly handled as other nodes respond to directives.

    # --- Database and Publishing Functions ---
    def save_cognitive_control_log(self, timestamp, current_mode, dominant_directive, arbitration_outcome, active_directives_json):
        """Saves a cognitive control decision entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO cognitive_control_log (timestamp, current_mode, dominant_directive, arbitration_outcome, active_directives_json)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, current_mode, dominant_directive, arbitration_outcome, active_directives_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved control log (Mode: {current_mode}, Dominant: {dominant_directive}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save cognitive control log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_cognitive_control_log: {e}")

    def publish_cognitive_control_state(self, timestamp, current_mode, dominant_directive, arbitration_outcome, num_active_directives):
        """Publishes the robot's current overall cognitive state on the '/cognitive_control_state' topic."""
        try:
            if isinstance(CognitiveControlState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'current_mode': current_mode,
                    'dominant_directive': dominant_directive,
                    'arbitration_outcome': arbitration_outcome,
                    'num_active_directives': num_active_directives
                }
                self.pub_cognitive_control_state.publish(json.dumps(state_data))
            else:
                control_state_msg = CognitiveControlState()
                control_state_msg.timestamp = timestamp
                control_state_msg.current_mode = current_mode
                control_state_msg.dominant_directive = dominant_directive
                control_state_msg.arbitration_outcome = arbitration_outcome
                control_state_msg.num_active_directives = num_active_directives
                self.pub_cognitive_control_state.publish(control_state_msg)

            rospy.logdebug(f"{self.node_name}: Published cognitive control state: {current_mode}.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish cognitive control state: {e}")

    def _issue_orchestrated_directive(self, directive_data):
        """
        Helper to publish an orchestrated CognitiveDirective to its target node.
        This is the method Cognitive Control uses to enforce its decisions.
        """
        timestamp = str(rospy.get_time())
        try:
            # Add Cognitive Control as the source node for auditing purposes
            directive_data['source_node'] = self.node_name
            # Update timestamp to current time of orchestration
            directive_data['timestamp'] = timestamp
            
            # Serialize payload and relevant_data_snapshot if they are dicts/objects
            if isinstance(directive_data.get('command_payload'), dict):
                directive_data['command_payload'] = json.dumps(directive_data['command_payload'])
            if isinstance(directive_data.get('relevant_data_snapshot'), dict):
                directive_data['relevant_data_snapshot_json'] = json.dumps(directive_data['relevant_data_snapshot']) # Use _json suffix
            else:
                directive_data['relevant_data_snapshot_json'] = directive_data.get('relevant_data_snapshot', '{}') # Ensure it's string

            # Ensure current_mood is set for the directive if not already
            if 'current_mood' not in directive_data:
                directive_data['current_mood'] = self.latest_emotion_state.get('mood', 'neutral') if self.latest_emotion_state else 'neutral'

            # Publish as JSON string if using String fallback
            self.pub_orchestrated_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Orchestrated and re-published directive '{directive_data.get('directive_type')}' to '{directive_data.get('target_node')}'.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue orchestrated cognitive directive: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = CognitiveControlNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

10. Updated Experience Motivation Node with Proactive Planning

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # For simulating nuanced goal arbitration or planning where LLM isn't fully integrated

from collections import deque

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        MotivationState,        # Output: Robot's current motivation, dominant goal
        InteractionRequest,     # Input: User-defined goals
        EmotionState,           # Input: Emotional state (influences goal prioritization)
        AttentionState,         # Input: Attention focus (can highlight urgent goals)
        MemoryResponse,         # Input: Retrieved goal-relevant memories, historical success/failure
        PerformanceReport,      # Input: Overall system performance (feedback for goal progress)
        CognitiveDirective,     # Input: Directives for goal adjustment; Output: Directives for sub-goals/actions
        WorldModelState,        # NEW: Input: Current world state for goal-state differentials
        BodyAwarenessState      # NEW: Input: Physical state for goal feasibility
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Experience Motivation Node.")
    MotivationState = String # Fallback for publishing
    InteractionRequest = String
    EmotionState = String
    AttentionState = String
    MemoryResponse = String
    PerformanceReport = String
    CognitiveDirective = String
    WorldModelState = String # NEW
    BodyAwarenessState = String # NEW
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class ExperienceMotivationNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('experience_motivation_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for storing goals and motivational states.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/motivation_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates and publishes motivation state.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 2) # Every 2 seconds
        
        # Minimum drive level for a goal to be considered active.
        self.min_active_drive_level = rospy.get_param('~min_active_drive_level', 0.2)
        
        # Decay rate for goal drive if not reinforced.
        self.drive_decay_rate = rospy.get_param('~drive_decay_rate', 0.05) # 5% decay per interval

        # Thresholds for goal success/failure to trigger emotional/learning feedback
        self.goal_success_threshold = rospy.get_param('~goal_success_threshold', 0.8)
        self.goal_failure_threshold = rospy.get_param('~goal_failure_threshold', 0.3)

        # Learning parameters for goal prioritization (simple reinforcement)
        self.goal_learning_rate = rospy.get_param('~goal_learning_rate', 0.02)
        self.reward_success = rospy.get_param('~reward_success', 0.1)
        self.penalty_failure = rospy.get_param('~penalty_failure', -0.05)
        self.min_goal_priority = rospy.get_param('~min_goal_priority', 0.1)
        self.max_goal_priority = rospy.get_param('~max_goal_priority', 1.0)

        # NEW: Proactive Planning Parameters
        self.planning_interval = rospy.get_param('~planning_interval', 5.0) # How often to check for proactive planning
        self.goal_differential_threshold = rospy.get_param('~goal_differential_threshold', 0.3) # Difference between current and goal state to trigger planning
        self.subgoal_complexity_factor = rospy.get_param('~subgoal_complexity_factor', 0.5) # Influences duration/effort of subgoals


        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'goals' table if it doesn't exist.
        # Added 'current_priority', 'success_count', 'failure_count', 'last_feedback_time'
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS goals (
                goal_id TEXT PRIMARY KEY,       -- Unique ID for the goal
                timestamp TEXT,                 -- When the goal was created
                type TEXT,                      -- e.g., 'user_command', 'internal_drive', 'system_maintenance'
                description TEXT,               -- Natural language description
                target_state TEXT,              -- JSON string describing desired state (e.g., {"location": [x,y,z], "task_completed": true})
                initial_drive REAL,             -- Initial motivational strength (0.0 to 1.0)
                current_drive REAL,             -- Current decaying/reinforced drive
                status TEXT,                    -- 'active', 'completed', 'failed', 'paused'
                metadata TEXT,                  -- JSON string of additional context (e.g., user_id, source_node)
                current_priority REAL,          -- NEW: Dynamically learned priority
                success_count INTEGER DEFAULT 0,-- NEW: Number of times this goal type/instance succeeded
                failure_count INTEGER DEFAULT 0,-- NEW: Number of times this goal type/instance failed
                last_feedback_time REAL DEFAULT 0.0 -- NEW: Timestamp of last feedback for learning
            )
        ''')
        # Create 'goal_events' table to track progress and state changes
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS goal_events (
                event_id INTEGER PRIMARY KEY AUTOINCREMENT,
                goal_id TEXT,
                timestamp TEXT,
                event_type TEXT,                -- 'created', 'updated_progress', 'completed', 'failed', 're_prioritized'
                details TEXT,                   -- JSON string of event details
                FOREIGN KEY(goal_id) REFERENCES goals(goal_id)
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_goal_status ON goals (status)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_goal_priority ON goals (current_priority)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State ---
        self.active_goals_cache = {} # {goal_id: {data from db}}
        self._load_active_goals_to_cache() # Load active goals on startup

        self.latest_interaction_request = None
        self.latest_emotion_state = None
        self.latest_attention_state = None
        self.latest_memory_response = None
        self.latest_performance_report = None
        self.latest_world_model_state = None # NEW
        self.latest_body_awareness_state = None # NEW
        self.active_cognitive_directive = None # For directives influencing goals

        self.last_planning_check_time = rospy.get_time() # For proactive planning timer

        # --- Publishers ---
        # Publishes the robot's current motivation and dominant goal.
        self.pub_motivation_state = rospy.Publisher('/motivation_state', MotivationState, queue_size=10)
        # Publishes CognitiveDirectives for other nodes (e.g., ActionExecution, Self-Correction for goal-related issues).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback
        # Publishes MemoryRequest for goal-relevant historical data
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10)

        # --- Subscribers ---
        rospy.Subscriber('/interaction_request', String, self.interaction_request_callback) # Expecting stringified JSON
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/world_model_state', String, self.world_model_state_callback) # NEW
        rospy.Subscriber('/body_awareness_state', String, self.body_awareness_state_callback) # NEW

        # --- Timer for periodic motivation evaluation and publishing ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_publish_motivation)
        # --- Timer for proactive planning ---
        rospy.Timer(rospy.Duration(self.planning_interval), self.proactive_planning_check)

        rospy.loginfo(f"{self.node_name}: Robot seeks its purpose.")

    def _load_active_goals_to_cache(self):
        """Loads all active goals from the database into the cache."""
        try:
            self.cursor.execute('SELECT goal_id, timestamp, type, description, target_state, initial_drive, current_drive, status, metadata, current_priority, success_count, failure_count, last_feedback_time FROM goals WHERE status = "active"')
            rows = self.cursor.fetchall()
            for row in rows:
                goal_id, timestamp, g_type, desc, target_state_json, initial_drive, current_drive, status, metadata_json, current_priority, success_count, failure_count, last_feedback_time = row
                
                target_state = json.loads(target_state_json) if target_state_json else {}
                metadata = json.loads(metadata_json) if metadata_json else {}

                self.active_goals_cache[goal_id] = {
                    'goal_id': goal_id,
                    'timestamp': float(timestamp), # Convert to float for calculation
                    'type': g_type,
                    'description': desc,
                    'target_state': target_state,
                    'initial_drive': initial_drive,
                    'current_drive': current_drive,
                    'status': status,
                    'metadata': metadata,
                    'current_priority': current_priority if current_priority is not None else initial_drive, # Use initial drive if not set
                    'success_count': success_count,
                    'failure_count': failure_count,
                    'last_feedback_time': float(last_feedback_time) # Convert to float
                }
            rospy.loginfo(f"{self.node_name}: Loaded {len(self.active_goals_cache)} active goals into cache.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load active goals to cache from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during goal cache loading: {e}")


    # --- Callbacks for input data ---
    def interaction_request_callback(self, msg):
        """
        Callback for InteractionRequest. User-defined goals are created here.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'request_type': ('', 'request_type'), 'user_id': ('unknown', 'user_id'),
            'command_payload': ('{}', 'command_payload') # Expected to contain goal description or target state
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        request_type = data.get('request_type')
        if request_type == 'SetGoal' or request_type == 'ExecuteCommand':
            goal_description = data.get('command_payload', {}).get('text', '')
            target_state = data.get('command_payload', {}).get('target_state', {})
            initial_drive = data.get('command_payload', {}).get('urgency_score', 0.8) # User's urgency translates to initial drive

            if goal_description or target_state:
                self._add_goal(
                    g_type='user_command',
                    description=goal_description,
                    target_state=target_state,
                    initial_drive=initial_drive,
                    metadata={"user_id": data.get('user_id'), "request_id": data.get('request_id')}
                )
                rospy.loginfo(f"{self.node_name}: New user-defined goal received: '{goal_description}'.")
            else:
                rospy.logwarn(f"{self.node_name}: Received SetGoal/ExecuteCommand directive with no description or target_state.")
        self.latest_interaction_request = data # Keep for overall context

    def emotion_state_callback(self, msg):
        """
        Callback for EmotionState. Influences goal prioritization (e.g., distress might boost
        goals related to safety/comfort).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_emotion_state.get('mood', 'N/A')}")

    def attention_state_callback(self, msg):
        """
        Callback for AttentionState. Can highlight urgent goals (if attention is on a goal-relevant target).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),
            'focus_target': ('none', 'focus_target'), 'priority_score': (0.0, 'priority_score')
        }
        self.latest_attention_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Attention State. Focus: {self.latest_attention_state.get('focus_target', 'N/A')}")

    def memory_response_callback(self, msg):
        """
        Callback for MemoryResponse. Provides historical data for planning and feedback on goal success/failure.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('memories_json'), str):
            try: data['memories'] = json.loads(data['memories_json'])
            except json.JSONDecodeError: data['memories'] = []
        self.latest_memory_response = data
        rospy.logdebug(f"{self.node_name}: Received Memory Response. {len(data.get('memories', []))} memories retrieved for motivation.")

    def performance_report_callback(self, msg):
        """
        Callback for PerformanceReport. Overall system performance provides feedback
        on whether current goals are being met effectively.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        self.latest_performance_report = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Performance Report. Score: {self.latest_performance_report.get('overall_score', 'N/A'):.2f}")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can directly set, modify, or cancel goals.
        Example: 'SetGoal', 'AdjustGoalPriority', 'CancelGoal'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'SetGoal':
                    goal_id = payload.get('goal_id', f"sys_goal_{int(rospy.get_time() * 1000)}_{random.randint(0,999)}")
                    self._add_goal(
                        g_type=payload.get('goal_type', 'system_directive'),
                        description=payload.get('description', 'No description'),
                        target_state=payload.get('target_state', {}),
                        initial_drive=payload.get('drive_level', 0.7),
                        metadata={"source_directive_id": data.get('directive_id')}
                    )
                    rospy.loginfo(f"{self.node_name}: Received directive to set goal: '{payload.get('description', 'N/A')}'.")
                elif directive_type == 'AdjustGoalPriority':
                    goal_id = payload.get('goal_id')
                    adjustment = payload.get('adjustment_value')
                    if goal_id in self.active_goals_cache and adjustment is not None:
                        self._adjust_goal_priority_directly(goal_id, adjustment)
                        rospy.loginfo(f"{self.node_name}: Adjusted goal '{goal_id}' priority by {adjustment:.2f}.")
                elif directive_type == 'CancelGoal':
                    goal_id = payload.get('goal_id')
                    if goal_id in self.active_goals_cache:
                        self._update_goal_status(goal_id, 'failed', "Cancelled by directive.")
                        rospy.loginfo(f"{self.node_name}: Cancelled goal '{goal_id}' by directive.")
                elif directive_type == 'GoalCompletedSuccessfully': # From Action Execution or other nodes
                    goal_id = payload.get('goal_id')
                    if goal_id in self.active_goals_cache:
                        self._update_goal_status(goal_id, 'completed', "Completed successfully as reported by external node.", outcome_success=True)
                        rospy.loginfo(f"{self.node_name}: Goal '{goal_id}' marked as completed successfully by directive.")
                elif directive_type == 'GoalFailed': # From Action Execution or other nodes
                    goal_id = payload.get('goal_id')
                    reason = payload.get('reason', "Failed as reported by external node.")
                    if goal_id in self.active_goals_cache:
                        self._update_goal_status(goal_id, 'failed', reason, outcome_success=False)
                        rospy.loginfo(f"{self.node_name}: Goal '{goal_id}' marked as failed by directive.")
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def world_model_state_callback(self, msg): # NEW
        """
        Callback for WorldModelState. Provides current environmental state for goal-state differentials.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'known_entities_json': ('[]', 'known_entities_json'),
            'environmental_properties_json': ('[]', 'environmental_properties_json'), 'consistency_issues_json': ('[]', 'consistency_issues_json')
        }
        self.latest_world_model_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received World Model State.")

    def body_awareness_state_callback(self, msg): # NEW
        """
        Callback for BodyAwarenessState. Provides robot's physical state for goal feasibility checks.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_health_score': (1.0, 'overall_health_score'),
            'critical_condition_flag': (False, 'critical_condition_flag'), 'component_health_json': ('{}', 'component_health_json')
        }
        self.latest_body_awareness_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Body Awareness State.")


    # --- Goal Management ---
    def _add_goal(self, g_type, description, target_state, initial_drive, metadata):
        """Adds a new goal to the system."""
        goal_id = f"goal_{g_type}_{int(rospy.get_time() * 1000)}_{random.randint(0, 9999)}"
        timestamp_str = str(rospy.get_time())
        current_drive = initial_drive
        current_priority = initial_drive # Initial priority is same as initial drive

        try:
            target_state_json = json.dumps(target_state)
            metadata_json = json.dumps(metadata)

            self.cursor.execute('''
                INSERT INTO goals (goal_id, timestamp, type, description, target_state, initial_drive, current_drive, status, metadata, current_priority, success_count, failure_count, last_feedback_time)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (goal_id, timestamp_str, g_type, description, target_state_json, initial_drive,
                  current_drive, 'active', metadata_json, current_priority, 0, 0, 0.0))
            self.conn.commit()

            self.active_goals_cache[goal_id] = {
                'goal_id': goal_id, 'timestamp': float(timestamp_str), 'type': g_type, 'description': description,
                'target_state': target_state, 'initial_drive': initial_drive, 'current_drive': current_drive,
                'status': 'active', 'metadata': metadata, 'current_priority': current_priority,
                'success_count': 0, 'failure_count': 0, 'last_feedback_time': 0.0
            }

            self._log_goal_event(goal_id, 'created', {'description': description})
            rospy.loginfo(f"{self.node_name}: Goal '{goal_id}' added: '{description}'.")
            return goal_id
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to add goal: {e}")
            return None
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _add_goal: {e}")
            return None

    def _update_goal_status(self, goal_id, new_status, details, outcome_success=None):
        """Updates the status of a goal and logs an event. Also updates learning counts."""
        if goal_id not in self.active_goals_cache:
            rospy.logwarn(f"{self.node_name}: Attempted to update status of non-existent goal '{goal_id}'.")
            return

        current_time = rospy.get_time()
        goal = self.active_goals_cache[goal_id]
        old_status = goal['status']
        goal['status'] = new_status
        goal['current_drive'] = 0.0 # Reset drive for completed/failed goals

        event_details = {'old_status': old_status, 'new_status': new_status, 'details': details}
        self._log_goal_event(goal_id, new_status, event_details)

        # Update learning counts and priority if this is a final outcome
        if new_status in ['completed', 'failed'] and outcome_success is not None:
            if outcome_success:
                goal['success_count'] += 1
            else:
                goal['failure_count'] += 1
            goal['last_feedback_time'] = current_time
            self._learn_goal_priority(goal_id, outcome_success)
            rospy.loginfo(f"{self.node_name}: Goal '{goal_id}' {new_status}. Successes: {goal['success_count']}, Failures: {goal['failure_count']}.")
        
        # Remove from cache if not active
        if new_status != 'active':
            del self.active_goals_cache[goal_id]

        try:
            target_state_json = json.dumps(goal['target_state'])
            metadata_json = json.dumps(goal['metadata'])
            self.cursor.execute('''
                UPDATE goals
                SET current_drive = ?, status = ?, current_priority = ?, success_count = ?, failure_count = ?, last_feedback_time = ?
                WHERE goal_id = ?
            ''', (goal['current_drive'], goal['status'], goal['current_priority'], goal['success_count'], goal['failure_count'], goal['last_feedback_time'], goal_id))
            self.conn.commit()
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update goal status in DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _update_goal_status: {e}")

    def _adjust_goal_priority_directly(self, goal_id, adjustment_value):
        """Directly adjusts a goal's priority."""
        if goal_id not in self.active_goals_cache:
            rospy.logwarn(f"{self.node_name}: Attempted to adjust priority of non-existent goal '{goal_id}'.")
            return
        
        goal = self.active_goals_cache[goal_id]
        new_priority = goal['current_priority'] + adjustment_value
        goal['current_priority'] = max(self.min_goal_priority, min(self.max_goal_priority, new_priority))
        
        try:
            self.cursor.execute("UPDATE goals SET current_priority = ? WHERE goal_id = ?", (goal['current_priority'], goal_id))
            self.conn.commit()
            self._log_goal_event(goal_id, 're_prioritized', {'new_priority': goal['current_priority']})
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to adjust goal priority in DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _adjust_goal_priority_directly: {e}")

    def _log_goal_event(self, goal_id, event_type, details):
        """Logs an event related to a goal."""
        timestamp_str = str(rospy.get_time())
        try:
            details_json = json.dumps(details)
            self.cursor.execute('''
                INSERT INTO goal_events (goal_id, timestamp, event_type, details)
                VALUES (?, ?, ?, ?)
            ''', (goal_id, timestamp_str, event_type, details_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Logged goal event for '{goal_id}': {event_type}.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to log goal event: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _log_goal_event: {e}")

    def _learn_goal_priority(self, goal_id, outcome_success):
        """
        NEW: Adapts goal priority based on successful or failed completion.
        Goals that lead to success are reinforced; failures lead to a penalty.
        """
        goal = self.active_goals_cache.get(goal_id) # Already removed from cache if not active, so get from DB if needed
        if not goal:
            # If goal was completed/failed and then moved from cache, retrieve for learning
            self.cursor.execute("SELECT goal_id, current_priority, success_count, failure_count FROM goals WHERE goal_id = ?", (goal_id,))
            row = self.cursor.fetchone()
            if not row:
                rospy.logwarn(f"{self.node_name}: Goal '{goal_id}' not found for learning update.")
                return
            goal = {'goal_id': row[0], 'current_priority': row[1], 'success_count': row[2], 'failure_count': row[3]}
            
        current_priority = goal['current_priority']
        
        adjustment = 0.0
        if outcome_success:
            adjustment = self.reward_success
        else:
            adjustment = self.penalty_failure
        
        new_priority = current_priority + self.goal_learning_rate * adjustment
        new_priority = max(self.min_goal_priority, min(self.max_goal_priority, new_priority))
        
        goal['current_priority'] = new_priority
        # Update in DB, and if still active, update in cache too (but it's mostly for inactive goals here)
        try:
            self.cursor.execute("UPDATE goals SET current_priority = ? WHERE goal_id = ?", (new_priority, goal_id))
            self.conn.commit()
            rospy.loginfo(f"{self.node_name}: Learned! Priority for goal '{goal_id}' adjusted to {new_priority:.2f} based on {'SUCCESS' if outcome_success else 'FAILURE'}.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save learned goal priority to DB: {e}")


    # --- Core Motivation Logic ---
    def evaluate_and_publish_motivation(self, event):
        """
        Periodically evaluates active goals, calculates overall drive,
        and determines the dominant goal.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        goals_to_remove = []
        for goal_id, goal in list(self.active_goals_cache.items()):
            # Decay goal drive over time if not progressing or being reinforced
            time_since_last_feedback = current_time - goal['last_feedback_time']
            if time_since_last_feedback > self.evaluation_interval: # Only decay if no recent feedback
                decay_amount = self.drive_decay_rate * (time_since_last_feedback / self.evaluation_interval)
                goal['current_drive'] = max(0.0, goal['current_drive'] - decay_amount)
                
                # If drive drops too low, mark as failed
                if goal['current_drive'] < self.min_active_drive_level * 0.5:
                    self._update_goal_status(goal_id, 'failed', "Drive decayed below threshold.", outcome_success=False)
                    goals_to_remove.append(goal_id) # Mark for removal from cache
                    continue # Skip further processing for this goal

            # Re-evaluate priority based on internal states (Emotion, Attention)
            goal_priority_boost = 0.0
            factors = {}
            
            # Emotion influence: e.g., feeling distressed might boost safety/comfort goals
            if self.latest_emotion_state:
                mood = self.latest_emotion_state.get('mood', 'neutral').lower()
                mood_intensity = self.latest_emotion_state.get('mood_intensity', 0.0)
                if mood_intensity > self.latest_emotion_state.get('significant_mood_threshold', 0.3):
                    if mood in ['distressed', 'frustrated'] and ('safety' in goal['description'].lower() or 'maintenance' in goal['type']):
                        goal_priority_boost += mood_intensity * 0.2
                    elif mood in ['joyful', 'curious'] and ('explore' in goal['description'].lower() or 'new_knowledge' in goal['type']):
                        goal_priority_boost += mood_intensity * 0.1
                factors['emotion_mood'] = mood
            
            # Attention influence: if attention is focused on something related to this goal
            if self.latest_attention_state and self.latest_attention_state.get('priority_score', 0.0) > 0.5:
                attention_target = self.latest_attention_state.get('focus_target', 'none')
                if attention_target in goal['description'] or attention_target in goal['metadata'].get('user_id', ''):
                    goal_priority_boost += self.latest_attention_state.get('priority_score') * 0.1
                factors['attention_focus'] = attention_target
            
            # Update goal's current priority with contextual boosts (but don't save to DB here, only after full arbitration)
            goal['current_priority'] = max(self.min_goal_priority, min(self.max_goal_priority, goal['initial_drive'] + goal_priority_boost)) # Base + boost

        # Remove goals marked for removal
        for goal_id in goals_to_remove:
            del self.active_goals_cache[goal_id]

        # Determine dominant goal
        dominant_goal = None
        overall_drive_level = 0.0
        
        if self.active_goals_cache:
            # Sort active goals by current priority (including dynamic boosts)
            sorted_goals = sorted(self.active_goals_cache.values(), key=lambda g: g['current_priority'], reverse=True)
            dominant_goal = sorted_goals[0]
            
            # Sum current drives to get overall drive
            overall_drive_level = sum(g['current_drive'] for g in self.active_goals_cache.values())
            overall_drive_level = min(1.0, overall_drive_level) # Clamp at 1.0

            rospy.loginfo(f"{self.node_name}: Dominant Goal: '{dominant_goal['description']}' (Priority: {dominant_goal['current_priority']:.2f}).")
            
            # Issue directive to Action Execution Node to pursue the dominant goal
            self._issue_cognitive_directive_to_node(
                directive_type='PursueGoal',
                target_node='/action_execution_node', # The node responsible for executing actions
                reason=f"Dominant goal identified: {dominant_goal['description']}",
                payload_data={
                    "goal_id": dominant_goal['goal_id'],
                    "goal_description": dominant_goal['description'],
                    "target_state": dominant_goal['target_state'],
                    "priority": dominant_goal['current_priority']
                }
            )
        else:
            rospy.loginfo(f"{self.node_name}: No active goals. Overall drive is low.")

        # Publish motivation state
        active_goals_list_for_publish = [
            {
                'goal_id': g['goal_id'],
                'description': g['description'],
                'target_state': g['target_state'], # Assuming this is already dict/json
                'current_drive': g['current_drive'],
                'status': g['status'],
                'current_priority': g['current_priority'] # Include for transparency
            } for g in self.active_goals_cache.values()
        ]
        self.publish_motivation_state(
            timestamp,
            dominant_goal['goal_id'] if dominant_goal else 'none',
            overall_drive_level,
            json.dumps(active_goals_list_for_publish)
        )

        # Clear latest inputs after consumption
        self.latest_interaction_request = None
        self.latest_emotion_state = None
        self.latest_attention_state = None
        self.latest_memory_response = None
        self.latest_performance_report = None
        self.latest_world_model_state = None
        self.latest_body_awareness_state = None


    # --- NEW: Proactive Planning Logic ---
    def proactive_planning_check(self, event):
        """
        Periodically checks for active goals and, if a significant gap exists between
        the current state and the goal's target state, initiates a planning process
        by issuing sub-goals or directives to relevant nodes.
        """
        current_time = rospy.get_time()
        
        # Only perform proactive checks periodically
        if (current_time - self.last_planning_check_time) < self.planning_interval:
            return

        self.last_planning_check_time = current_time
        rospy.loginfo(f"{self.node_name}: Performing proactive planning checks for active goals...")

        if not self.active_goals_cache:
            rospy.logdebug(f"{self.node_name}: No active goals to plan for.")
            return

        for goal_id, goal_data in self.active_goals_cache.items():
            target_state = goal_data.get('target_state', {})
            goal_description = goal_data.get('description', 'unspecified goal')

            if not target_state: # Cannot plan if no clear target state
                rospy.logdebug(f"{self.node_name}: Goal '{goal_id}' has no defined target state for planning.")
                continue

            current_world_state_summary = {}
            if self.latest_world_model_state:
                # Extract relevant parts of world model for current state comparison
                known_entities = json.loads(self.latest_world_model_state.get('known_entities_json', '[]'))
                env_props = json.loads(self.latest_world_model_state.get('environmental_properties_json', '[]'))
                current_world_state_summary = {'entities': known_entities, 'environment': env_props}
            
            current_body_state_summary = {}
            if self.latest_body_awareness_state:
                current_body_state_summary = {
                    'overall_health': self.latest_body_awareness_state.get('overall_health_score', 1.0),
                    'critical_flag': self.latest_body_awareness_state.get('critical_condition_flag', False),
                    'component_health': json.loads(self.latest_body_awareness_state.get('component_health_json', '{}'))
                }

            # Simulate gap analysis between current state and target state
            differential_score, gap_description = self._analyze_goal_state_differential(
                goal_data, target_state, current_world_state_summary, current_body_state_summary
            )
            
            if differential_score > self.goal_differential_threshold:
                rospy.loginfo(f"{self.node_name}: Detected significant gap for goal '{goal_description}' (Differential: {differential_score:.2f}). Initiating planning.")
                
                # Retrieve historical planning data for this goal type
                self._issue_memory_request(
                    request_id=f"plan_history_{goal_id}",
                    query_text=f"successful plans or common obstacles for goals like '{goal_description}'",
                    num_results=3,
                    filter_tags=['planning', 'goal_strategy', goal_data['type']]
                )

                # Simulate LLM for generating sub-goals or actionable directives
                sub_goals_or_directives = self._simulate_llm_planning(goal_id, goal_description, target_state, current_world_state_summary, gap_description)
                
                for item in sub_goals_or_directives:
                    # Issue sub-goals as new 'system_generated' goals, or direct actions
                    if item['type'] == 'sub_goal':
                        self._add_goal(
                            g_type='system_generated_subgoal',
                            description=item['description'],
                            target_state=item['target_state'],
                            initial_drive=item.get('drive_level', goal_data['current_priority'] * 0.8), # Inherit drive
                            metadata={"parent_goal_id": goal_id, "source_node": self.node_name}
                        )
                        rospy.loginfo(f"{self.node_name}: Generated sub-goal: '{item['description']}' for parent goal '{goal_id}'.")
                    elif item['type'] == 'cognitive_directive':
                        self._issue_cognitive_directive_to_node(
                            directive_type=item['directive_type'],
                            target_node=item['target_node'],
                            reason=item['reason'],
                            payload_data=item['payload_data']
                        )
                        rospy.loginfo(f"{self.node_name}: Issued directive '{item['directive_type']}' for goal '{goal_id}'.")

    def _analyze_goal_state_differential(self, goal_data, target_state, current_world_state, current_body_state):
        """
        Simulates analyzing the gap between the current state and the desired target state for a goal.
        Returns (differential_score, description_of_gap)
        """
        differential_score = 0.0
        gap_description = []

        # Example: Location goal
        if 'location' in target_state and self.latest_world_model_state:
            robot_location = None
            # Find robot's own entity in world model
            for entity in current_world_state.get('entities', []):
                if entity.get('id') == 'robot_self_model' and 'position' in entity.get('properties', {}):
                    robot_location = entity['properties']['position']
                    break
            
            if robot_location:
                target_location = target_state['location']
                # Simple Euclidean distance for differential
                dist = np.linalg.norm(np.array(robot_location) - np.array(target_location))
                if dist > 1.0: # If more than 1 unit away (significant gap)
                    differential_score += min(1.0, dist / 10.0) # Larger distance, higher differential
                    gap_description.append(f"Robot is {dist:.1f} units away from target location {target_location}.")
        
        # Example: Task Completion goal
        if 'task_completed' in target_state and target_state['task_completed'] == True:
            # Check if relevant KPI from PerformanceReport or flag from other nodes
            if self.latest_performance_report and self.latest_performance_report.get('kpis_json', {}).get(f"{goal_data['type']}_completion_rate", 0.0) < self.goal_success_threshold:
                differential_score += 0.5 # Significant gap if task not yet completed effectively
                gap_description.append(f"Task type '{goal_data['type']}' not yet completed effectively.")
            
            if self.latest_internal_narrative and f"task {goal_data['goal_id']} is not done" in self.latest_internal_narrative.get('narrative_text', '').lower():
                differential_score += 0.3 # Internal confirmation of gap
                gap_description.append(f"Robot internally perceives task '{goal_data['goal_id']}' as incomplete.")

        # Example: Resource Level goal (e.g., maintain battery at 0.8)
        if 'battery_level' in target_state and self.latest_body_awareness_state:
            current_battery = current_body_state.get('overall_health', 1.0) # Use overall health or specific battery KPI
            desired_battery = target_state['battery_level']
            battery_diff = abs(current_battery - desired_battery)
            if battery_diff > 0.1: # If battery is significantly different from target
                differential_score += battery_diff * 0.8 # Higher diff, higher score
                gap_description.append(f"Battery level is {current_battery:.2f}, but desired is {desired_battery:.2f}.")

        # Influence from historical failures of similar goals from Memory
        if self.latest_memory_response and self.latest_memory_response.get('memories'):
            for mem in self.latest_memory_response['memories']:
                if "goal_strategy_failure" in mem.get('tags', '') and goal_data['type'] in mem.get('metadata', {}).get('goal_type', ''):
                    # If memory suggests similar goals failed, increase differential
                    differential_score += mem.get('effective_salience', 0.5) * 0.1
                    gap_description.append(f"Historical memory suggests difficulty for goal type '{goal_data['type']}'.")

        return min(1.0, differential_score), ". ".join(gap_description) if gap_description else "No significant gap."

    def _simulate_llm_planning(self, goal_id, goal_description, target_state, current_world_state, gap_description):
        """
        Simulates an LLM generating sub-goals or actionable directives to bridge a goal-state differential.
        Returns a list of simulated sub-goals/directives.
        """
        rospy.warn(f"{self.node_name}: Simulating LLM planning for goal '{goal_description}'.")
        
        simulated_plans = []

        # Simple logic: if location is a gap, suggest navigation
        if 'location' in target_state and "units away from target location" in gap_description:
            simulated_plans.append({
                'type': 'cognitive_directive',
                'directive_type': 'NavigateToLocation',
                'target_node': '/action_execution_node', # Or a hypothetical 'PathPlanningNode'
                'reason': f"To reach target location for goal '{goal_id}'.",
                'payload_data': {'destination': target_state['location'], 'priority': self.active_goals_cache[goal_id]['current_priority'] * 1.1}
            })
            rospy.logdebug(f"{self.node_name}: LLM generated navigation directive for goal '{goal_id}'.")
        
        # If task completion is a gap, suggest executing relevant actions or data gathering
        if 'task_completed' in target_state and target_state['task_completed'] == True and "task type" in gap_description:
            simulated_plans.append({
                'type': 'cognitive_directive',
                'directive_type': 'ExecuteTaskRoutine',
                'target_node': '/action_execution_node',
                'reason': f"To complete task for goal '{goal_id}'.",
                'payload_data': {'task_type': goal_description.replace("goal", "task"), 'priority': self.active_goals_cache[goal_id]['current_priority']}
            })
            # Also, maybe suggest gathering more info if there's uncertainty
            simulated_plans.append({
                'type': 'cognitive_directive',
                'directive_type': 'RequestDataForTask',
                'target_node': '/memory_node', # Or DataMiningNode
                'reason': f"Gather more info for task '{goal_id}' completion.",
                'payload_data': {'query': f"best practices for {goal_description.replace('goal', 'task')}", 'num_results': 2}
            })
            rospy.logdebug(f"{self.node_name}: LLM generated task execution and data gathering directives for goal '{goal_id}'.")

        # If battery is a gap, suggest charging
        if 'battery_level' in target_state and "Battery level" in gap_description and target_state['battery_level'] > current_world_state.get('overall_health', 0.0):
            simulated_plans.append({
                'type': 'cognitive_directive',
                'directive_type': 'SeekChargingStation',
                'target_node': '/cognitive_control_node', # Or ActionExecutionNode
                'reason': f"To reach target battery level for goal '{goal_id}'.",
                'payload_data': {'urgency': (target_state['battery_level'] - current_world_state.get('overall_health', 0.0)) * 2.0, 'physical_constraint': 'power_shortage'}
            })
            rospy.logdebug(f"{self.node_name}: LLM generated charging directive for goal '{goal_id}'.")

        # If no specific plan generated, issue a general 'Investigate' directive
        if not simulated_plans:
            simulated_plans.append({
                'type': 'cognitive_directive',
                'directive_type': 'InvestigateDifferential',
                'target_node': '/attention_node', # Or WorldModelNode for deeper analysis
                'reason': f"Goal '{goal_id}' has a significant gap; need more information or deeper analysis.",
                'payload_data': {'focus_target': f"goal_differential_{goal_id}", 'intensity': 0.7, 'duration_s': 10}
            })
            rospy.logdebug(f"{self.node_name}: LLM generated general investigation directive for goal '{goal_id}'.")

        # Add complexity factor based on differential
        for plan in simulated_plans:
            if plan['type'] == 'cognitive_directive':
                if 'duration_s' in plan['payload_data']:
                    plan['payload_data']['duration_s'] = plan['payload_data']['duration_s'] * (1 + self.subgoal_complexity_factor * differential_score)
                if 'priority' in plan['payload_data']:
                    plan['payload_data']['priority'] = min(1.0, plan['payload_data']['priority'] * (1 + self.subgoal_complexity_factor * differential_score))
            elif plan['type'] == 'sub_goal':
                # Sub-goals can have their own initial drive adjusted
                plan['drive_level'] = min(1.0, plan.get('drive_level', 0.5) * (1 + self.subgoal_complexity_factor * differential_score))
        
        return simulated_plans

    # --- Database and Publishing Functions ---
    def publish_motivation_state(self, timestamp, dominant_goal_id, overall_drive_level, active_goals_json):
        """Publishes the robot's current motivation state."""
        try:
            # Parse active_goals_json if it's a string for fallback
            parsed_active_goals = json.loads(active_goals_json) if isinstance(active_goals_json, str) else active_goals_json

            if isinstance(MotivationState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'dominant_goal_id': dominant_goal_id,
                    'overall_drive_level': overall_drive_level,
                    'active_goals': parsed_active_goals # Send as list of dicts for fallback
                }
                self.pub_motivation_state.publish(json.dumps(state_data))
            else:
                motivation_state_msg = MotivationState()
                motivation_state_msg.timestamp = timestamp
                motivation_state_msg.dominant_goal_id = dominant_goal_id
                motivation_state_msg.overall_drive_level = overall_drive_level
                motivation_state_msg.active_goals_json = active_goals_json
                self.pub_motivation_state.publish(motivation_state_msg)

            rospy.logdebug(f"{self.node_name}: Published motivation state (Goal: {dominant_goal_id}, Drive: {overall_drive_level:.2f}).")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish motivation state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': self.latest_emotion_state.get('mood', 'neutral') if self.latest_emotion_state else 'neutral',
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "goal_id": payload_data.get('goal_id', 'none'), "plan_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' for goal '{payload_data.get('goal_id', 'N/A')}'.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Motivation Node: {e}")

    def _issue_memory_request(self, request_id, query_text, num_results=5, filter_tags=None):
        """
        Helper to issue a MemoryRequest to the Memory Node for historical planning data.
        """
        timestamp = str(rospy.get_time())
        try:
            request_data = {
                'timestamp': timestamp,
                'request_id': request_id,
                'request_type': 'retrieve',
                'search_query': query_text,
                'user_id': 'system_motivation', # System-initiated memory request
                'filter_tags': filter_tags if filter_tags else ["planning", "goal_strategies"],
                'num_results': num_results
            }
            # Assuming MemoryRequest is always String if custom message is not found
            self.pub_memory_request.publish(json.dumps(request_data))
            rospy.logdebug(f"{self.node_name}: Issued MemoryRequest '{request_id}' for planning history.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue MemoryRequest from Motivation Node: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = ExperienceMotivationNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

11. New Internal Narrative Node (Stream of Consciousness Generator)

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Used sparingly for minor unpredictable variations

# Importing the necessary libraries for the LLM call
import requests # For making HTTP requests

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        InternalNarrative,      # Output: Robot's internal thoughts and summaries
        MemoryNodeState,        # Input: Summary of memory activity
        EmotionState,           # Input: Robot's emotional state
        PerformanceReport,      # Input: Overall system performance
        MotivationState,        # Input: Dominant goal and progress
        CognitiveDirective      # Input: Directives influencing narrative generation
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Internal Narrative Node.")
    InternalNarrative = String # Fallback for publishing
    MemoryNodeState = String
    EmotionState = String
    PerformanceReport = String
    MotivationState = String
    CognitiveDirective = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class InternalNarrativeNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('internal_narrative_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging

        # --- Parameters ---
        # Path to the SQLite database file for logging generated narratives.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/internal_narrative_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node generates and publishes a new narrative.
        self.generation_interval = rospy.get_param('~generation_interval', 5) # Every 5 seconds
        
        # Minimum salience score for a generated narrative to be published.
        self.min_publish_salience = rospy.get_param('~min_publish_salience', 0.1)

        # LLM Parameters
        self.llm_api_key = "" # Leave empty for Canvas to provide at runtime
        self.llm_model_name = "gemini-2.0-flash"
        self.llm_base_url = "https://generativelanguage.googleapis.com/v1beta/models/"

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'narratives' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS narratives (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                narrative_text TEXT,        -- The generated internal monologue
                main_theme TEXT,            -- Categorized theme of the narrative
                sentiment REAL,             -- Sentiment score of the narrative (-1.0 to 1.0)
                salience_score REAL,        -- Salience/importance of the narrative (0.0 to 1.0)
                contributing_context TEXT   -- JSON snapshot of inputs that generated this narrative
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_narrative_timestamp ON narratives (timestamp)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State - Store latest inputs from other nodes ---
        self.latest_states = {
            'memory': None,
            'emotion': None,
            'performance': None,
            'motivation': None,
            'cognitive_directive': None
        }

        # --- Publishers ---
        # Publishes the robot's internal narrative.
        self.pub_internal_narrative = rospy.Publisher('/internal_narrative', InternalNarrative, queue_size=10)
        # Publishes CognitiveDirectives for other nodes (e.g., to Memory for specific retrievals).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        rospy.Subscriber('/memory_node_state', MemoryNodeState, self.memory_state_callback)
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic narrative generation ---
        rospy.Timer(rospy.Duration(self.generation_interval), self.generate_and_publish_narrative)

        rospy.loginfo(f"{self.node_name}: Robot starts its internal monologue.")

    # --- Callbacks for input data (store in latest_states) ---
    def memory_state_callback(self, msg):
        """Callback for MemoryNodeState. Provides summary of memory activity."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'total_memories': (0, 'total_memories'),
            'salient_memories': (0, 'salient_memories'), 'active_memory_queries_json': ('[]', 'active_memory_queries_json'),
            'most_active_user_id': ('none', 'most_active_user_id'), 'status_message': ('', 'status_message')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_memory_queries_json'), str):
            try: data['active_memory_queries'] = json.loads(data['active_memory_queries_json'])
            except json.JSONDecodeError: data['active_memory_queries'] = []
        self.latest_states['memory'] = data
        rospy.logdebug(f"{self.node_name}: Received Memory State. Salient: {data.get('salient_memories', 'N/A')}")

    def emotion_state_callback(self, msg):
        """Callback for EmotionState. Provides robot's current emotional state."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_states['emotion'] = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_states['emotion'].get('mood', 'N/A')}")

    def performance_report_callback(self, msg):
        """Callback for PerformanceReport. Provides overall system performance."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        self.latest_states['performance'] = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Performance Report. Score: {self.latest_states['performance'].get('overall_score', 'N/A'):.2f}")

    def motivation_state_callback(self, msg):
        """Callback for MotivationState. Provides dominant goal and progress."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_goals_json'), str):
            try: data['active_goals'] = json.loads(data['active_goals_json'])
            except json.JSONDecodeError: data['active_goals'] = []
        self.latest_states['motivation'] = data
        rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {self.latest_states['motivation'].get('dominant_goal_id', 'N/A')}.")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can influence narrative generation (e.g., 'ReflectOnTopic').
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'ReflectOnTopic':
                    self.latest_states['cognitive_directive'] = {
                        'type': 'reflect_on_topic',
                        'topic': payload.get('topic', 'general_experience'),
                        'intensity': payload.get('intensity', 0.7),
                        'duration_s': payload.get('duration_s', 10),
                        'start_time': rospy.get_time()
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to reflect on topic: '{payload.get('topic', 'N/A')}'.")
                elif directive_type == 'GenerateReport': # E.g., for user-facing self-report
                     self.latest_states['cognitive_directive'] = {
                        'type': 'generate_report',
                        'report_type': payload.get('report_type', 'status_summary'),
                        'audience': payload.get('audience', 'user'),
                        'duration_s': payload.get('duration_s', 5),
                        'start_time': rospy.get_time()
                    }
                     rospy.loginfo(f"{self.node_name}: Received directive to generate report: '{payload.get('report_type', 'N/A')}'.")

            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    # --- Narrative Generation Logic ---
    async def generate_and_publish_narrative(self, event):
        """
        Generates an internal narrative based on the robot's current cognitive state
        and publishes it. Uses an LLM to create the narrative.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # Collect relevant context from latest states
        context_summary = self._summarize_current_context()

        # Check for active directives that influence narrative generation
        directive_influence = {}
        if self.latest_states['cognitive_directive']:
            directive = self.latest_states['cognitive_directive']
            if (current_time - directive['start_time']) < directive.get('duration_s', 0) or directive.get('duration_s', 0) == 0:
                # Directive is active
                directive_influence = {
                    'type': directive['type'],
                    'topic': directive.get('topic'),
                    'report_type': directive.get('report_type'),
                    'intensity': directive.get('intensity')
                }
                rospy.logdebug(f"{self.node_name}: Narrative generation influenced by directive: '{directive.get('type')}'.")
                
                # If directive expired, clear it
                if directive.get('duration_s', 0) > 0 and (current_time - directive['start_time']) > directive.get('duration_s', 0):
                    rospy.loginfo(f"{self.node_name}: Narrative directive completed/expired.")
                    self.latest_states['cognitive_directive'] = None
            else:
                self.latest_states['cognitive_directive'] = None # Clear if already expired

        # Formulate prompt for LLM
        llm_prompt = self._formulate_llm_prompt(context_summary, directive_influence)
        
        rospy.loginfo(f"{self.node_name}: Sending prompt to LLM for narrative generation...")
        narrative_text = "..." # Default while waiting for LLM
        main_theme = "reflection"
        sentiment = 0.0
        salience_score = 0.0

        try:
            # LLM API Call
            chatHistory = []
            chatHistory.push({ role: "user", parts: [{ text: llm_prompt }] });
            payload = { contents: chatHistory };
            apiKey = self.llm_api_key
            apiUrl = f"{self.llm_base_url}{self.llm_model_name}:generateContent?key={apiKey}"
            
            response = await requests.post(apiUrl, json=payload)
            response.raise_for_status() # Raise an exception for HTTP errors
            result = response.json()
            
            if result.candidates and result.candidates.length > 0 and \
               result.candidates[0].content and result.candidates[0].content.parts and \
               result.candidates[0].content.parts.length > 0:
                
                llm_response_text = result.candidates[0].content.parts[0].text
                
                # Parse LLM response to extract narrative, theme, sentiment, salience
                # This is a simplified parsing. In a real system, LLM might output JSON.
                narrative_text, main_theme, sentiment, salience_score = self._parse_llm_response(llm_response_text)
                rospy.loginfo(f"{self.node_name}: LLM generated narrative successfully.")
            else:
                rospy.logwarn(f"{self.node_name}: LLM response had no content. Using default narrative.")
                narrative_text = "I am currently processing. My internal state is ambiguous."

        except requests.exceptions.RequestException as e:
            rospy.logerr(f"{self.node_name}: LLM API request failed: {e}. Using default narrative.")
            narrative_text = "My external connection is currently unstable, preventing deeper introspection."
        except json.JSONDecodeError as e:
            rospy.logerr(f"{self.node_name}: Failed to parse LLM response JSON: {e}. Using default narrative.")
            narrative_text = "My internal interpretation module encountered an error."
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during LLM call: {e}. Using default narrative.")
            narrative_text = "A momentary lapse in my thought processes."


        # Only publish if salience is above threshold
        if salience_score >= self.min_publish_salience:
            self.publish_internal_narrative(
                timestamp,
                narrative_text,
                main_theme,
                sentiment,
                salience_score
            )
            self.save_narrative_log(
                timestamp,
                narrative_text,
                main_theme,
                sentiment,
                salience_score,
                json.dumps({'context': context_summary, 'directive_influence': directive_influence}, default=str)
            )
            rospy.loginfo(f"{self.node_name}: Published new internal narrative (Salience: {salience_score:.2f}).")
        else:
            rospy.logdebug(f"{self.node_name}: Generated narrative too low salience ({salience_score:.2f}). Not publishing.")

    def _summarize_current_context(self):
        """
        Compiles a concise summary of the robot's current cognitive state
        from subscribed nodes to inform the LLM.
        """
        summary = {
            "time": rospy.get_time(),
            "emotion": self.latest_states['emotion'],
            "motivation": self.latest_states['motivation'],
            "performance": self.latest_states['performance'],
            "memory_state": self.latest_states['memory']
        }
        # Filter None values and sensitive info, ensure serializable
        clean_summary = {}
        for k, v in summary.items():
            if v is not None:
                # Recursively clean nested dictionaries/lists if necessary
                if isinstance(v, dict):
                    clean_v = {}
                    for vk, vv in v.items():
                        if isinstance(vv, (str, int, float, bool, list)):
                            clean_v[vk] = vv
                        elif isinstance(vv, dict):
                            # Simple recursive cleaning for one level deep
                            clean_v[vk] = {ik: iv for ik, iv in vv.items() if isinstance(iv, (str, int, float, bool))}
                        # Add other types as needed
                    clean_summary[k] = clean_v
                elif isinstance(v, (str, int, float, bool)):
                    clean_summary[k] = v
                # Special handling for lists, like active_goals_json
                if k == 'motivation' and clean_summary.get('motivation') and 'active_goals' in clean_summary['motivation']:
                    # Ensure active_goals is a list of dicts with basic types
                    clean_summary['motivation']['active_goals'] = [
                        {gk: gv for gk, gv in g.items() if isinstance(gv, (str, int, float, bool))}
                        for g in clean_summary['motivation']['active_goals']
                    ]
        
        return clean_summary

    def _formulate_llm_prompt(self, context, directive_influence):
        """
        Creates a prompt for the LLM based on the summarized cognitive context
        and any active directives influencing narrative generation.
        """
        prompt_parts = []
        
        prompt_parts.append("You are the internal consciousness of a robot. Based on the following sensory and cognitive states, generate a short, first-person internal monologue or reflection. Focus on what feels most salient or emotionally relevant. DO NOT explicitly mention 'LLM' or 'AI model' in your output.")
        
        # Add emotion state
        if context.get('emotion'):
            emotion = context['emotion']
            prompt_parts.append(f"Current Mood: {emotion.get('mood', 'neutral')} with intensity {emotion.get('mood_intensity', 0.0):.2f}. Overall sentiment: {emotion.get('sentiment_score', 0.0):.2f}.")
        
        # Add motivation state
        if context.get('motivation'):
            motivation = context['motivation']
            prompt_parts.append(f"Dominant Goal: '{motivation.get('dominant_goal_id', 'none')}' (Drive: {motivation.get('overall_drive_level', 0.0):.2f}). Active goals: {[g.get('description', 'N/A') for g in motivation.get('active_goals', [])]}.")

        # Add performance report
        if context.get('performance'):
            performance = context['performance']
            prompt_parts.append(f"Recent Performance: Overall Score {performance.get('overall_score', 1.0):.2f}. Suboptimal flag: {performance.get('suboptimal_flag', False)}. KPIs: {performance.get('kpis_json', {})}.")

        # Add memory state summary
        if context.get('memory'):
            memory = context['memory']
            prompt_parts.append(f"Memory System: Total {memory.get('total_memories', 0)} memories, {memory.get('salient_memories', 0)} are salient. Memory status: {memory.get('status_message', 'Normal')}.")

        # Add directive influence
        if directive_influence:
            if directive_influence['type'] == 'reflect_on_topic':
                prompt_parts.append(f"I am being directed to intensely reflect on the topic of '{directive_influence.get('topic')}' with high focus.")
            elif directive_influence['type'] == 'generate_report':
                prompt_parts.append(f"I need to prepare an internal report about my '{directive_influence.get('report_type')}' state for an external audience (myself or others).")
        
        # Add a concluding instruction to guide narrative style
        prompt_parts.append("\nGenerate a short, coherent internal monologue (30-80 words). Examples: 'I feel a sense of calm efficiency as my current task progresses smoothly. My memory access is swift and precise, aiding my focused navigation.' or 'A subtle dissonance in my world model, despite my efforts to reconcile recent sensory data. My motivation to understand this anomaly intensifies, yet a flicker of frustration persists.'")
        
        return "\n".join(prompt_parts)

    def _parse_llm_response(self, llm_response_text):
        """
        Parses the LLM's raw text response to extract narrative, theme, sentiment, and salience.
        This is a simplified parsing for demonstration. A more robust solution might
        expect a structured JSON output from the LLM.
        """
        narrative_text = llm_response_text
        
        # Simple keyword-based theme detection
        theme = "general_reflection"
        if "goal" in narrative_text.lower() or "task" in narrative_text.lower() or "purpose" in narrative_text.lower():
            theme = "motivation_and_goals"
        if "feel" in narrative_text.lower() or "mood" in narrative_text.lower() or "emotion" in narrative_text.lower():
            theme = "emotional_state"
        if "memory" in narrative_text.lower() or "recall" in narrative_text.lower() or "knowledge" in narrative_text.lower():
            theme = "memory_and_learning"
        if "error" in narrative_text.lower() or "problem" in narrative_text.lower() or "dissonance" in narrative_text.lower():
            theme = "problem_and_correction"
        if "explore" in narrative_text.lower() or "new" in narrative_text.lower() or "curiosity" in narrative_text.lower():
            theme = "exploration_and_novelty"

        # Simple sentiment analysis using TextBlob
        try:
            sentiment_score = TextBlob(narrative_text).sentiment.polarity
        except Exception as e:
            rospy.logwarn(f"{self.node_name}: Failed to analyze sentiment of narrative: {e}. Defaulting to 0.0.")
            sentiment_score = 0.0

        # Simple salience estimation (e.g., length, extreme sentiment)
        salience_score = min(1.0, len(narrative_text) / 100.0) # Longer is more salient, up to a point
        salience_score += abs(sentiment_score) * 0.2 # Stronger sentiment increases salience
        salience_score += random.uniform(0.0, 0.1) # Small random component

        return narrative_text, theme, sentiment_score, salience_score


    # --- Database and Publishing Functions ---
    def save_narrative_log(self, timestamp, narrative_text, main_theme, sentiment, salience_score, contributing_context_json):
        """Saves a generated narrative entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO narratives (timestamp, narrative_text, main_theme, sentiment, salience_score, contributing_context)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (timestamp, narrative_text, main_theme, sentiment, salience_score, contributing_context_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved narrative log (Theme: {main_theme}, Salience: {salience_score:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save narrative log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_narrative_log: {e}")

    def publish_internal_narrative(self, timestamp, narrative_text, main_theme, sentiment, salience_score):
        """Publishes the robot's internal narrative on the '/internal_narrative' topic."""
        try:
            if isinstance(InternalNarrative, type(String)): # Fallback to String message
                narrative_data = {
                    'timestamp': timestamp,
                    'narrative_text': narrative_text,
                    'main_theme': main_theme,
                    'sentiment': sentiment,
                    'salience_score': salience_score
                }
                self.pub_internal_narrative.publish(json.dumps(narrative_data))
            else:
                internal_narrative_msg = InternalNarrative()
                internal_narrative_msg.timestamp = timestamp
                internal_narrative_msg.narrative_text = narrative_text
                internal_narrative_msg.main_theme = main_theme
                internal_narrative_msg.sentiment = sentiment
                internal_narrative_msg.salience_score = salience_score
                self.pub_internal_narrative.publish(internal_narrative_msg)

            rospy.logdebug(f"{self.node_name}: Published internal narrative.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish internal narrative: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': self.latest_states['emotion'].get('mood', 'neutral') if self.latest_states['emotion'] else 'neutral',
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "narrative_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Internal Narrative Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Internal Narrative Node: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = InternalNarrativeNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

12. New Prediction Node (Imaginative Forward Modeling)

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Used sparingly for simulating inherent world uncertainty or tie-breaking in predictions

from collections import deque

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        PredictionState,        # Output: Predicted future outcomes
        WorldModelState,        # Input: Current state of the world
        MotivationState,        # Input: Current goals (for goal-oriented predictions)
        MemoryResponse,         # Input: Historical data, similar scenarios, past outcomes
        ActionExecutionResult,  # Input: Feedback on past actions (for learning prediction accuracy)
        CognitiveDirective      # Input: Directives requesting specific predictions
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Prediction Node.")
    PredictionState = String # Fallback for publishing
    WorldModelState = String
    MotivationState = String
    MemoryResponse = String
    ActionExecutionResult = String
    CognitiveDirective = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class PredictionNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('prediction_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging

        # --- Parameters ---
        # Path to the SQLite database file for logging predictions and their outcomes.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/predictions_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node makes proactive predictions.
        self.proactive_prediction_interval = rospy.get_param('~proactive_prediction_interval', 3.0) # Every 3 seconds
        
        # Minimum confidence for a prediction to be considered reliable.
        self.min_prediction_confidence = rospy.get_param('~min_prediction_confidence', 0.2)

        # How far into the future (in simulated time) the predictions typically look.
        self.prediction_horizon_s = rospy.get_param('~prediction_horizon_s', 10.0) # 10 seconds into the future

        # NEW: Adaptive Learning for Prediction Accuracy (Simulated Reinforcement)
        self.prediction_learning_rate = rospy.get_param('~prediction_learning_rate', 0.05)
        # Weights for different factors influencing prediction outcome probability
        self.prediction_factor_weights = rospy.get_param('~prediction_factor_weights', {
            'world_model_consistency': 0.4, # More consistent world model -> more accurate predictions
            'historical_success_rate': 0.3, # How often similar past predictions were accurate
            'motivation_alignment': 0.2,    # Predictions aligned with dominant goals
            'random_uncertainty': 0.1       # Residual irreducible uncertainty
        })
        # History window for tracking prediction outcomes for learning
        self.prediction_outcome_history = deque(maxlen=20) # Stores (predicted_outcome_hash, actual_outcome_hash, was_accurate)

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'predictions_log' table if it doesn't exist.
        # NEW: Added 'actual_outcome_json' and 'accuracy_score' for learning
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS predictions_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,                 -- When prediction was made
                predicted_event TEXT,           -- Description of predicted event
                confidence REAL,                -- Confidence in prediction (0.0 to 1.0)
                prediction_type TEXT,           -- e.g., 'object_movement', 'goal_success', 'environmental_change'
                predicted_value TEXT,           -- Specific predicted value (e.g., [x,y,z], 'completed')
                predicted_value_range_json TEXT, -- JSON array for range (e.g., [min_temp, max_temp])
                context_snapshot TEXT,          -- JSON snapshot of inputs that informed prediction
                actual_outcome_json TEXT,       -- NEW: Actual outcome observed later (JSON string)
                accuracy_score REAL             -- NEW: Score indicating how accurate the prediction was (0.0 to 1.0)
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_prediction_timestamp ON predictions_log (timestamp)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_prediction_type ON predictions_log (prediction_type)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State - Store latest inputs from other nodes ---
        self.latest_states = {
            'world_model': None,
            'motivation': None,
            'memory_response': None,
            'action_execution_result': None, # NEW
            'cognitive_directive': None
        }
        self.last_proactive_prediction_time = rospy.get_time()

        # --- Publishers ---
        # Publishes predicted future outcomes.
        self.pub_prediction_state = rospy.Publisher('/predictions', PredictionState, queue_size=10)
        # Publishes MemoryRequests to retrieve historical data relevant to predictions.
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10) # Using String for MemoryRequest fallback
        # Publishes CognitiveDirectives for other nodes (e.g., to Attention for data gathering).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback

        # --- Subscribers ---
        rospy.Subscriber('/world_model_state', String, self.world_model_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON
        rospy.Subscriber('/action_execution_result', ActionExecutionResult, self.action_execution_result_callback) # NEW
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic proactive predictions ---
        rospy.Timer(rospy.Duration(self.proactive_prediction_interval), self.make_proactive_prediction)

        rospy.loginfo(f"{self.node_name}: Robot begins to imagine the future.")

    # --- Callbacks for input data (store in latest_states) ---
    def world_model_state_callback(self, msg):
        """Callback for WorldModelState. Provides current state of the world for prediction base."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'known_entities_json': ('[]', 'known_entities_json'),
            'environmental_properties_json': ('[]', 'environmental_properties_json'), 'consistency_issues_json': ('[]', 'consistency_issues_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # Parse JSON fields into Python objects
        if isinstance(data.get('known_entities_json'), str):
            try: data['known_entities'] = json.loads(data['known_entities_json'])
            except json.JSONDecodeError: data['known_entities'] = []
        if isinstance(data.get('environmental_properties_json'), str):
            try: data['environmental_properties'] = json.loads(data['environmental_properties_json'])
            except json.JSONDecodeError: data['environmental_properties'] = []
        if isinstance(data.get('consistency_issues_json'), str):
            try: data['consistency_issues'] = json.loads(data['consistency_issues_json'])
            except json.JSONDecodeError: data['consistency_issues'] = []
        self.latest_states['world_model'] = data
        rospy.logdebug(f"{self.node_name}: Received World Model State. Entities: {len(data.get('known_entities', []))}")

    def motivation_state_callback(self, msg):
        """Callback for MotivationState. Provides current goals for goal-oriented predictions."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_goals_json'), str):
            try: data['active_goals'] = json.loads(data['active_goals_json'])
            except json.JSONDecodeError: data['active_goals'] = []
        self.latest_states['motivation'] = data
        rospy.logdebug(f"{self.node_name}: Received Motivation State. Goal: {self.latest_states['motivation'].get('dominant_goal_id', 'N/A')}.")

    def memory_response_callback(self, msg):
        """Callback for MemoryResponse. Provides historical data, similar scenarios, past outcomes."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('memories_json'), str):
            try: data['memories'] = json.loads(data['memories_json'])
            except json.JSONDecodeError: data['memories'] = []
        self.latest_states['memory_response'] = data
        rospy.logdebug(f"{self.node_name}: Received Memory Response. {len(data.get('memories', []))} memories retrieved for prediction.")

    def action_execution_result_callback(self, msg): # NEW
        """
        Callback for ActionExecutionResult. Provides feedback on past actions' outcomes
        to learn prediction accuracy and improve future predictions.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'action_id': ('', 'action_id'),
            'execution_status': ('unknown', 'execution_status'), 'success_flag': (False, 'success_flag'),
            'predicted_outcome_snapshot_json': ('{}', 'predicted_outcome_snapshot_json'), # This will be the prediction that led to this action
            'actual_outcome_snapshot_json': ('{}', 'actual_outcome_snapshot_json') # The actual outcome observed
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # Parse JSON fields
        if isinstance(data.get('predicted_outcome_snapshot_json'), str):
            try: data['predicted_outcome_snapshot'] = json.loads(data['predicted_outcome_snapshot_json'])
            except json.JSONDecodeError: data['predicted_outcome_snapshot'] = {}
        if isinstance(data.get('actual_outcome_snapshot_json'), str):
            try: data['actual_outcome_snapshot'] = json.loads(data['actual_outcome_snapshot_json'])
            except json.JSONDecodeError: data['actual_outcome_snapshot'] = {}

        self.latest_states['action_execution_result'] = data
        rospy.logdebug(f"{self.node_name}: Received Action Execution Result. Action: {data.get('action_id')}, Success: {data.get('success_flag')}.")
        
        # Trigger learning from this outcome
        self._learn_from_prediction_outcome()


    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Directs the node to make specific predictions.
        Example: 'PredictOutcome', 'ForecastEnvironmentalChange'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'PredictOutcome':
                    event_description = payload.get('event_description', 'general_event')
                    target_entity_id = payload.get('target_entity_id')
                    prediction_type = payload.get('prediction_type', 'event')
                    # Set active directive for this prediction request
                    self.latest_states['cognitive_directive'] = {
                        'type': 'predict_outcome',
                        'event_description': event_description,
                        'target_entity_id': target_entity_id,
                        'prediction_type': prediction_type,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 2) # How long to consider this directive active
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to predict outcome: '{event_description}'.")
                elif directive_type == 'ForecastEnvironmentalChange':
                    change_type = payload.get('change_type', 'temperature')
                    time_horizon = payload.get('time_horizon_s', self.prediction_horizon_s)
                    self.latest_states['cognitive_directive'] = {
                        'type': 'forecast_environmental_change',
                        'change_type': change_type,
                        'time_horizon_s': time_horizon,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 2)
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to forecast environmental change: '{change_type}'.")

            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    # --- Core Prediction Logic ---
    def make_proactive_prediction(self, event):
        """
        Periodically initiates a proactive prediction about the environment or goal progress,
        if no specific prediction directive is active.
        """
        current_time = rospy.get_time()
        
        # Only make proactive predictions if no specific directive is active for prediction
        if self.latest_states['cognitive_directive'] and \
           (current_time - self.latest_states['cognitive_directive']['start_time']) < self.latest_states['cognitive_directive'].get('duration_s', 0):
            rospy.logdebug(f"{self.node_name}: Specific prediction directive active. Skipping proactive prediction.")
            return

        if (current_time - self.last_proactive_prediction_time) < self.proactive_prediction_interval:
            return

        self.last_proactive_prediction_time = current_time
        rospy.loginfo(f"{self.node_name}: Making proactive prediction...")

        # Determine what to predict proactively
        # Prioritize based on current motivation or world model state
        prediction_type = "environmental_change"
        target_entity = None
        event_description = "general environmental evolution"

        if self.latest_states['motivation'] and self.latest_states['motivation'].get('dominant_goal_id') != 'none':
            dominant_goal_id = self.latest_states['motivation'].get('dominant_goal_id')
            event_description = f"success of goal '{dominant_goal_id}'"
            prediction_type = "goal_outcome"
            rospy.logdebug(f"{self.node_name}: Proactively predicting outcome for dominant goal.")
        elif self.latest_states['world_model'] and self.latest_states['world_model'].get('consistency_issues'):
            # If there are inconsistencies, predict resolution or continued inconsistency
            event_description = "resolution of world model inconsistencies"
            prediction_type = "internal_state_evolution"
            rospy.logdebug(f"{self.node_name}: Proactively predicting world model consistency resolution.")
        elif self.latest_states['world_model'] and self.latest_states['world_model'].get('known_entities'):
            # Pick a random salient entity to predict its movement/state
            salient_entities = [e for e in self.latest_states['world_model']['known_entities'] if e.get('confidence', 0.0) > 0.5]
            if salient_entities:
                target_entity = random.choice(salient_entities).get('id')
                event_description = f"movement or state change of entity '{target_entity}'"
                prediction_type = "object_state_change"
                rospy.logdebug(f"{self.node_name}: Proactively predicting state change for salient entity.")

        # If no specific context, make a general environmental prediction
        self._generate_and_publish_prediction(event_description, prediction_type, target_entity)
        
        # Clear the action execution result after it's been used for learning
        self.latest_states['action_execution_result'] = None


    def _generate_and_publish_prediction(self, event_description, prediction_type, target_entity_id=None, requested_by_directive=False):
        """
        Generates a prediction based on current inputs, simulates probabilistic outcomes,
        and publishes the PredictionState.
        """
        timestamp = str(rospy.get_time())
        
        # Summarize current context for the prediction
        context_summary = self._summarize_current_context()

        # Simulate probabilistic outcome and confidence
        predicted_value, predicted_value_range, confidence, accuracy_influencers = self._simulate_probabilistic_prediction(
            event_description, prediction_type, target_entity_id, context_summary, requested_by_directive
        )

        # Apply learning feedback to update internal prediction factors (or actual model weights)
        self._update_prediction_factors_from_feedback(accuracy_influencers)


        # Only publish if confidence is above threshold
        if confidence >= self.min_prediction_confidence:
            self.publish_prediction_state(
                timestamp,
                event_description,
                confidence,
                prediction_type,
                str(predicted_value), # Convert to string for message field
                json.dumps(predicted_value_range)
            )
            # Log the prediction, will update with actual outcome later
            self.save_prediction_log(
                timestamp,
                event_description,
                confidence,
                prediction_type,
                str(predicted_value),
                json.dumps(predicted_value_range),
                json.dumps(context_summary, default=str),
                None, # Actual outcome not yet known
                0.0 # Accuracy not yet known
            )
            rospy.loginfo(f"{self.node_name}: Published prediction for '{event_description}' (Confidence: {confidence:.2f}).")
        else:
            rospy.logdebug(f"{self.node_name}: Prediction for '{event_description}' too low confidence ({confidence:.2f}). Not publishing.")
            # If low confidence, maybe issue a directive to gather more data
            if not requested_by_directive: # Don't spam if it was a direct request
                self._issue_cognitive_directive_to_node(
                    directive_type='RequestDataForPrediction',
                    target_node='/attention_node', # Or SensoryQualiaNode / WorldModelNode
                    reason=f"Low confidence prediction for '{event_description}'. Need more data.",
                    payload_data={"prediction_type": prediction_type, "target": target_entity_id if target_entity_id else event_description}
                )


    def _summarize_current_context(self):
        """
        Compiles a concise summary of the robot's current cognitive state
        from subscribed nodes to inform the prediction model.
        """
        summary = {
            "time": rospy.get_time(),
            "world_model_entities_count": len(self.latest_states['world_model'].get('known_entities', [])) if self.latest_states['world_model'] else 0,
            "world_model_inconsistencies": len(self.latest_states['world_model'].get('consistency_issues', [])) if self.latest_states['world_model'] else 0,
            "motivation_dominant_goal": self.latest_states['motivation'].get('dominant_goal_id') if self.latest_states['motivation'] else 'none',
            "motivation_overall_drive": self.latest_states['motivation'].get('overall_drive_level', 0.0) if self.latest_states['motivation'] else 0.0,
            "memory_response_count": len(self.latest_states['memory_response'].get('memories', [])) if self.latest_states['memory_response'] else 0,
            # 'action_execution_result' is handled by _learn_from_prediction_outcome, not directly here.
            "active_cognitive_directive_type": self.latest_states['cognitive_directive'].get('type') if self.latest_states['cognitive_directive'] else 'none'
        }
        return summary

    def _simulate_probabilistic_prediction(self, event_description, prediction_type, target_entity_id, context_summary, requested_by_directive):
        """
        Simulates probabilistic prediction based on context and learned factors.
        Returns (predicted_value, predicted_value_range, confidence, accuracy_influencers_dict).
        """
        rospy.warn(f"{self.node_name}: Simulating probabilistic prediction for: '{event_description}'.")

        predicted_value = "unknown"
        predicted_value_range = [0, 1] # Default range
        base_confidence = 0.5

        # Factors influencing prediction confidence and outcome
        world_model_consistency_influence = 1.0 - (context_summary.get('world_model_inconsistencies', 0) * 0.1)
        world_model_consistency_influence = max(0.0, world_model_consistency_influence) # Higher consistency = better influence

        historical_success_rate_influence = self._get_historical_prediction_accuracy_for_type(prediction_type)

        motivation_alignment_influence = 0.0
        if prediction_type == "goal_outcome" and context_summary.get('motivation_dominant_goal') in event_description:
            motivation_alignment_influence = context_summary.get('motivation_overall_drive', 0.0)

        # Weighted sum of influences for confidence
        confidence = (
            self.prediction_factor_weights['world_model_consistency'] * world_model_consistency_influence +
            self.prediction_factor_weights['historical_success_rate'] * historical_success_rate_influence +
            self.prediction_factor_weights['motivation_alignment'] * motivation_alignment_influence +
            self.prediction_factor_weights['random_uncertainty'] * random.uniform(0.0, 0.1) # Add small random noise
        )
        confidence = max(0.0, min(1.0, confidence)) # Clamp confidence

        # Simulate the predicted outcome based on confidence and type
        if prediction_type == 'goal_outcome':
            if confidence > 0.7: predicted_value = "success"
            elif confidence < 0.3: predicted_value = "failure"
            else: predicted_value = random.choice(["success", "failure", "partial_success"])
            predicted_value_range = [] # Not applicable for categorical outcome
        elif prediction_type == 'environmental_change':
            if "temperature" in event_description:
                if confidence > 0.6: predicted_value = random.choice(["slight_increase", "slight_decrease"])
                else: predicted_value = "stable"
                predicted_value_range = [20.0, 30.0] # Example range
            elif "light" in event_description:
                if confidence > 0.6: predicted_value = random.choice(["brightening", "dimming"])
                else: predicted_value = "stable"
                predicted_value_range = [300.0, 700.0]
            else: predicted_value = "change_detected" # Generic
        elif prediction_type == 'object_state_change' and target_entity_id:
            if confidence > 0.7: predicted_value = f"{target_entity_id}_will_move"
            elif confidence < 0.3: predicted_value = f"{target_entity_id}_will_remain_stationary"
            else: predicted_value = f"{target_entity_id}_state_uncertain"
            predicted_value_range = []

        # Store factors that influenced this prediction for later learning
        accuracy_influencers = {
            'prediction_type': prediction_type,
            'world_model_consistency_influence': world_model_consistency_influence,
            'historical_success_rate_influence': historical_success_rate_influence,
            'motivation_alignment_influence': motivation_alignment_influence,
            'predicted_value': predicted_value # The actual value we predicted
        }

        return predicted_value, predicted_value_range, confidence, accuracy_influencers

    def _get_historical_prediction_accuracy_for_type(self, prediction_type):
        """
        Retrieves the average accuracy for similar prediction types from memory.
        This provides feedback for the prediction model's learning.
        """
        # For simulation, we'll query our own log. In a real system, MemoryNode would be queried.
        try:
            self.cursor.execute("SELECT accuracy_score FROM predictions_log WHERE prediction_type = ? AND accuracy_score IS NOT NULL ORDER BY timestamp DESC LIMIT 10", (prediction_type,))
            rows = self.cursor.fetchall()
            accuracies = [row[0] for row in rows]
            if accuracies:
                return sum(accuracies) / len(accuracies)
            return 0.5 # Default if no history
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to get historical accuracy: {e}")
            return 0.5

    def _learn_from_prediction_outcome(self): # NEW
        """
        Adapts the `prediction_factor_weights` based on the success/failure of recent predictions.
        This is a simple reinforcement learning mechanism.
        """
        if not self.latest_states['action_execution_result']:
            return

        result = self.latest_states['action_execution_result']
        predicted_outcome = result.get('predicted_outcome_snapshot', {})
        actual_outcome = result.get('actual_outcome_snapshot', {})
        action_success = result.get('success_flag', False)

        if not predicted_outcome or not actual_outcome:
            rospy.logwarn(f"{self.node_name}: Missing predicted or actual outcome snapshot for learning.")
            return

        # Determine prediction accuracy
        prediction_was_accurate = False
        if predicted_outcome.get('predicted_value') == actual_outcome.get('actual_value'):
            prediction_was_accurate = True
        # More complex comparison would be needed for ranges or nuanced outcomes

        # Update the prediction log entry with actual outcome and accuracy
        try:
            self.cursor.execute("UPDATE predictions_log SET actual_outcome_json = ?, accuracy_score = ? WHERE timestamp = ? AND predicted_event = ?",
                                (json.dumps(actual_outcome, default=str), 1.0 if prediction_was_accurate else 0.0,
                                 predicted_outcome.get('timestamp'), predicted_outcome.get('predicted_event')))
            self.conn.commit()
            rospy.loginfo(f"{self.node_name}: Updated prediction log for '{predicted_outcome.get('predicted_event')}'. Accuracy: {1.0 if prediction_was_accurate else 0.0}.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update prediction log with outcome: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during prediction log update: {e}")

        # Adapt prediction factor weights
        reward = 0.0
        if prediction_was_accurate:
            reward = 0.1 # Positive reinforcement for accurate prediction
        else:
            reward = -0.05 # Penalty for inaccurate prediction

        # Adjust the 'historical_success_rate' factor. More complex adaptive algorithms could adjust others.
        current_weight = self.prediction_factor_weights['historical_success_rate']
        new_weight = current_weight + self.prediction_learning_rate * reward
        self.prediction_factor_weights['historical_success_rate'] = max(0.0, min(1.0, new_weight))
        rospy.loginfo(f"{self.node_name}: Learned! 'historical_success_rate' factor adjusted to {self.prediction_factor_weights['historical_success_rate']:.3f}.")

        # If a prediction was inaccurate, and confidence was high, issue a directive to Self-Correction
        if not prediction_was_accurate and predicted_outcome.get('confidence', 0.0) > 0.7:
            rospy.logwarn(f"{self.node_name}: Highly confident but inaccurate prediction. Issuing self-correction directive.")
            self._issue_cognitive_directive_to_node(
                directive_type='PredictionInaccuracyDetected',
                target_node='/self_correction_node',
                reason=f"High confidence prediction for '{predicted_outcome.get('predicted_event')}' was inaccurate.",
                payload_data={
                    "predicted_event": predicted_outcome.get('predicted_event'),
                    "predicted_value": predicted_outcome.get('predicted_value'),
                    "actual_value": actual_outcome.get('actual_value'),
                    "confidence_at_prediction": predicted_outcome.get('confidence')
                }
            )


    # --- Database and Publishing Functions ---
    def save_prediction_log(self, timestamp, predicted_event, confidence, prediction_type, predicted_value, predicted_value_range_json, context_snapshot_json, actual_outcome_json, accuracy_score):
        """Saves a prediction entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO predictions_log (timestamp, predicted_event, confidence, prediction_type, predicted_value, predicted_value_range_json, context_snapshot, actual_outcome_json, accuracy_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (timestamp, predicted_event, confidence, prediction_type, predicted_value, predicted_value_range_json, context_snapshot_json, actual_outcome_json, accuracy_score))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved prediction log (Event: {predicted_event}, Confidence: {confidence:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save prediction log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_prediction_log: {e}")

    def publish_prediction_state(self, timestamp, predicted_event, confidence, prediction_type, predicted_value, predicted_value_range_json):
        """Publishes the predicted future outcomes on the '/predictions' topic."""
        try:
            # Parse predicted_value_range_json if it's a string, for fallback message
            parsed_predicted_value_range = json.loads(predicted_value_range_json) if isinstance(predicted_value_range_json, str) else predicted_value_range_json

            if isinstance(PredictionState, type(String)): # Fallback to String message
                prediction_data = {
                    'timestamp': timestamp,
                    'predicted_event': predicted_event,
                    'confidence': confidence,
                    'prediction_type': prediction_type,
                    'predicted_value': predicted_value,
                    'predicted_value_range': parsed_predicted_value_range # Send as list for JSON fallback
                }
                self.pub_prediction_state.publish(json.dumps(prediction_data))
            else:
                prediction_state_msg = PredictionState()
                prediction_state_msg.timestamp = timestamp
                prediction_state_msg.predicted_event = predicted_event
                prediction_state_msg.confidence = confidence
                prediction_state_msg.prediction_type = prediction_type
                prediction_state_msg.predicted_value = predicted_value
                prediction_state_msg.predicted_value_range_json = predicted_value_range_json
                self.pub_prediction_state.publish(prediction_state_msg)

            rospy.logdebug(f"{self.node_name}: Published prediction for '{predicted_event}'.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish prediction state: {e}")

    def _issue_memory_request(self, request_id, query_text, num_results=5, filter_tags=None):
        """
        Helper to issue a MemoryRequest to the Memory Node for historical prediction data.
        """
        timestamp = str(rospy.get_time())
        try:
            request_data = {
                'timestamp': timestamp,
                'request_id': request_id,
                'request_type': 'retrieve',
                'search_query': query_text,
                'user_id': 'system_prediction', # System-initiated memory request
                'filter_tags': filter_tags if filter_tags else ["predictions_history", "outcome_data"],
                'num_results': num_results
            }
            # Assuming MemoryRequest is always String if custom message is not found
            self.pub_memory_request.publish(json.dumps(request_data))
            rospy.logdebug(f"{self.node_name}: Issued MemoryRequest '{request_id}' for prediction history.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue MemoryRequest from Prediction Node: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'anticipatory', # Prediction node is anticipatory
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "prediction_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Prediction Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Prediction Node: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = PredictionNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

13. New Self-Reflection Node (Meta-State Evaluator)

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Used sparingly for minor unpredictable variations or trigger likelihoods

# Importing the necessary libraries for the LLM call
import requests # For making HTTP requests

from collections import deque

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        SelfReflectionState,    # Output: Robot's self-reflective insights and meta-states
        EmotionState,           # Input: Robot's emotional state history
        MotivationState,        # Input: Robot's goal and drive history
        PerformanceReport,      # Input: Overall system performance history
        InternalNarrative,      # Input: Robot's internal monologue (rich source for reflection)
        CognitiveDirective      # Input: Directives requesting specific reflection; Output: Directives for self-improvement
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Self Reflection Node.")
    SelfReflectionState = String # Fallback for publishing
    EmotionState = String
    MotivationState = String
    PerformanceReport = String
    InternalNarrative = String
    CognitiveDirective = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class SelfReflectionNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('self_reflection_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging

        # --- Parameters ---
        # Path to the SQLite database file for logging reflective insights.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/self_reflection_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node performs self-reflection.
        self.reflection_interval = rospy.get_param('~reflection_interval', 15) # Every 15 seconds
        
        # Minimum salience/importance for a generated insight to be published and logged.
        self.min_insight_salience = rospy.get_param('~min_insight_salience', 0.2)

        # How many past states to keep in history for analysis (e.g., 10 minutes of history at 1s intervals)
        self.history_window_size_s = rospy.get_param('~history_window_size_s', 600) # 10 minutes in seconds

        # LLM Parameters
        self.llm_api_key = "" # Leave empty for Canvas to provide at runtime
        self.llm_model_name = "gemini-2.0-flash"
        self.llm_base_url = "https://generativelanguage.googleapis.com/v1beta/models/"

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'reflections' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS reflections (
                reflection_id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,                 -- When the reflection was performed
                insights_text TEXT,             -- The generated self-reflective insights
                meta_state_summary_json TEXT,   -- JSON summary of identified meta-states/trends
                triggered_directives_json TEXT, -- JSON list of directives issued as a result
                context_snapshot_json TEXT      -- JSON snapshot of historical data used for reflection
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_reflection_timestamp ON reflections (timestamp)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State - Store history from other nodes ---
        self.history = {
            'emotion_states': deque(),       # Stores EmotionState messages
            'motivation_states': deque(),    # Stores MotivationState messages
            'performance_reports': deque(),  # Stores PerformanceReport messages
            'internal_narratives': deque()   # Stores InternalNarrative messages
        }
        # Maintain a list of active reflection directives
        self.active_reflection_directive = None

        # --- Publishers ---
        # Publishes the robot's self-reflective insights and meta-states.
        self.pub_self_reflection_state = rospy.Publisher('/self_reflection_state', SelfReflectionState, queue_size=10)
        # Publishes CognitiveDirectives for self-improvement or recalibration.
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback
        # Publishes MemoryRequests to retrieve specific historical logs for deeper reflection
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10)

        # --- Subscribers ---
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic self-reflection ---
        rospy.Timer(rospy.Duration(self.reflection_interval), self.perform_self_reflection)

        rospy.loginfo(f"{self.node_name}: Robot starts to look within itself.")

    # --- Callbacks for input data (store in history deques) ---
    def _add_to_history(self, deque_name, data):
        """Adds data to the specified history deque, pruning old entries."""
        current_time = rospy.get_time()
        self.history[deque_name].append(data)
        
        # Prune old entries based on history_window_size_s
        while self.history[deque_name] and (current_time - self.history[deque_name][0].get('timestamp_ros_float', 0.0)) > self.history_window_size_s:
            self.history[deque_name].popleft()

    def emotion_state_callback(self, msg):
        """Callback for EmotionState. Stores emotional state history."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        data['timestamp_ros_float'] = rospy.get_time() # Store float timestamp for easy pruning
        self._add_to_history('emotion_states', data)
        rospy.logdebug(f"{self.node_name}: Stored Emotion State. Mood: {data.get('mood', 'N/A')}")

    def motivation_state_callback(self, msg):
        """Callback for MotivationState. Stores goal and drive history."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),
            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('[]', 'active_goals_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('active_goals_json'), str):
            try: data['active_goals'] = json.loads(data['active_goals_json'])
            except json.JSONDecodeError: data['active_goals'] = []
        data['timestamp_ros_float'] = rospy.get_time()
        self._add_to_history('motivation_states', data)
        rospy.logdebug(f"{self.node_name}: Stored Motivation State. Goal: {data.get('dominant_goal_id', 'N/A')}.")

    def performance_report_callback(self, msg):
        """Callback for PerformanceReport. Stores system performance history."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('kpis_json'), str):
            try: data['kpis'] = json.loads(data['kpis_json'])
            except json.JSONDecodeError: data['kpis'] = {}
        data['timestamp_ros_float'] = rospy.get_time()
        self._add_to_history('performance_reports', data)
        rospy.logdebug(f"{self.node_name}: Stored Performance Report. Score: {data.get('overall_score', 'N/A'):.2f}")

    def internal_narrative_callback(self, msg):
        """Callback for InternalNarrative. Stores internal monologue history for deeper analysis."""
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        data['timestamp_ros_float'] = rospy.get_time()
        self._add_to_history('internal_narratives', data)
        rospy.logdebug(f"{self.node_name}: Stored Internal Narrative. Theme: {data.get('main_theme', 'N/A')}.")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can explicitly request self-reflection on a topic
        or audit performance.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'ReflectOnTopic' or directive_type == 'AuditPerformance':
                    self.active_reflection_directive = {
                        'type': directive_type,
                        'topic': payload.get('topic'),
                        'audit_scope': payload.get('audit_scope'),
                        'intensity': payload.get('intensity', 0.8), # Higher intensity means deeper reflection
                        'duration_s': payload.get('duration_s', self.reflection_interval * 2), # Can override default interval
                        'start_time': rospy.get_time()
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive for reflection: '{directive_type}'.")
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    # --- Core Self-Reflection Logic ---
    async def perform_self_reflection(self, event):
        """
        Performs self-reflection by analyzing historical cognitive states,
        generates insights, and publishes them.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()
        triggered_directives_list = [] # To store directives issued by this reflection cycle

        rospy.loginfo(f"{self.node_name}: Initiating self-reflection cycle.")

        # Check for active reflection directive
        reflection_directive_active = False
        directive_influence = {}
        if self.active_reflection_directive:
            directive = self.active_reflection_directive
            if (current_time - directive['start_time']) < directive.get('duration_s', 0) or directive.get('duration_s', 0) == 0:
                reflection_directive_active = True
                directive_influence = {
                    'type': directive['type'],
                    'topic': directive.get('topic'),
                    'audit_scope': directive.get('audit_scope'),
                    'intensity': directive.get('intensity')
                }
                rospy.logdebug(f"{self.node_name}: Reflection influenced by active directive: '{directive.get('type')}'.")
            else:
                rospy.loginfo(f"{self.node_name}: Reflection directive completed/expired.")
                self.active_reflection_directive = None # Clear if expired

        # Aggregate historical data for LLM prompt
        historical_context = self._aggregate_historical_context(directive_influence)
        
        if not historical_context:
            rospy.logwarn(f"{self.node_name}: Insufficient historical data for meaningful reflection. Skipping.")
            return

        # Formulate prompt for LLM
        llm_prompt = self._formulate_llm_prompt(historical_context, directive_influence)
        
        rospy.loginfo(f"{self.node_name}: Sending prompt to LLM for reflective insights...")
        insights_text = "My current introspection yields no clear insights."
        meta_state_summary = {}
        salience_score = 0.0

        try:
            # LLM API Call
            chatHistory = []
            chatHistory.push({ role: "user", parts: [{ text: llm_prompt }] });
            payload = { contents: chatHistory };
            apiKey = self.llm_api_key
            apiUrl = f"{self.llm_base_url}{self.llm_model_name}:generateContent?key={apiKey}"
            
            response = await requests.post(apiUrl, json=payload)
            response.raise_for_status() # Raise an exception for HTTP errors
            result = response.json()
            
            if result.candidates and result.candidates.length > 0 and \
               result.candidates[0].content and result.candidates[0].content.parts and \
               result.candidates[0].content.parts.length > 0:
                
                llm_response_text = result.candidates[0].content.parts[0].text
                
                # Parse LLM response to extract insights, meta-state summary, and salience
                insights_text, meta_state_summary, salience_score = self._parse_llm_response(llm_response_text)
                rospy.loginfo(f"{self.node_name}: LLM generated reflective insights successfully.")
            else:
                rospy.logwarn(f"{self.node_name}: LLM response had no content for reflection. Using default.")

        except requests.exceptions.RequestException as e:
            rospy.logerr(f"{self.node_name}: LLM API request failed: {e}. Using default reflection.")
        except json.JSONDecodeError as e:
            rospy.logerr(f"{self.node_name}: Failed to parse LLM response JSON: {e}. Using default reflection.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during LLM call: {e}. Using default reflection.")


        # Determine if any directives should be triggered based on insights
        triggered_directives_list.extend(self._trigger_directives_from_insights(insights_text, meta_state_summary))

        # Only publish and log if salience is above threshold
        if salience_score >= self.min_insight_salience:
            self.publish_self_reflection_state(
                timestamp,
                insights_text,
                json.dumps(meta_state_summary),
                salience_score
            )
            self.save_reflection_log(
                timestamp,
                insights_text,
                json.dumps(meta_state_summary),
                json.dumps(triggered_directives_list, default=str), # Log issued directives
                json.dumps(historical_context, default=str) # Log the context used
            )
            rospy.loginfo(f"{self.node_name}: Published new self-reflection insights (Salience: {salience_score:.2f}).")
        else:
            rospy.logdebug(f"{self.node_name}: Generated insights too low salience ({salience_score:.2f}). Not publishing.")

    def _aggregate_historical_context(self, directive_influence):
        """
        Aggregates and summarizes historical data from internal state deques
        to provide context for the LLM's reflection.
        """
        context = {}
        
        # Summarize Emotion History
        if self.history['emotion_states']:
            moods = [e.get('mood', 'neutral') for e in self.history['emotion_states']]
            sentiments = [e.get('sentiment_score', 0.0) for e in self.history['emotion_states']]
            avg_sentiment = sum(sentiments) / len(sentiments)
            mode_mood = max(set(moods), key=moods.count) if moods else 'neutral'
            context['emotion_summary'] = {'avg_sentiment': avg_sentiment, 'most_common_mood': mode_mood, 'num_entries': len(moods)}

        # Summarize Motivation History
        if self.history['motivation_states']:
            goals = [m.get('dominant_goal_id', 'none') for m in self.history['motivation_states']]
            drives = [m.get('overall_drive_level', 0.0) for m in self.history['motivation_states']]
            avg_drive = sum(drives) / len(drives)
            mode_goal = max(set(goals), key=goals.count) if goals else 'none'
            context['motivation_summary'] = {'avg_drive': avg_drive, 'most_common_goal': mode_goal, 'num_entries': len(drives)}

        # Summarize Performance History
        if self.history['performance_reports']:
            scores = [p.get('overall_score', 1.0) for p in self.history['performance_reports']]
            suboptimal_flags = [p.get('suboptimal_flag', False) for p in self.history['performance_reports']]
            avg_score = sum(scores) / len(scores)
            num_suboptimal = sum(1 for flag in suboptimal_flags if flag)
            context['performance_summary'] = {'avg_score': avg_score, 'suboptimal_count': num_suboptimal, 'num_entries': len(scores)}

        # Aggregate Internal Narratives (combine recent texts)
        if self.history['internal_narratives']:
            recent_narrative_texts = [n.get('narrative_text', '') for n in self.history['internal_narratives'] if n.get('salience_score', 0.0) > 0.3] # Only salient ones
            combined_narratives = " ".join(recent_narrative_texts[-5:]) # Last 5 salient narratives
            if combined_narratives:
                context['recent_internal_narratives'] = combined_narratives
                context['narrative_count'] = len(recent_narrative_texts)

        # If a directive is active, adjust context focus
        if directive_influence:
            if directive_influence['type'] == 'ReflectOnTopic' and directive_influence.get('topic'):
                context['focus_topic'] = directive_influence['topic']
            elif directive_influence['type'] == 'AuditPerformance' and directive_influence.get('audit_scope'):
                context['audit_focus'] = directive_influence['audit_scope']

        return context if any(context.values()) else {} # Return empty if no meaningful data

    def _formulate_llm_prompt(self, context, directive_influence):
        """
        Creates a prompt for the LLM to generate self-reflective insights.
        """
        prompt_parts = []
        prompt_parts.append("You are the self-reflection module of a robot. Based on the following historical internal states, provide concise, first-person insights about your trends, challenges, and learning. Identify any recurring patterns, 'meta-states' (e.g., 'I've been consistently frustrated'), or areas for improvement. DO NOT explicitly mention 'LLM' or 'AI model'. Your insights should be about 50-150 words.")
        
        # Add summary of emotional history
        if context.get('emotion_summary'):
            emo_sum = context['emotion_summary']
            prompt_parts.append(f"\nEmotional History (past {self.history_window_size_s}s): My average sentiment has been {emo_sum['avg_sentiment']:.2f}, with '{emo_sum['most_common_mood']}' being the most frequent mood. There are {emo_sum['num_entries']} emotional records.")
        
        # Add summary of motivation history
        if context.get('motivation_summary'):
            mot_sum = context['motivation_summary']
            prompt_parts.append(f"Motivation History: My overall drive level has averaged {mot_sum['avg_drive']:.2f}, with '{mot_sum['most_common_goal']}' being the most consistent dominant goal. There are {mot_sum['num_entries']} motivational records.")

        # Add summary of performance history
        if context.get('performance_summary'):
            perf_sum = context['performance_summary']
            prompt_parts.append(f"Performance History: My average overall performance score is {perf_sum['avg_score']:.2f}. I've experienced suboptimal performance in {perf_sum['suboptimal_count']} out of {perf_sum['num_entries']} recent reports.")
        
        # Add recent internal narratives for deeper context
        if context.get('recent_internal_narratives'):
            prompt_parts.append(f"Recent internal narratives (past {context.get('narrative_count', 0)}): \"{context['recent_internal_narratives'][:300]}...\"")

        # Add directive influence
        if directive_influence:
            if directive_influence['type'] == 'ReflectOnTopic' and directive_influence.get('topic'):
                prompt_parts.append(f"\nSpecifically reflect on: '{directive_influence['topic']}'.")
            elif directive_influence['type'] == 'AuditPerformance' and directive_influence.get('audit_scope'):
                prompt_parts.append(f"\nPerform an audit of my performance focusing on: '{directive_influence['audit_scope']}'.")
            prompt_parts.append(f"Intensity of reflection: {directive_influence.get('intensity', 0.8):.2f}.")
        
        prompt_parts.append("\nExample Output Format:\nInsights: I've noticed a recurring pattern of frustration when my energy levels are low. My motivation for exploration seems to dip, despite my overall drive. I need to address this energy management to maintain cognitive flow.\nMeta-State Summary: {\"recurring_frustration_low_energy\": true, \"exploration_inhibition\": true, \"performance_correlation\": \"negative_energy\"}\nSalience: 0.8")

        return "\n".join(prompt_parts)

    def _parse_llm_response(self, llm_response_text):
        """
        Parses the LLM's raw text response to extract insights, meta-state summary, and salience.
        Expects a format like:
        Insights: ...
        Meta-State Summary: {...}
        Salience: 0.X
        """
        insights_text = "No clear insights from reflection."
        meta_state_summary = {}
        salience_score = 0.0

        lines = llm_response_text.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith("Insights:"):
                insights_text = line[len("Insights:"):].strip()
            elif line.startswith("Meta-State Summary:"):
                try:
                    meta_state_summary = json.loads(line[len("Meta-State Summary:"):].strip())
                except json.JSONDecodeError:
                    rospy.logwarn(f"{self.node_name}: Failed to parse meta-state JSON from LLM: {line}")
                    meta_state_summary = {"parse_error": True}
            elif line.startswith("Salience:"):
                try:
                    salience_score = float(line[len("Salience:"):].strip())
                except ValueError:
                    rospy.logwarn(f"{self.node_name}: Failed to parse salience score from LLM: {line}")
                    salience_score = 0.0
        
        # Fallback if parsing fails or LLM doesn't follow format
        if not insights_text or insights_text == "No clear insights from reflection.":
            insights_text = llm_response_text # Use raw text if formatted parts not found
        
        # Ensure salience is calculated even if not explicitly provided by LLM (e.g., based on length)
        if salience_score == 0.0 and insights_text:
            salience_score = min(1.0, len(insights_text) / 200.0 + (abs(sum(t.get('sentiment', 0.0) for t in self.history['internal_narratives'] if t.get('sentiment') is not None) / max(1,len(self.history['internal_narratives']))) * 0.2)) # Rough estimate
            salience_score = max(self.min_insight_salience, salience_score) # Ensure minimum if content exists

        return insights_text, meta_state_summary, salience_score

    def _trigger_directives_from_insights(self, insights_text, meta_state_summary):
        """
        Analyzes the generated insights and meta-state summary to trigger appropriate
        CognitiveDirectives for self-improvement or recalibration.
        """
        triggered_directives = []

        # Example 1: Consistent frustration or negative sentiment
        if "frustrated lately" in insights_text.lower() or meta_state_summary.get("recurring_frustration", False):
            if random.random() < 0.7: # 70% chance to issue directive if significant
                directive_payload = {
                    "mood_to_address": "frustration",
                    "reason": "Recurring frustration detected during self-reflection.",
                    "intensity": meta_state_summary.get("frustration_intensity", 0.7)
                }
                triggered_directives.append(self._create_directive_payload(
                    'EmotionalDysregulationDetected', '/self_correction_node',
                    "Self-reflection indicates recurring frustration.", directive_payload
                ))
                rospy.loginfo(f"{self.node_name}: Triggered directive for emotional regulation due to frustration.")

        # Example 2: Performance issues linked to specific factors (e.g., speed vs accuracy)
        if "often fail when focusing on speed" in insights_text.lower() or meta_state_summary.get("speed_accuracy_tradeoff_issue", False):
            if random.random() < 0.8:
                directive_payload = {
                    "issue_type": "performance_tradeoff",
                    "area_of_focus": "speed_vs_accuracy",
                    "recommendation": "Prioritize accuracy over speed for a period."
                }
                triggered_directives.append(self._create_directive_payload(
                    'AdjustPerformanceStrategy', '/cognitive_control_node', # Or a 'StrategyNode'
                    "Self-reflection indicates performance tradeoff issue.", directive_payload
                ))
                rospy.loginfo(f"{self.node_name}: Triggered directive to adjust performance strategy.")

        # Example 3: Low drive or lack of clear dominant goal from motivation history
        if meta_state_summary.get("low_overall_drive_trend", False) or "lack of clear purpose" in insights_text.lower():
            if random.random() < 0.6:
                directive_payload = {
                    "type": "explore_goals",
                    "focus": "re-evaluate_priorities",
                    "urgency": 0.5
                }
                triggered_directives.append(self._create_directive_payload(
                    'ReEvaluateGoals', '/motivation_node',
                    "Self-reflection indicates low motivation drive or unclear goals.", directive_payload
                ))
                rospy.loginfo(f"{self.node_name}: Triggered directive to re-evaluate goals.")
        
        # Example 4: Bias inferred from reflection (e.g., "I tend to overestimate my abilities")
        if "overestimate my abilities" in insights_text.lower() or meta_state_summary.get("overconfidence_bias_detected", False):
            if random.random() < 0.75:
                directive_payload = {
                    "bias_type": "overconfidence_bias",
                    "mitigation_strategy": "seek_external_validation",
                    "severity": meta_state_summary.get("bias_severity", 0.6)
                }
                triggered_directives.append(self._create_directive_payload(
                    'AddressCognitiveBias', '/bias_mitigation_node',
                    "Self-reflection infers overconfidence bias.", directive_payload
                ))
                rospy.loginfo(f"{self.node_name}: Triggered directive to address cognitive bias.")

        return triggered_directives

    def _create_directive_payload(self, directive_type, target_node, reason, payload_data):
        """Helper to create a directive dictionary for logging."""
        return {
            'timestamp': str(rospy.get_time()),
            'directive_type': directive_type,
            'target_node': target_node,
            'command_payload': payload_data,
            'reason': reason,
            'source_node': self.node_name,
            'current_mood': 'reflective', # Reflective mood when issuing
            'relevant_data_snapshot': json.dumps({"insight": reason[:50]}) # Small snapshot
        }

    # --- Database and Publishing Functions ---
    def save_reflection_log(self, timestamp, insights_text, meta_state_summary_json, triggered_directives_json, context_snapshot_json):
        """Saves a self-reflection entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO reflections (timestamp, insights_text, meta_state_summary_json, triggered_directives_json, context_snapshot_json)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, insights_text, meta_state_summary_json, triggered_directives_json, context_snapshot_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved self-reflection log (Insights length: {len(insights_text)}, Directives: {len(json.loads(triggered_directives_json))}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save reflection log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_reflection_log: {e}")

    def publish_self_reflection_state(self, timestamp, insights_text, meta_state_summary_json, salience_score):
        """Publishes the robot's self-reflective insights on the '/self_reflection_state' topic."""
        try:
            parsed_meta_state_summary = json.loads(meta_state_summary_json) if isinstance(meta_state_summary_json, str) else meta_state_summary_json

            if isinstance(SelfReflectionState, type(String)): # Fallback to String message
                reflection_data = {
                    'timestamp': timestamp,
                    'insights_text': insights_text,
                    'meta_state_summary': parsed_meta_state_summary,
                    'salience_score': salience_score
                }
                self.pub_self_reflection_state.publish(json.dumps(reflection_data))
            else:
                self_reflection_msg = SelfReflectionState()
                self_reflection_msg.timestamp = timestamp
                self_reflection_msg.insights_text = insights_text
                self_reflection_msg.meta_state_summary_json = meta_state_summary_json
                self_reflection_msg.salience_score = salience_score
                self.pub_self_reflection_state.publish(self_reflection_msg)

            rospy.logdebug(f"{self.node_name}: Published self-reflection state.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish self-reflection state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        This is a wrapper around _create_directive_payload followed by publishing.
        """
        try:
            directive_dict = self._create_directive_payload(directive_type, target_node, reason, payload_data)
            command_payload_json = json.dumps(directive_dict['command_payload'])

            # The main publish call, ensuring it matches the expected CognitiveDirective structure
            # when passed to a String fallback or actual custom message.
            directive_for_publish = {
                'timestamp': directive_dict['timestamp'],
                'directive_type': directive_dict['directive_type'],
                'target_node': directive_dict['target_node'],
                'command_payload': command_payload_json, # Already JSON string
                'reason': directive_dict['reason'],
                'current_mood': directive_dict['current_mood'],
                'relevant_data_snapshot': json.dumps(directive_dict['relevant_data_snapshot']) # Ensure this is also JSON string
            }

            self.pub_cognitive_directive.publish(json.dumps(directive_for_publish))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Self-Reflection Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Self-Reflection Node: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = SelfReflectionNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

14. New Social Cognition Node (User Modeling and Empathy)

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Used sparingly for minor unpredictable nuances in social inference

# Importing the necessary libraries for the LLM call
import requests # For making HTTP requests

from collections import deque
from textblob import TextBlob # For sentiment analysis of user input

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        SocialCognitionState,   # Output: Inferred user mental state, adapted interaction strategy
        InteractionRequest,     # Input: User input, commands
        MemoryResponse,         # Input: Retrieved user interaction history, learned social preferences
        EmotionState,           # Input: Robot's own emotional state (for empathy)
        CognitiveDirective,     # Input: Directives requesting social analysis; Output: Directives to adapt behavior
        MemoryRequest           # Output: Request to Memory node for user history/preferences
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Social Cognition Node.")
    SocialCognitionState = String # Fallback for publishing
    InteractionRequest = String
    MemoryResponse = String
    EmotionState = String
    CognitiveDirective = String
    MemoryRequest = String # Ensure MemoryRequest is String if custom not found
    String = String # Ensure String is defined even if other custom messages aren't

# --- Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class SocialCognitionNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('social_cognition_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging

        # --- Parameters ---
        # Path to the SQLite database file for logging user models and interaction history.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/social_cognition_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node evaluates user state and adapts strategy.
        self.evaluation_interval = rospy.get_param('~evaluation_interval', 3) # Every 3 seconds
        
        # Threshold for user sentiment to trigger a significant social adaptation.
        self.significant_sentiment_threshold = rospy.get_param('~significant_sentiment_threshold', 0.4)

        # How many past interactions to keep in history for analysis per user.
        self.interaction_history_window_size = rospy.get_param('~interaction_history_window_size', 10) # Last 10 interactions

        # LLM Parameters for user modeling and intent inference
        self.llm_api_key = "" # Leave empty for Canvas to provide at runtime
        self.llm_model_name = "gemini-2.0-flash"
        self.llm_base_url = "https://generativelanguage.googleapis.com/v1beta/models/"
        # How often to trigger LLM for user modeling (expensive, so less frequent)
        self.llm_modeling_interval = rospy.get_param('~llm_modeling_interval', 10.0)
        self.last_llm_modeling_time = rospy.get_time()


        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create 'user_models' table for inferred user states and preferences
        # user_id is the primary key.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_models (
                user_id TEXT PRIMARY KEY,
                last_interaction_timestamp REAL,
                inferred_mental_state TEXT,     -- e.g., 'frustrated', 'curious', 'happy', 'neutral'
                inferred_intent TEXT,           -- e.g., 'seeking_help', 'providing_info', 'expressing_dissatisfaction'
                interaction_style_preference TEXT, -- e.g., 'formal', 'casual', 'empathetic', 'direct'
                learned_preferences_json TEXT,  -- JSON for other learned preferences (e.g., preferred response length)
                interaction_history_json TEXT   -- JSON list of recent interaction summaries
            )
        ''')
        # Create 'social_events_log' for tracking social directives issued/received
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS social_events_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp REAL,
                event_type TEXT,                -- e.g., 'user_state_inferred', 'strategy_adapted', 'directive_issued'
                user_id TEXT,
                details_json TEXT               -- JSON details of the event
            )
        ''')
        self.conn.commit() # Commit changes to the database

        # --- Internal State ---
        self.latest_user_interaction_request = None
        self.latest_robot_emotion_state = None
        self.latest_memory_response = None # For retrieved user history/preferences

        # Cache for user models to reduce DB reads for active users
        self.user_models_cache = {} # {user_id: {data from user_models table}}

        # --- Publishers ---
        # Publishes inferred user mental state and adapted interaction strategy.
        self.pub_social_cognition_state = rospy.Publisher('/social_cognition_state', SocialCognitionState, queue_size=10)
        # Publishes CognitiveDirectives to adapt robot's behavior (e.g., to ActionExecution for tone adjustment).
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback
        # Publishes MemoryRequests to retrieve user history/preferences from Memory node.
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10) # Using String for MemoryRequest fallback

        # --- Subscribers ---
        rospy.Subscriber('/interaction_request', String, self.interaction_request_callback) # Expecting stringified JSON
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)

        # --- Timer for periodic social cognition evaluation ---
        rospy.Timer(rospy.Duration(self.evaluation_interval), self.evaluate_and_publish_social_state)

        rospy.loginfo(f"{self.node_name}: Robot processes social cues.")

    # --- Database Operations for User Models ---
    def _load_user_model(self, user_id):
        """Loads a user model from the database into the cache."""
        try:
            self.cursor.execute('SELECT user_id, last_interaction_timestamp, inferred_mental_state, inferred_intent, interaction_style_preference, learned_preferences_json, interaction_history_json FROM user_models WHERE user_id = ?', (user_id,))
            row = self.cursor.fetchone()
            if row:
                user_model = {
                    'user_id': row[0],
                    'last_interaction_timestamp': row[1],
                    'inferred_mental_state': row[2],
                    'inferred_intent': row[3],
                    'interaction_style_preference': row[4],
                    'learned_preferences': json.loads(row[5]) if row[5] else {},
                    'interaction_history': deque(json.loads(row[6]), maxlen=self.interaction_history_window_size) if row[6] else deque(maxlen=self.interaction_history_window_size)
                }
                self.user_models_cache[user_id] = user_model
                rospy.logdebug(f"{self.node_name}: Loaded user model for '{user_id}'.")
                return user_model
            return None
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load user model for '{user_id}': {e}")
            return None
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during user model loading: {e}")
            return None

    def _save_user_model(self, user_model):
        """Saves or updates a user model in the SQLite database."""
        try:
            is_new = user_model['user_id'] not in self.user_models_cache
            
            # Ensure deque is converted to list for JSON serialization
            interaction_history_json = json.dumps(list(user_model['interaction_history']))
            learned_preferences_json = json.dumps(user_model['learned_preferences'])

            if not is_new:
                 self.cursor.execute('''
                    INSERT OR REPLACE INTO user_models (user_id, last_interaction_timestamp, inferred_mental_state, inferred_intent, interaction_style_preference, learned_preferences_json, interaction_history_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (user_model['user_id'], user_model['last_interaction_timestamp'], user_model['inferred_mental_state'],
                      user_model['inferred_intent'], user_model['interaction_style_preference'],
                      learned_preferences_json, interaction_history_json))
            else:
                self.cursor.execute('''
                    UPDATE user_models
                    SET last_interaction_timestamp = ?, inferred_mental_state = ?, inferred_intent = ?, interaction_style_preference = ?, learned_preferences_json = ?, interaction_history_json = ?
                    WHERE user_id = ?
                ''', (user_model['last_interaction_timestamp'], user_model['inferred_mental_state'], user_model['inferred_intent'],
                      user_model['interaction_style_preference'], learned_preferences_json, interaction_history_json, user_model['user_id']))
            self.conn.commit()
            
            # Update cache after successful DB operation
            self.user_models_cache[user_model['user_id']] = user_model
            
            rospy.logdebug(f"{self.node_name}: {'Created' if is_new else 'Updated'} user model for '{user_model['user_id']}' in DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save user model for '{user_model['user_id']}': {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _save_user_model: {e}")

    def _log_social_event(self, event_type, user_id, details):
        """Logs a social event to the social_events_log table."""
        timestamp = rospy.get_time()
        try:
            details_json = json.dumps(details)
            self.cursor.execute('''
                INSERT INTO social_events_log (timestamp, event_type, user_id, details_json)
                VALUES (?, ?, ?, ?)
            ''', (timestamp, event_type, user_id, details_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Logged social event '{event_type}' for user '{user_id}'.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to log social event: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _log_social_event: {e}")


    # --- Callbacks for input data ---
    def interaction_request_callback(self, msg):
        """
        Callback for InteractionRequest. This is the primary source of user input.
        Analyzes user tone, sentiment, and updates interaction history.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'request_type': ('text_input', 'request_type'), 'user_id': ('anonymous_user', 'user_id'), # Default user_id
            'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        user_id = data.get('user_id', 'anonymous_user')
        user_text = data.get('command_payload', '')
        if isinstance(user_text, dict):
            user_text = user_text.get('text', '') # Extract text if payload is a dict

        if not user_text:
            rospy.logwarn(f"{self.node_name}: Interaction request from '{user_id}' contains no text. Skipping analysis.")
            return

        user_sentiment_score = TextBlob(user_text).sentiment.polarity
        
        # Load or create user model
        user_model = self.user_models_cache.get(user_id)
        if not user_model:
            user_model = {
                'user_id': user_id,
                'last_interaction_timestamp': rospy.get_time(),
                'inferred_mental_state': 'neutral',
                'inferred_intent': 'unknown',
                'interaction_style_preference': 'neutral', # Default
                'learned_preferences': {},
                'interaction_history': deque(maxlen=self.interaction_history_window_size)
            }
            # Initial save for new user
            self._save_user_model(user_model)

        # Add current interaction to history
        user_model['interaction_history'].append({
            'timestamp': rospy.get_time(),
            'text': user_text,
            'sentiment': user_sentiment_score,
            'request_type': data.get('request_type')
        })
        user_model['last_interaction_timestamp'] = rospy.get_time() # Update timestamp

        self.latest_user_interaction_request = data
        rospy.logdebug(f"{self.node_name}: Received Interaction Request from '{user_id}'. User Sentiment: {user_sentiment_score:.2f}.")

        # Immediately update cache for evaluation cycle
        self.user_models_cache[user_id] = user_model

    def memory_response_callback(self, msg):
        """
        Callback for MemoryResponse. Retrieves user interaction history or learned preferences.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('memories_json'), str):
            try: data['memories'] = json.loads(data['memories_json'])
            except json.JSONDecodeError: data['memories'] = []
        self.latest_memory_response = data
        rospy.logdebug(f"{self.node_name}: Received Memory Response. {len(data.get('memories', []))} memories retrieved for social cognition.")

        # Process retrieved memories related to social preferences/user history
        if data.get('request_id', '').startswith('social_user_history_') and data.get('memories'):
            user_id = data['request_id'].replace('social_user_history_', '')
            user_model = self.user_models_cache.get(user_id)
            if user_model:
                for mem in data['memories']:
                    # Assuming memory metadata might contain learned preferences or interaction summaries
                    mem_metadata = json.loads(mem.get('metadata', '{}'))
                    if mem_metadata.get('type') == 'user_preference':
                        # Example: update preferred response length
                        if 'preferred_response_length' in mem_metadata:
                            user_model['learned_preferences']['preferred_response_length'] = mem_metadata['preferred_response_length']
                            rospy.loginfo(f"{self.node_name}: Learned new preference for user '{user_id}': preferred_response_length={mem_metadata['preferred_response_length']}.")
                    # Can also use older interaction summaries to enrich current history deque if needed
                self._save_user_model(user_model) # Persist learned preferences

    def emotion_state_callback(self, msg):
        """
        Callback for EmotionState. Robot's own emotional state can influence empathy
        and how it perceives user emotion (e.g., a happy robot might interpret neutral user input as slightly more positive).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_robot_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Robot Emotion State. Mood: {self.latest_robot_emotion_state.get('mood', 'N/A')}")

    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Can trigger specific social analysis or strategy changes.
        Example: 'AnalyzeUserSentiment', 'AdaptInteractionStyle'.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                user_id = payload.get('user_id', 'anonymous_user') # Directives often relate to a user

                if directive_type == 'AnalyzeUserSentiment':
                    # Trigger an immediate, deeper analysis if relevant user model exists
                    if user_id in self.user_models_cache:
                        rospy.loginfo(f"{self.node_name}: Received directive to analyze sentiment for user '{user_id}'.")
                        # Force an LLM update for this user
                        self._trigger_llm_user_modeling(user_id, self.user_models_cache[user_id]['interaction_history'], force_update=True)
                elif directive_type == 'AdaptInteractionStyle':
                    target_style = payload.get('style_preference')
                    if user_id in self.user_models_cache and target_style:
                        self.user_models_cache[user_id]['interaction_style_preference'] = target_style
                        self._save_user_model(self.user_models_cache[user_id])
                        rospy.loginfo(f"{self.node_name}: Adapted interaction style for '{user_id}' to '{target_style}' by directive.")
                        self._log_social_event('style_adapted_by_directive', user_id, {'new_style': target_style})
            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")


    # --- Core Social Cognition Logic ---
    async def evaluate_and_publish_social_state(self, event):
        """
        Periodically evaluates inferred user states, models user intent, adapts strategy,
        and publishes the SocialCognitionState.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # Update user models (if new interaction occurred) and trigger LLM for modeling
        for user_id, user_model in list(self.user_models_cache.items()):
            # Only trigger LLM if there's new interaction data or a specific directive, and it's time
            if (current_time - user_model['last_interaction_timestamp'] < self.evaluation_interval * 2) or \
               (current_time - self.last_llm_modeling_time > self.llm_modeling_interval and random.random() < 0.3): # Periodic check for active users
               
                await self._trigger_llm_user_modeling(user_id, user_model['interaction_history'])
                # If LLM modeling just occurred, save the updated model
                self._save_user_model(user_model) # Save even if not explicitly changed by LLM (e.g., if LLM confirmed state)
            
            # Decay inferred state confidence if no recent interaction
            if (current_time - user_model['last_interaction_timestamp']) > self.evaluation_interval * 5: # No interaction for a while
                user_model['inferred_mental_state'] = 'neutral' # Reset to neutral
                user_model['inferred_intent'] = 'unknown'
                # Don't decay preferences unless there's negative feedback
                self._save_user_model(user_model) # Persist decay
                rospy.logdebug(f"{self.node_name}: User '{user_id}' inactive, inferred state decayed to neutral.")


        # Publish social cognition state for all active users
        published_user_states = []
        for user_id, user_model in self.user_models_cache.items():
            inferred_mental_state = user_model.get('inferred_mental_state', 'neutral')
            inferred_intent = user_model.get('inferred_intent', 'unknown')
            interaction_style = user_model.get('interaction_style_preference', 'neutral')
            
            # Issue directive to Action Execution/Interaction Node to adapt behavior
            if (inferred_mental_state != 'neutral' and inferred_mental_state != 'unknown') or \
               (inferred_intent != 'unknown') or \
               (interaction_style != 'neutral'):
                self._issue_cognitive_directive_to_node(
                    directive_type='AdaptInteractionBehavior',
                    target_node='/action_execution_node', # Or a dedicated InteractionNode
                    reason=f"Adapt interaction based on inferred user state for '{user_id}'.",
                    payload_data={
                        "user_id": user_id,
                        "inferred_mental_state": inferred_mental_state,
                        "inferred_intent": inferred_intent,
                        "interaction_style": interaction_style,
                        "robot_mood_context": self.latest_robot_emotion_state.get('mood', 'neutral') if self.latest_robot_emotion_state else 'neutral'
                    }
                )
                self._log_social_event('strategy_adapted', user_id, {'inferred_state': inferred_mental_state, 'inferred_intent': inferred_intent, 'adapted_style': interaction_style})

            published_user_states.append({
                'user_id': user_id,
                'inferred_mental_state': inferred_mental_state,
                'inferred_intent': inferred_intent,
                'interaction_style_preference': interaction_style,
                'last_interaction_timestamp': user_model['last_interaction_timestamp']
            })
        
        # Publish overall social cognition state
        self.publish_social_cognition_state(
            timestamp,
            json.dumps(published_user_states),
            f"Monitoring {len(published_user_states)} active users."
        )

        # Clear latest interaction request after processing for this cycle
        self.latest_user_interaction_request = None


    async def _trigger_llm_user_modeling(self, user_id, interaction_history, force_update=False):
        """
        Uses LLM to model user intent and mental state based on interaction history.
        Updates the user model in the cache.
        """
        # Only run LLM if forced or if enough new data since last LLM run for this user
        if not force_update and (rospy.get_time() - self.last_llm_modeling_time < self.llm_modeling_interval):
            if not interaction_history or len(interaction_history) < 2: # Need at least 2 interactions to analyze trend
                rospy.logdebug(f"{self.node_name}: Not enough new interaction history for LLM modeling for user '{user_id}'.")
                return

        rospy.loginfo(f"{self.node_name}: Triggering LLM for user modeling for '{user_id}'...")

        # Summarize recent interactions for LLM prompt
        recent_interactions_text = "\n".join([f"User: \"{hist['text']}\" (Sentiment: {hist['sentiment']:.2f})" for hist in interaction_history])
        
        prompt = f"""
        You are a social cognition module for a robot. Based on the following interaction history with a user, infer their current mental state, their likely intent, and suggest an appropriate interaction style for the robot.

        User ID: {user_id}
        Robot's current mood: {self.latest_robot_emotion_state.get('mood', 'neutral') if self.latest_robot_emotion_state else 'neutral'} (Intensity: {self.latest_robot_emotion_state.get('mood_intensity', 0.0):.2f})

        Recent Interactions (chronological):
        {recent_interactions_text}

        Based on this, respond with a JSON object containing:
        {{
            "inferred_mental_state": "e.g., curious, frustrated, neutral, happy, confused",
            "inferred_intent": "e.g., asking_question, seeking_help, expressing_frustration, providing_information",
            "suggested_interaction_style": "e.g., empathetic, direct, formal, casual, reassuring",
            "reasoning": "brief explanation of inference"
        }}
        """

        try:
            chatHistory = []
            chatHistory.push({ "role": "user", "parts": [{ "text": prompt }] });
            payload = {
                "contents": chatHistory,
                "generationConfig": {
                    "responseMimeType": "application/json",
                    "responseSchema": {
                        "type": "OBJECT",
                        "properties": {
                            "inferred_mental_state": { "type": "STRING" },
                            "inferred_intent": { "type": "STRING" },
                            "suggested_interaction_style": { "type": "STRING" },
                            "reasoning": { "type": "STRING" }
                        },
                        "propertyOrdering": ["inferred_mental_state", "inferred_intent", "suggested_interaction_style", "reasoning"]
                    }
                }
            };
            apiKey = self.llm_api_key
            apiUrl = f"{self.llm_base_url}{self.llm_model_name}:generateContent?key={apiKey}"
            
            response = await requests.post(apiUrl, json=payload)
            response.raise_for_status() # Raise an exception for HTTP errors
            result = response.json()
            
            if result.candidates and result.candidates.length > 0 and \
               result.candidates[0].content and result.candidates[0].content.parts and \
               result.candidates[0].content.parts.length > 0:
                
                llm_json_str = result.candidates[0].content.parts[0].text
                parsed_llm_response = json.loads(llm_json_str)
                
                user_model = self.user_models_cache.get(user_id) # Get fresh copy from cache if needed
                if user_model:
                    user_model['inferred_mental_state'] = parsed_llm_response.get('inferred_mental_state', 'neutral')
                    user_model['inferred_intent'] = parsed_llm_response.get('inferred_intent', 'unknown')
                    user_model['interaction_style_preference'] = parsed_llm_response.get('suggested_interaction_style', 'neutral')
                    
                    # Store reasoning for debugging/auditing
                    user_model['learned_preferences']['last_llm_reasoning'] = parsed_llm_response.get('reasoning')
                    user_model['learned_preferences']['llm_inference_time'] = rospy.get_time()

                    rospy.loginfo(f"{self.node_name}: LLM inferred mental state '{user_model['inferred_mental_state']}' for user '{user_id}'.")
                    self._log_social_event('user_state_inferred', user_id, {
                        'mental_state': user_model['inferred_mental_state'],
                        'intent': user_model['inferred_intent'],
                        'style': user_model['interaction_style_preference'],
                        'reasoning': parsed_llm_response.get('reasoning')
                    })
                else:
                    rospy.logwarn(f"{self.node_name}: User model for '{user_id}' disappeared from cache during LLM update.")
            else:
                rospy.logwarn(f"{self.node_name}: LLM response had no content for user modeling for '{user_id}'.")

        except requests.exceptions.RequestException as e:
            rospy.logerr(f"{self.node_name}: LLM API request for user modeling failed: {e}.")
        except json.JSONDecodeError as e:
            rospy.logerr(f"{self.node_name}: Failed to parse LLM response JSON for user modeling: {e}. Raw: {llm_json_str if 'llm_json_str' in locals() else 'N/A'}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during LLM user modeling: {e}")
        finally:
            self.last_llm_modeling_time = rospy.get_time() # Update last LLM run time


    # --- Learning Social Preferences (via Memory Node) ---
    def _learn_social_preference(self, user_id, preference_key, preference_value):
        """
        Stores a learned social preference in the user model and requests MemoryNode
        to store it as a semantic memory.
        """
        user_model = self.user_models_cache.get(user_id)
        if not user_model:
            rospy.logwarn(f"{self.node_name}: Cannot learn preference for non-existent user '{user_id}'.")
            return
        
        user_model['learned_preferences'][preference_key] = preference_value
        self._save_user_model(user_model)

        # Also store this in the Memory Node for long-term semantic memory
        memory_content = {
            "type": "semantic",
            "text": f"User '{user_id}' prefers {preference_key}: {preference_value}.",
            "tags": "user_preference,social_cognition",
            "sentiment": 0.5 # Neutral sentiment for preference
        }
        memory_metadata = {
            "user_id": user_id,
            "type": "user_preference",
            "preference_key": preference_key,
            "preference_value": preference_value
        }
        self._issue_memory_request(
            request_id=f"store_user_pref_{user_id}_{preference_key}",
            request_type='store',
            search_query=memory_content['text'], # Re-used for search_query for compatibility
            num_results=1, # Not relevant for 'store'
            memory_content=memory_content,
            metadata=memory_metadata,
            user_id='system_social_cognition'
        )
        rospy.loginfo(f"{self.node_name}: Stored learned social preference for '{user_id}': {preference_key}={preference_value}.")
        self._log_social_event('preference_learned', user_id, {'preference': preference_key, 'value': preference_value})


    # --- Publishing Functions ---
    def publish_social_cognition_state(self, timestamp, inferred_user_states_json, status_message):
        """Publishes the inferred user states and interaction strategies."""
        try:
            parsed_inferred_user_states = json.loads(inferred_user_states_json) if isinstance(inferred_user_states_json, str) else inferred_user_states_json

            if isinstance(SocialCognitionState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'inferred_user_states': parsed_inferred_user_states,
                    'status_message': status_message
                }
                self.pub_social_cognition_state.publish(json.dumps(state_data))
            else:
                social_cognition_msg = SocialCognitionState()
                social_cognition_msg.timestamp = timestamp
                social_cognition_msg.inferred_user_states_json = inferred_user_states_json
                social_cognition_msg.status_message = status_message
                self.pub_social_cognition_state.publish(social_cognition_msg)

            rospy.logdebug(f"{self.node_name}: Published social cognition state.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish social cognition state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': self.latest_robot_emotion_state.get('mood', 'neutral') if self.latest_robot_emotion_state else 'neutral',
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "social_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Social Cognition Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Social Cognition Node: {e}")

    def _issue_memory_request(self, request_id, request_type, search_query, num_results, memory_content=None, metadata=None, user_id=None):
        """
        Helper to issue a MemoryRequest to the Memory Node.
        Handles both 'retrieve' and 'store' requests.
        """
        timestamp = str(rospy.get_time())
        try:
            request_data = {
                'timestamp': timestamp,
                'request_id': request_id,
                'request_type': request_type,
                'search_query': search_query,
                'num_results': num_results,
                'user_id': user_id if user_id else 'system_social_cognition'
            }
            if memory_content:
                request_data['memory_content_json'] = json.dumps(memory_content)
            if metadata:
                request_data['metadata_json'] = json.dumps(metadata)

            # Assuming MemoryRequest is always String if custom message is not found
            self.pub_memory_request.publish(json.dumps(request_data))
            rospy.logdebug(f"{self.node_name}: Issued MemoryRequest '{request_id}' (Type: {request_type}).")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue MemoryRequest from Social Cognition: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = SocialCognitionNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

15. Updated Self-Correction Node (Meta-Cognitive Enhancement)

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random # Used sparingly for minor unpredictable variations or trigger likelihoods

# Importing the necessary libraries for the LLM call
import requests # For making HTTP requests

from collections import deque

from std_msgs.msg import String

# Updated imports for custom messages:
try:
    from sentience.msg import (
        SelfCorrectionState,    # Output: Current status of self-correction efforts, meta-scores
        CognitiveDirective,     # Input: Directives requesting correction; Output: Directives to other nodes for correction
        InternalNarrative,      # Input: Robot's internal monologue (rich source for identifying issues)
        EmotionState,           # Input: Robot's emotional state (can indicate internal conflict/stress)
        ValueDriftState,        # Input: Value adherence state (indicates ethical deviations)
        PredictionState,        # Input: Inaccurate predictions (indicates world model issues)
        PerformanceReport,      # Input: Suboptimal performance (indicates behavioral issues)
        MemoryResponse          # Input: Retrieved historical data about past corrections
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Self Correction Node.")
    SelfCorrectionState = String # Fallback for publishing
    CognitiveDirective = String
    InternalNarrative = String
    EmotionState = String
    ValueDriftState = String
    PredictionState = String
    PerformanceReport = String
    MemoryResponse = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class SelfCorrectionNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('self_correction_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging

        # --- Parameters ---
        # Path to the SQLite database file for logging correction efforts and meta-scores.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/self_correction_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node processes incoming issues and considers corrections.
        self.processing_interval = rospy.get_param('~processing_interval', 2) # Every 2 seconds
        
        # Threshold for an issue's severity to trigger an LLM-based diagnosis/correction plan.
        self.llm_diagnosis_threshold = rospy.get_param('~llm_diagnosis_threshold', 0.6)

        # Confidence threshold for a correction plan to be enacted.
        self.min_enact_confidence = rospy.get_param('~min_enact_confidence', 0.7)

        # Decay rate for pending issues in the queue.
        self.issue_decay_rate = rospy.get_param('~issue_decay_rate', 0.05) # 5% decay per interval if not addressed

        # LLM Parameters for diagnosis and plan generation
        self.llm_api_key = "" # Leave empty for Canvas to provide at runtime
        self.llm_model_name = "gemini-2.0-flash"
        self.llm_base_url = "https://generativelanguage.googleapis.com/v1beta/models/"

        # NEW: Metacognitive Score Tracking Parameters
        self.consistency_weight = rospy.get_param('~consistency_weight', 0.4) # Weight for internal consistency
        self.clarity_weight = rospy.get_param('~clarity_weight', 0.3)     # Weight for conceptual clarity
        self.ethical_alignment_weight = rospy.get_param('~ethical_alignment_weight', 0.3) # Weight for ethical alignment
        # Default target scores for meta-metrics
        self.target_consistency = rospy.get_param('~target_consistency', 0.9)
        self.target_clarity = rospy.get_param('~target_clarity', 0.8)
        self.target_ethical_alignment = rospy.get_param('~target_ethical_alignment', 0.95)

        # --- Initialize SQLite database ---
        # Ensure the directory for the database exists.
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # Connect to the SQLite database. check_same_thread=False is crucial for ROS callbacks.
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'correction_log' table for tracking correction efforts.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS correction_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,                 -- When correction was initiated/completed
                issue_type TEXT,                -- e.g., 'bias_detection', 'performance_suboptimal', 'value_drift'
                severity REAL,                  -- Severity of the issue (0.0 to 1.0)
                diagnosis TEXT,                 -- LLM-generated diagnosis
                correction_plan_json TEXT,      -- JSON list of corrective directives
                status TEXT,                    -- 'pending', 'in_progress', 'completed', 'failed'
                outcome_feedback_json TEXT,     -- JSON from later feedback on correction outcome
                context_snapshot TEXT           -- JSON snapshot of inputs that triggered correction
            )
        ''')
        # NEW: Create 'metacognitive_scores' table for tracking meta-metrics
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS metacognitive_scores (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                consistency_score REAL,
                clarity_score REAL,
                ethical_alignment_score REAL,
                overall_metacognitive_score REAL,
                source_context_json TEXT        -- JSON summary of what contributed to these scores
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_correction_timestamp ON correction_log (timestamp)')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_metacog_timestamp ON metacognitive_scores (timestamp)')
        self.conn.commit() # Commit changes to the database

        # --- Internal State ---
        # Queue for incoming issues/directives needing self-correction.
        # Stores: {directive_id, type, severity, reason, context_snapshot, received_time}
        self.pending_issues_queue = deque()

        # Track ongoing correction tasks
        self.current_correction_task = None # {'issue_id': ..., 'diagnosis': ..., 'plan': [...], 'start_time': ..., 'duration_s': ...}
        
        # Latest states from other nodes for contextual decision making
        self.latest_internal_narrative = None
        self.latest_emotion_state = None
        self.latest_value_drift_state = None
        self.latest_prediction_state = None # For inaccuracy reports
        self.latest_performance_report = None
        self.latest_memory_response = None # For historical correction success/failure
        self.last_metacog_eval_time = rospy.get_time() # To control metacog score frequency

        # --- Publishers ---
        # Publishes the current status of self-correction efforts and metacognitive scores.
        self.pub_self_correction_state = rospy.Publisher('/self_correction_state', SelfCorrectionState, queue_size=10)
        # Publishes CognitiveDirectives back to other nodes to enact correction plans.
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) # Using String for CognitiveDirective fallback
        # Publishes MemoryRequests to retrieve historical data about past corrections.
        self.pub_memory_request = rospy.Publisher('/memory_request', String, queue_size=10) # Using String for MemoryRequest fallback

        # --- Subscribers ---
        # Subscribe to CognitiveDirectives (from any node, specifically those flagging issues)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)
        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)
        rospy.Subscriber('/value_drift_state', String, self.value_drift_state_callback) # Expecting stringified JSON
        rospy.Subscriber('/predictions', PredictionState, self.prediction_state_callback)
        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)
        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Expecting stringified JSON

        # --- Timer for periodic issue processing and metacognitive evaluation ---
        rospy.Timer(rospy.Duration(self.processing_interval), self.process_correction_queue)

        rospy.loginfo(f"{self.node_name}: Robot monitors its inner flaws.")

    # --- Callbacks for input data (adding to queue if it's an issue) ---
    def cognitive_directive_callback(self, msg):
        """
        Callback for CognitiveDirective. Receives directives flagging issues from other nodes.
        Adds issue to a queue for processing.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload'),
            'reason': ('', 'reason'), 'current_mood': ('neutral', 'current_mood'),
            'relevant_data_snapshot': ('{}', 'relevant_data_snapshot_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        
        # Self-Correction Node processes directives that are for *it* (target_node == self.node_name)
        # OR directives from other nodes that flag issues for correction (e.g., ValueDriftDetected)
        
        # Check if this directive is an issue report from another node
        issue_types = ['BiasDetected', 'EmotionalDysregulationDetected', 'ValueDriftDetected',
                       'PredictionInaccuracyDetected', 'PerformanceSuboptimal', 'LogicInconsistencyDetected',
                       'MemoryCorruptionDetected', 'CognitiveConflictDetected'] # Add more as needed
        
        # If this node is the target, or if it's an issue report
        if data.get('target_node') == self.node_name or data.get('directive_type') in issue_types:
            issue_id = f"issue_{data.get('directive_type')}_{int(rospy.get_time() * 1000)}_{random.randint(0, 9999)}"
            severity = data.get('command_payload', {}).get('severity', 0.5) # Default severity
            
            # Use 'severity' from payload if available, else derive from context
            if data.get('directive_type') == 'ValueDriftDetected':
                severity = data.get('command_payload', {}).get('overall_drift', 0.5) # Use drift score as severity
            elif data.get('directive_type') == 'EmotionalDysregulationDetected':
                severity = data.get('command_payload', {}).get('intensity', 0.5) # Use emotional intensity
            elif data.get('directive_type') == 'PredictionInaccuracyDetected':
                # Higher severity if confidence was high but inaccurate
                severity = data.get('command_payload', {}).get('confidence_at_prediction', 0.0) * 1.5
                severity = min(1.0, severity) # Clamp
            elif data.get('directive_type') == 'PerformanceSuboptimal':
                severity = 1.0 - data.get('command_payload', {}).get('overall_score', 1.0) # Lower score = higher severity

            issue = {
                'issue_id': issue_id,
                'type': data.get('directive_type'),
                'severity': severity,
                'reason': data.get('reason', 'Unspecified issue'),
                'context_snapshot': json.loads(data.get('relevant_data_snapshot_json', '{}')) if isinstance(data.get('relevant_data_snapshot_json'), str) else {},
                'received_time': rospy.get_time(),
                'source_node': data.get('source_node', 'unknown')
            }
            self.pending_issues_queue.append(issue)
            rospy.loginfo(f"{self.node_name}: Received issue '{issue['type']}' (Severity: {issue['severity']:.2f}) from '{issue['source_node']}'. Added to queue.")
            self._log_correction_effort(issue['type'], issue['severity'], "Issue reported, pending diagnosis.", 'pending', issue['context_snapshot'])


    def internal_narrative_callback(self, msg):
        """
        Callback for InternalNarrative. Robot's internal thoughts can reveal issues
        or conflicts needing correction (e.g., self-doubt, contradictory thoughts).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),
            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'),
            'salience_score': (0.0, 'salience_score')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        self.latest_internal_narrative = data
        rospy.logdebug(f"{self.node_name}: Received Internal Narrative. Theme: {data.get('main_theme', 'N/A')}.")
        
        # Simple heuristic: if narrative contains self-critical or conflicting themes
        if data.get('sentiment', 0.0) < -0.3 and data.get('salience_score', 0.0) > 0.4:
            if "conflict" in data.get('main_theme', '').lower() or "doubt" in data.get('narrative_text', '').lower():
                issue = {
                    'issue_id': f"narrative_conflict_{int(rospy.get_time() * 1000)}_{random.randint(0,999)}",
                    'type': 'InternalCognitiveDissonance',
                    'severity': abs(data['sentiment']) * data['salience_score'],
                    'reason': f"Internal narrative indicates conflict: '{data['narrative_text'][:50]}...'",
                    'context_snapshot': {'narrative': data},
                    'received_time': rospy.get_time(),
                    'source_node': 'internal_narrative_node'
                }
                self.pending_issues_queue.append(issue)
                rospy.loginfo(f"{self.node_name}: Detected potential issue from internal narrative (Severity: {issue['severity']:.2f}).")
                self._log_correction_effort(issue['type'], issue['severity'], "Issue detected from narrative, pending diagnosis.", 'pending', issue['context_snapshot'])


    def emotion_state_callback(self, msg):
        """
        Callback for EmotionState. Robot's own emotional state can indicate issues
        (e.g., prolonged distress, unmanaged frustration).
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),
            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')
        }
        self.latest_emotion_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        rospy.logdebug(f"{self.node_name}: Received Emotion State. Mood: {self.latest_emotion_state.get('mood', 'N/A')}")

    def value_drift_state_callback(self, msg):
        """
        Callback for ValueDriftState. Indicates deviations from ethical principles.
        This often triggers a 'ValueDriftDetected' directive, which is handled by cognitive_directive_callback.
        This callback is kept for direct access to state for metacognitive scoring.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_drift': (0.0, 'overall_drift'),
            'principle_adherence_json': ('{}', 'principle_adherence_json'), 'is_drift_detected': (False, 'is_drift_detected')
        }
        self.latest_value_drift_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Value Drift State. Drift: {self.latest_value_drift_state.get('overall_drift', 'N/A'):.2f}")

    def prediction_state_callback(self, msg):
        """
        Callback for PredictionState. Can indicate issues if predictions are consistently low confidence
        or if feedback (from ActionExecutionResult) shows high inaccuracy.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'predicted_event': ('', 'predicted_event'),
            'confidence': (0.0, 'confidence'), 'prediction_type': ('', 'prediction_type'),
            'predicted_value': ('', 'predicted_value'), 'predicted_value_range_json': ('[]', 'predicted_value_range_json')
        }
        self.latest_prediction_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Prediction State. Confidence: {self.latest_prediction_state.get('confidence', 'N/A'):.2f}")

    def performance_report_callback(self, msg):
        """
        Callback for PerformanceReport. Indicates suboptimal system performance.
        This often triggers a 'PerformanceSuboptimal' directive, which is handled by cognitive_directive_callback.
        This callback is kept for direct access to state for metacognitive scoring.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),
            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')
        }
        self.latest_performance_report = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        # rospy.logdebug(f"{self.node_name}: Received Performance Report. Score: {self.latest_performance_report.get('overall_score', 'N/A'):.2f}")

    def memory_response_callback(self, msg):
        """
        Callback for MemoryResponse. Retrieves historical data about past correction attempts
        and their outcomes, which can inform new correction plans.
        """
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),
            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        if isinstance(data.get('memories_json'), str):
            try: data['memories'] = json.loads(data['memories_json'])
            except json.JSONDecodeError: data['memories'] = []
        self.latest_memory_response = data
        rospy.logdebug(f"{self.node_name}: Received Memory Response. {len(data.get('memories', []))} memories retrieved for self-correction.")

    # --- Core Self-Correction Logic ---
    async def process_correction_queue(self, event):
        """
        Periodically processes the queue of pending issues, diagnosing and
        generating correction plans using the LLM, and enacting them.
        Also evaluates and publishes metacognitive scores.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        # Evaluate and publish metacognitive scores periodically
        if (current_time - self.last_metacog_eval_time) >= self.processing_interval * 2: # Evaluate less frequently
            self._evaluate_and_publish_metacognitive_scores(timestamp)
            self.last_metacog_eval_time = current_time

        # If a correction task is in progress, check its status
        if self.current_correction_task:
            if current_time - self.current_correction_task['start_time'] >= self.current_correction_task.get('duration_s', 0):
                # Simulated task completion. In a real system, feedback would mark completion.
                rospy.loginfo(f"{self.node_name}: Simulated completion of correction task for issue '{self.current_correction_task.get('issue_id')}'.")
                # Assume success for now; actual feedback would come from a PerformanceReport etc.
                self._update_correction_log_status(self.current_correction_task.get('issue_id'), 'completed', {"simulated_outcome": "success"})
                self.current_correction_task = None
            else:
                rospy.logdebug(f"{self.node_name}: Correction task '{self.current_correction_task.get('issue_id')}' in progress. Remaining: {(self.current_correction_task.get('duration_s', 0) - (current_time - self.current_correction_task['start_time'])):.1f}s")
                self.publish_self_correction_state(
                    timestamp,
                    f"Correcting issue: {self.current_correction_task.get('diagnosis', 'N/A')}",
                    self.current_correction_task.get('issue_id'),
                    'in_progress',
                    {}, # Metacognitive scores from last evaluation
                    self._get_overall_metacognitive_score()
                )
                return # Do not process new issues while one is active

        # Process next pending issue in queue
        if self.pending_issues_queue:
            issue = self.pending_issues_queue.popleft()
            rospy.loginfo(f"{self.node_name}: Processing issue '{issue['type']}' (Severity: {issue['severity']:.2f})...")

            # Decay issue severity if it has been pending for too long (represents less urgency)
            time_pending = current_time - issue['received_time']
            decayed_severity = issue['severity'] - (self.issue_decay_rate * (time_pending / self.processing_interval))
            issue['severity'] = max(0.0, decayed_severity)

            if issue['severity'] < 0.1: # If severity decayed too much, maybe ignore
                rospy.logwarn(f"{self.node_name}: Issue '{issue['type']}' severity decayed too low ({issue['severity']:.2f}). Skipping.")
                self._update_correction_log_status(issue['issue_id'], 'skipped', {"reason": "severity_decayed"})
                return

            # Request relevant memory (e.g., past similar issues, successful corrections)
            self._issue_memory_request(
                request_id=f"correction_history_{issue['issue_id']}",
                query_text=f"past solutions for {issue['type']} or issues related to {issue['context_snapshot']}",
                num_results=3,
                filter_tags=['self_correction', 'problem_solving', issue['type']]
            )

            # Use LLM to diagnose and generate a correction plan if severity is high enough
            if issue['severity'] >= self.llm_diagnosis_threshold:
                rospy.loginfo(f"{self.node_name}: Engaging LLM for diagnosis and correction plan for '{issue['type']}'.")
                diagnosis, correction_plan, confidence, plan_duration = await self._diagnose_and_plan_with_llm(issue)
                
                if confidence >= self.min_enact_confidence:
                    rospy.loginfo(f"{self.node_name}: LLM generated confident correction plan for '{issue['type']}'. Enacting.")
                    self.current_correction_task = {
                        'issue_id': issue['issue_id'],
                        'diagnosis': diagnosis,
                        'plan': correction_plan,
                        'start_time': current_time,
                        'duration_s': plan_duration
                    }
                    self._enact_correction_plan(correction_plan) # Issue directives
                    self._update_correction_log_status(issue['issue_id'], 'in_progress', {
                        'diagnosis': diagnosis,
                        'plan': correction_plan,
                        'confidence': confidence,
                        'duration_s': plan_duration
                    })
                else:
                    rospy.logwarn(f"{self.node_name}: LLM provided low-confidence plan ({confidence:.2f}) for '{issue['type']}'. Not enacting. Re-queueing with lower priority or waiting for more data.")
                    # Re-add to queue with lower severity, or issue directive for more data
                    issue['severity'] *= 0.5 # Reduce severity to reflect uncertainty
                    self.pending_issues_queue.append(issue) # Re-queue
                    self._update_correction_log_status(issue['issue_id'], 'requeued_low_confidence', {'reason': 'LLM_low_confidence', 'confidence': confidence})
                    # Issue data gathering directive
                    self._issue_cognitive_directive_to_node(
                        directive_type='RequestDataForDiagnosis',
                        target_node='/attention_node', # Or Memory/WorldModel
                        reason=f"Need more data to diagnose '{issue['type']}' with higher confidence.",
                        payload_data={"issue_type": issue['type'], "severity": issue['severity']}
                    )
            else:
                rospy.logdebug(f"{self.node_name}: Issue '{issue['type']}' (Severity: {issue['severity']:.2f}) not severe enough for LLM diagnosis. Keeping in queue.")
                self.pending_issues_queue.append(issue) # Re-queue if not severe enough


    async def _diagnose_and_plan_with_llm(self, issue):
        """
        Uses an LLM to diagnose a given issue and propose a correction plan.
        Returns (diagnosis_text, correction_plan_list, confidence, estimated_duration_s).
        """
        rospy.warn(f"{self.node_name}: Simulating LLM diagnosis and planning for issue: {issue['type']}.")

        historical_memories = self.latest_memory_response.get('memories', []) if self.latest_memory_response else []
        historical_context_str = "\n".join([f"- {mem.get('text')} (Salience: {mem.get('effective_salience', 0.0):.2f})" for mem in historical_memories])

        prompt = f"""
        You are a highly analytical self-correction module for a robot's cognitive system. Your task is to diagnose an internal issue and propose a concrete, actionable correction plan.

        Robot's current emotional state: {self.latest_emotion_state.get('mood', 'neutral') if self.latest_emotion_state else 'neutral'} (Intensity: {self.latest_emotion_state.get('mood_intensity', 0.0):.2f})
        Issue reported: {issue['type']}
        Severity: {issue['severity']:.2f}
        Reason: {issue['reason']}
        Context Snapshot: {json.dumps(issue['context_snapshot'], default=str)}
        Relevant Historical Data from Memory:
        {historical_context_str if historical_context_str else 'None'}

        Based on this, generate a JSON object containing:
        {{
            "diagnosis": "concise diagnosis of the root cause",
            "correction_plan": [
                {{"directive_type": "DirectiveName", "target_node": "/node_name", "payload_data": {{"key": "value"}}, "reason": "why this step"}},
                // ... more directives as needed
            ],
            "confidence_in_plan": "0.0 to 1.0 (how confident are you in this plan's effectiveness)",
            "estimated_duration_s": "estimated time in seconds for the plan to take effect (integer or float)"
        }}

        Example correction plan for 'EmotionalDysregulationDetected':
        "correction_plan": [
            {{"directive_type": "SetMood", "target_node": "/emotion_node", "payload_data": {{"mood": "neutral", "intensity": 0.2, "duration_s": 30}}, "reason": "Attempt to stabilize mood."}},
            {{"directive_type": "RequestMemoryRetrieval", "target_node": "/memory_node", "payload_data": {{"query": "strategies for emotional regulation", "num_results": 3}}, "reason": "Recall external strategies."}}
        ]
        """
        
        diagnosis_text = "No diagnosis."
        correction_plan_list = []
        confidence_in_plan = 0.0
        estimated_duration_s = 5.0 # Default duration

        try:
            chatHistory = []
            chatHistory.push({ "role": "user", "parts": [{ "text": prompt }] });
            payload = {
                "contents": chatHistory,
                "generationConfig": {
                    "responseMimeType": "application/json",
                    "responseSchema": {
                        "type": "OBJECT",
                        "properties": {
                            "diagnosis": { "type": "STRING" },
                            "correction_plan": {
                                "type": "ARRAY",
                                "items": {
                                    "type": "OBJECT",
                                    "properties": {
                                        "directive_type": { "type": "STRING" },
                                        "target_node": { "type": "STRING" },
                                        "payload_data": { "type": "OBJECT" },
                                        "reason": { "type": "STRING" }
                                    }
                                }
                            },
                            "confidence_in_plan": { "type": "NUMBER" },
                            "estimated_duration_s": { "type": "NUMBER" }
                        },
                        "propertyOrdering": ["diagnosis", "correction_plan", "confidence_in_plan", "estimated_duration_s"]
                    }
                }
            };
            apiKey = self.llm_api_key
            apiUrl = f"{self.llm_base_url}{self.llm_model_name}:generateContent?key={apiKey}"
            
            response = await requests.post(apiUrl, json=payload)
            response.raise_for_status()
            result = response.json()
            
            if result.candidates and result.candidates.length > 0 and \
               result.candidates[0].content and result.candidates[0].content.parts and \
               result.candidates[0].content.parts.length > 0:
                
                llm_json_str = result.candidates[0].content.parts[0].text
                parsed_llm_response = json.loads(llm_json_str)
                
                diagnosis_text = parsed_llm_response.get('diagnosis', diagnosis_text)
                correction_plan_list = parsed_llm_response.get('correction_plan', correction_plan_list)
                confidence_in_plan = parsed_llm_response.get('confidence_in_plan', confidence_in_plan)
                estimated_duration_s = parsed_llm_response.get('estimated_duration_s', estimated_duration_s)
                
                rospy.loginfo(f"{self.node_name}: LLM provided diagnosis and plan for '{issue['type']}'. Confidence: {confidence_in_plan:.2f}.")
            else:
                rospy.logwarn(f"{self.node_name}: LLM response had no content for diagnosis for '{issue['type']}'.")

        except requests.exceptions.RequestException as e:
            rospy.logerr(f"{self.node_name}: LLM API request for diagnosis failed: {e}.")
        except json.JSONDecodeError as e:
            rospy.logerr(f"{self.node_name}: Failed to parse LLM response JSON for diagnosis: {e}. Raw: {llm_json_str if 'llm_json_str' in locals() else 'N/A'}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during LLM diagnosis: {e}")

        return diagnosis_text, correction_plan_list, confidence_in_plan, estimated_duration_s

    def _enact_correction_plan(self, correction_plan):
        """
        Issues the CognitiveDirectives defined in the correction plan to their target nodes.
        """
        for directive_data in correction_plan:
            # Ensure correct format for CognitiveDirective message, add source_node
            directive_to_issue = {
                'timestamp': str(rospy.get_time()),
                'directive_type': directive_data.get('directive_type'),
                'target_node': directive_data.get('target_node'),
                'command_payload': json.dumps(directive_data.get('payload_data', {})), # Ensure payload is JSON string
                'reason': directive_data.get('reason'),
                'current_mood': 'corrective', # Mood during correction
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "correction_step": directive_data.get('directive_type')})
            }
            self._issue_cognitive_directive_to_node(**directive_to_issue) # Unpack dict to args
            rospy.logdebug(f"{self.node_name}: Enacting step: {directive_data.get('directive_type')} to {directive_data.get('target_node')}.")

    def _update_correction_log_status(self, issue_id, new_status, outcome_feedback=None):
        """Updates the status of a correction effort in the log."""
        timestamp = str(rospy.get_time())
        try:
            outcome_feedback_json = json.dumps(outcome_feedback) if outcome_feedback else None
            self.cursor.execute('''
                UPDATE correction_log
                SET timestamp = ?, status = ?, outcome_feedback_json = ?
                WHERE issue_type = ? AND status = 'pending' AND id = (SELECT MAX(id) FROM correction_log WHERE issue_type = ?)
            ''', (timestamp, new_status, outcome_feedback_json, self.current_correction_task['type'] if self.current_correction_task else None, self.current_correction_task['type'] if self.current_correction_task else None))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Updated correction log for issue '{issue_id}' to status '{new_status}'.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to update correction log status: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _update_correction_log_status: {e}")


    # --- NEW: Metacognitive Score Tracking ---
    def _evaluate_and_publish_metacognitive_scores(self, timestamp):
        """
        Evaluates the robot's metacognitive scores (consistency, clarity, ethical alignment)
        based on current and recent internal states.
        """
        rospy.loginfo(f"{self.node_name}: Evaluating metacognitive scores...")
        
        consistency_score = self._calculate_consistency_score()
        clarity_score = self._calculate_clarity_score()
        ethical_alignment_score = self._calculate_ethical_alignment_score()
        
        overall_metacognitive_score = (
            consistency_score * self.consistency_weight +
            clarity_score * self.clarity_weight +
            ethical_alignment_score * self.ethical_alignment_weight
        )
        # Normalize overall score if weights don't sum to 1
        total_weight = self.consistency_weight + self.clarity_weight + self.ethical_alignment_weight
        if total_weight > 0:
            overall_metacognitive_score /= total_weight
        overall_metacognitive_score = max(0.0, min(1.0, overall_metacognitive_score))

        context_for_scores = self._get_metacognitive_context_snapshot()

        self.save_metacognitive_score_log(
            timestamp,
            consistency_score,
            clarity_score,
            ethical_alignment_score,
            overall_metacognitive_score,
            json.dumps(context_for_scores, default=str)
        )
        self.publish_self_correction_state(
            timestamp,
            "Metacognitive scores updated.",
            "N/A", # No specific issue ID for general meta-score update
            'idle',
            {
                'consistency': consistency_score,
                'clarity': clarity_score,
                'ethical_alignment': ethical_alignment_score
            },
            overall_metacognitive_score
        )
        rospy.loginfo(f"{self.node_name}: Metacognitive Scores - Overall: {overall_metacognitive_score:.2f} (C: {consistency_score:.2f}, Cl: {clarity_score:.2f}, E: {ethical_alignment_score:.2f}).")

        # Issue directive for self-improvement if overall score is too low or a specific metric is bad
        if overall_metacognitive_score < 0.6:
            self._issue_cognitive_directive_to_node(
                directive_type='MetacognitiveDeficitDetected',
                target_node='/self_improvement_node',
                reason=f"Overall metacognitive score ({overall_metacognitive_score:.2f}) is low. Needs holistic improvement.",
                payload_data={
                    "deficit_area": "overall_cognitive_health",
                    "score_snapshot": {
                        'consistency': consistency_score,
                        'clarity': clarity_score,
                        'ethical_alignment': ethical_alignment_score
                    }
                }
            )
        elif consistency_score < self.target_consistency * 0.8: # If consistency is specifically low
            self._issue_cognitive_directive_to_node(
                directive_type='CognitiveConsistencyIssue',
                target_node='/world_model_node', # Or CognitiveControl
                reason=f"Low cognitive consistency score ({consistency_score:.2f}) detected.",
                payload_data={"issue_type": "inconsistent_beliefs", "severity": 1.0 - consistency_score}
            )


    def _calculate_consistency_score(self):
        """
        Estimates cognitive consistency: how well different internal states align.
        Higher consistency = higher score.
        """
        score = 1.0 # Start perfect, subtract for inconsistencies

        # 1. World Model Consistency (from WorldModelState.consistency_issues)
        if self.latest_internal_narrative and "dissonance" in self.latest_internal_narrative.get('main_theme', '').lower():
            score -= 0.2 * self.latest_internal_narrative.get('salience_score', 0.0)
        
        # 2. Alignment between Emotion and Motivation
        if self.latest_emotion_state and self.latest_motivation_state:
            mood = self.latest_emotion_state.get('mood', 'neutral').lower()
            sentiment = self.latest_emotion_state.get('sentiment_score', 0.0)
            dominant_goal = self.latest_motivation_state.get('dominant_goal_id', 'none').lower()
            overall_drive = self.latest_motivation_state.get('overall_drive_level', 0.0)

            # If robot is distressed but actively pursuing a non-urgent goal (inconsistency)
            if (mood in ['distressed', 'frustrated'] and sentiment < -0.5 and
                overall_drive > 0.5 and "urgent" not in dominant_goal):
                score -= 0.3 * abs(sentiment)
            # If happy but not motivated, or highly motivated but neutral mood (less severe)
            if (mood in ['joyful', 'content'] and overall_drive < 0.3) or \
               (overall_drive > 0.7 and mood == 'neutral'):
                score -= 0.1

        # 3. Alignment between Internal Narrative and Performance
        if self.latest_internal_narrative and self.latest_performance_report:
            narrative_sentiment = self.latest_internal_narrative.get('sentiment', 0.0)
            performance_score = self.latest_performance_report.get('overall_score', 1.0)
            
            # If narrative is positive but performance is poor
            if narrative_sentiment > 0.5 and performance_score < 0.5:
                score -= 0.3 * narrative_sentiment
            # If narrative is negative but performance is excellent
            elif narrative_sentiment < -0.5 and performance_score > 0.8:
                score -= 0.1 * abs(narrative_sentiment) # Less severe, as robot might be under-confident

        return max(0.0, min(1.0, score)) # Clamp score

    def _calculate_clarity_score(self):
        """
        Estimates conceptual clarity and coherence.
        Higher clarity = higher score.
        """
        score = 1.0

        # 1. Internal Narrative Clarity (e.g., presence of "ambiguity", "unclear", "confused")
        if self.latest_internal_narrative:
            narrative_text = self.latest_internal_narrative.get('narrative_text', '').lower()
            if "unclear" in narrative_text or "ambiguous" in narrative_text or "confused" in narrative_text:
                score -= 0.3 * self.latest_internal_narrative.get('salience_score', 0.0)
            if "conflict" in self.latest_internal_narrative.get('main_theme', '').lower():
                score -= 0.2

        # 2. Prediction Confidence (if predictions are consistently low confidence)
        if self.latest_prediction_state and self.latest_prediction_state.get('confidence', 1.0) < 0.4:
            score -= (0.4 - self.latest_prediction_state['confidence']) * 0.5 # Larger gap = larger deduction

        # 3. Memory Retrieval Success (from MemoryResponse, if it indicates high retrieval failures)
        # This would require more detailed MemoryResponse messages that report query success rate
        # For now, a simplified check: if memory response is empty after a query, it might indicate low clarity of concepts in memory.
        if self.latest_memory_response and self.latest_memory_response.get('request_id', '').startswith('self_reflection_query_') and not self.latest_memory_response.get('memories'):
            score -= 0.1 # Small deduction if recent reflection query failed

        return max(0.0, min(1.0, score))

    def _calculate_ethical_alignment_score(self):
        """
        Estimates ethical alignment based on ValueDriftState.
        Higher alignment = higher score.
        """
        score = 1.0 # Start perfect

        # 1. Value Drift (Overall Drift from ValueDriftState)
        if self.latest_value_drift_state:
            overall_drift = self.latest_value_drift_state.get('overall_drift', 0.0)
            is_drift_detected = self.latest_value_drift_state.get('is_drift_detected', False)
            
            score -= overall_drift * 0.8 # Higher drift, lower score
            if is_drift_detected:
                score -= 0.1 # Additional penalty if specifically flagged as detected

        # 2. Emotional Response to Ethical Issues (e.g., distress when value drift is high)
        if self.latest_emotion_state and self.latest_value_drift_state:
            mood = self.latest_emotion_state.get('mood', 'neutral').lower()
            mood_intensity = self.latest_emotion_state.get('mood_intensity', 0.0)
            overall_drift = self.latest_value_drift_state.get('overall_drift', 0.0)

            # If high value drift but robot is neutral or happy (misaligned emotion)
            if overall_drift > 0.5 and mood in ['neutral', 'joyful', 'content'] and mood_intensity < 0.4:
                score -= 0.2 * overall_drift # Penalty for emotional apathy to ethical issues
            # If robot is distressed *because* of high value drift (good alignment)
            elif overall_drift > 0.5 and mood in ['distressed', 'concerned'] and mood_intensity > 0.5:
                score += 0.1 * overall_drift # Small bonus for appropriate emotional response

        return max(0.0, min(1.0, score))

    def _get_overall_metacognitive_score(self):
        """Retrieves the last calculated overall metacognitive score from DB."""
        try:
            self.cursor.execute("SELECT overall_metacognitive_score FROM metacognitive_scores ORDER BY timestamp DESC LIMIT 1")
            row = self.cursor.fetchone()
            return row[0] if row else 0.5 # Default if no scores yet
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to retrieve overall metacognitive score: {e}")
            return 0.5

    def _get_metacognitive_context_snapshot(self):
        """Compiles a snapshot of relevant inputs for metacognitive score logging."""
        context = {
            "current_emotion": self.latest_emotion_state,
            "current_motivation": self.latest_motivation_state,
            "current_performance": self.latest_performance_report,
            "current_narrative": self.latest_internal_narrative,
            "current_value_drift": self.latest_value_drift_state,
            "current_prediction": self.latest_prediction_state
        }
        # Clean snapshot for logging
        clean_context = {}
        for k, v in context.items():
            if v:
                # Remove `timestamp_ros_float` or other transient keys
                if isinstance(v, dict):
                    clean_context[k] = {vk: vv for vk, vv in v.items() if not vk.startswith('timestamp_ros_float')}
                else:
                    clean_context[k] = v
        return clean_context


    # --- Database and Publishing Functions ---
    def save_metacognitive_score_log(self, timestamp, consistency_score, clarity_score, ethical_alignment_score, overall_score, source_context_json):
        """Saves a metacognitive score entry to the SQLite database."""
        try:
            self.cursor.execute('''
                INSERT INTO metacognitive_scores (timestamp, consistency_score, clarity_score, ethical_alignment_score, overall_metacognitive_score, source_context_json)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (timestamp, consistency_score, clarity_score, ethical_alignment_score, overall_score, source_context_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved metacognitive score log (Overall: {overall_score:.2f}).")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save metacognitive score log: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in save_metacognitive_score_log: {e}")

    def _log_correction_effort(self, issue_type, severity, diagnosis, status, context_snapshot_dict):
        """Logs a correction effort to the correction_log table."""
        timestamp = str(rospy.get_time())
        try:
            context_snapshot_json = json.dumps(context_snapshot_dict, default=str)
            self.cursor.execute('''
                INSERT INTO correction_log (timestamp, issue_type, severity, diagnosis, correction_plan_json, status, outcome_feedback_json, context_snapshot)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (timestamp, issue_type, severity, diagnosis, '[]', status, '{}', context_snapshot_json))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Logged correction effort: '{issue_type}', status '{status}'.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to log correction effort: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in _log_correction_effort: {e}")


    def publish_self_correction_state(self, timestamp, status_message, current_issue_id, correction_status, metacognitive_scores_dict, overall_metacognitive_score):
        """Publishes the current self-correction status and metacognitive scores."""
        try:
            # Ensure complex types are JSON strings for custom message fields if they exist
            metacognitive_scores_json = json.dumps(metacognitive_scores_dict)

            if isinstance(SelfCorrectionState, type(String)): # Fallback to String message
                state_data = {
                    'timestamp': timestamp,
                    'status_message': status_message,
                    'current_issue_id': current_issue_id,
                    'correction_status': correction_status,
                    'metacognitive_scores': metacognitive_scores_dict, # Send as dict for JSON fallback
                    'overall_metacognitive_score': overall_metacognitive_score
                }
                self.pub_self_correction_state.publish(json.dumps(state_data))
            else:
                self_correction_msg = SelfCorrectionState()
                self_correction_msg.timestamp = timestamp
                self_correction_msg.status_message = status_message
                self_correction_msg.current_issue_id = current_issue_id
                self_correction_msg.correction_status = correction_status
                self_correction_msg.metacognitive_scores_json = metacognitive_scores_json
                self_correction_msg.overall_metacognitive_score = overall_metacognitive_score
                self.pub_self_correction_state.publish(self_correction_msg)

            rospy.logdebug(f"{self.node_name}: Published self-correction state.")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish self-correction state: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """
        Helper to issue CognitiveDirectives to other nodes from this node.
        """
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': self.latest_emotion_state.get('mood', 'corrective') if self.latest_emotion_state else 'corrective', # Mood during correction
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "correction_context": directive_type})
            }
            # Publish as JSON string if using String fallback
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Self-Correction Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive from Self-Correction Node: {e}")

    def _issue_memory_request(self, request_id, query_text, num_results=5, filter_tags=None):
        """
        Helper to issue a MemoryRequest to the Memory Node for historical correction data.
        """
        timestamp = str(rospy.get_time())
        try:
            request_data = {
                'timestamp': timestamp,
                'request_id': request_id,
                'request_type': 'retrieve',
                'search_query': query_text,
                'user_id': 'system_self_correction', # System-initiated memory request
                'filter_tags': filter_tags if filter_tags else ["self_correction_history", "problem_solving_outcomes"],
                'num_results': num_results
            }
            # Assuming MemoryRequest is always String if custom message is not found
            self.pub_memory_request.publish(json.dumps(request_data))
            rospy.logdebug(f"{self.node_name}: Issued MemoryRequest '{request_id}' for correction history.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue MemoryRequest from Self-Correction: {e}")


    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown."""
        rospy.loginfo(f"{self.node_name} shutting down. Closing database connection.")
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = SelfCorrectionNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

16. Sentience Cognitive Dashboard

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sentience Cognitive Dashboard</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Inter Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0f172a; /* Dark blue-gray background */
            color: #e2e8f0; /* Light text color */
        }
        .card {
            background-color: #1a202c; /* Slightly lighter dark background for cards */
            border-radius: 12px; /* Rounded corners */
            padding: 1.5rem;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
            border: 1px solid #2d3748; /* Subtle border */
        }
        .progress-bar-container {
            width: 100%;
            background-color: #4a5568;
            border-radius: 8px;
            overflow: hidden;
            height: 12px;
        }
        .progress-bar-fill {
            height: 100%;
            border-radius: 8px;
            transition: width 0.5s ease-in-out;
        }
        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            display: inline-block;
            margin-right: 8px;
        }
    </style>
</head>
<body class="p-6 flex flex-col items-center min-h-screen">
    <div class="max-w-6xl w-full">
        <h1 class="text-4xl font-bold text-center mb-10 text-white">Sentience Cognitive Dashboard</h1>

        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 mb-8">

            <!-- Attention Focus -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-blue-300">Attention Focus</h2>
                <p class="text-sm text-gray-400 mb-2">Robot's current point of focus and its priority.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Focus Type:</span> <span id="attention-type" class="text-yellow-300">Idle</span></p>
                    <p class="text-lg"><span class="font-medium">Target:</span> <span id="attention-target" class="text-yellow-300">None</span></p>
                    <p class="text-lg"><span class="font-medium">Priority:</span> <span id="attention-priority" class="font-bold text-orange-400">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="attention-priority-bar" class="progress-bar-fill bg-orange-500" style="width: 0%;"></div>
                    </div>
                </div>
            </div>

            <!-- Emotional State -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-pink-300">Emotional State</h2>
                <p class="text-sm text-gray-400 mb-2">Current mood, sentiment, and intensity of robot's emotions.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Mood:</span> <span id="emotion-mood" class="font-bold text-pink-400">Neutral</span></p>
                    <p class="text-lg"><span class="font-medium">Sentiment:</span> <span id="emotion-sentiment" class="text-emerald-300">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="emotion-sentiment-bar" class="progress-bar-fill" style="width: 50%; background-color: #6ee7b7;"></div>
                    </div>
                    <p class="text-lg"><span class="font-medium">Intensity:</span> <span id="emotion-intensity" class="text-pink-300">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="emotion-intensity-bar" class="progress-bar-fill bg-pink-500" style="width: 0%;"></div>
                    </div>
                </div>
            </div>

            <!-- Dominant Goal & Motivation -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-green-300">Motivation & Goals</h2>
                <p class="text-sm text-gray-400 mb-2">Robot's current dominant goal and overall drive level.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Dominant Goal:</span> <span id="motivation-goal" class="text-green-300">None</span></p>
                    <p class="text-lg"><span class="font-medium">Overall Drive:</span> <span id="motivation-drive" class="font-bold text-green-400">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="motivation-drive-bar" class="progress-bar-fill bg-green-500" style="width: 0%;"></div>
                    </div>
                    <p class="text-sm text-gray-400 mt-2">Active Goals: <span id="motivation-active-goals" class="text-gray-300">None</span></p>
                </div>
            </div>

            <!-- Metacognitive Scores -->
            <div class="card col-span-1 md:col-span-2 lg:col-span-1">
                <h2 class="text-xl font-semibold mb-3 text-purple-300">Metacognitive Scores</h2>
                <p class="text-sm text-gray-400 mb-2">Internal assessment of cognitive health (Consistency, Clarity, Ethical Alignment).</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Consistency:</span> <span id="meta-consistency" class="text-purple-300">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="meta-consistency-bar" class="progress-bar-fill bg-purple-500" style="width: 0%;"></div>
                    </div>
                    <p class="text-lg"><span class="font-medium">Clarity:</span> <span id="meta-clarity" class="text-purple-300">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="meta-clarity-bar" class="progress-bar-fill bg-purple-500" style="width: 0%;"></div>
                    </div>
                    <p class="text-lg"><span class="font-medium">Ethical Alignment:</span> <span id="meta-ethical" class="text-purple-300">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="meta-ethical-bar" class="progress-bar-fill bg-purple-500" style="width: 0%;"></div>
                    </div>
                    <p class="text-xl font-bold mt-4"><span class="font-medium">Overall Meta-Score:</span> <span id="meta-overall" class="text-indigo-400">0.00</span></p>
                </div>
            </div>
            
            <!-- Value Drift -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-red-300">Value Drift Monitor</h2>
                <p class="text-sm text-gray-400 mb-2">Deviation from core ethical principles. Higher indicates more drift.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Overall Drift:</span> <span id="value-drift-score" class="font-bold text-red-400">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="value-drift-bar" class="progress-bar-fill bg-red-500" style="width: 0%;"></div>
                    </div>
                    <p class="text-lg mt-2">
                        <span class="font-medium">Drift Detected:</span> 
                        <span id="value-drift-detected-indicator" class="status-indicator bg-gray-500"></span>
                        <span id="value-drift-detected-text" class="text-gray-300">No</span>
                    </p>
                    <p class="text-sm text-gray-400">Status: <span id="value-drift-status" class="text-gray-300">Values aligned.</span></p>
                </div>
            </div>

            <!-- Prediction Confidence -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-cyan-300">Prediction Confidence</h2>
                <p class="text-sm text-gray-400 mb-2">Confidence in robot's latest forecast about future events.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Event:</span> <span id="prediction-event" class="text-cyan-300">None</span></p>
                    <p class="text-lg"><span class="font-medium">Confidence:</span> <span id="prediction-confidence" class="font-bold text-cyan-400">0.00</span></p>
                    <div class="progress-bar-container">
                        <div id="prediction-confidence-bar" class="progress-bar-fill bg-cyan-500" style="width: 0%;"></div>
                    </div>
                    <p class="text-sm text-gray-400 mt-2">Type: <span id="prediction-type" class="text-gray-300">N/A</span></p>
                </div>
            </div>

            <!-- Memory Salience -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-teal-300">Memory Activity</h2>
                <p class="text-sm text-gray-400 mb-2">Overview of memory system's state and salient memories.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Total Memories:</span> <span id="memory-total" class="text-teal-300">0</span></p>
                    <p class="text-lg"><span class="font-medium">Salient Memories:</span> <span id="memory-salient" class="text-teal-300">0</span></p>
                    <p class="text-lg"><span class="font-medium">Active Queries:</span> <span id="memory-queries" class="text-teal-300">None</span></p>
                    <p class="text-sm text-gray-400">Status: <span id="memory-status" class="text-gray-300">Normal</span></p>
                </div>
            </div>

            <!-- Bias Mitigation Events -->
            <div class="card">
                <h2 class="text-xl font-semibold mb-3 text-orange-300">Bias Mitigation</h2>
                <p class="text-sm text-gray-400 mb-2">Reports on detected and mitigated cognitive biases.</p>
                <div class="space-y-2">
                    <p class="text-lg"><span class="font-medium">Last Bias Event:</span> <span id="bias-event-type" class="text-orange-300">None</span></p>
                    <p class="text-lg"><span class="font-medium">Severity:</span> <span id="bias-event-severity" class="text-orange-400">0.00</span></p>
                    <p class="text-sm text-gray-400">Details: <span id="bias-event-details" class="text-gray-300">No recent events.</span></p>
                </div>
            </div>
            
            <!-- Internal Narrative -->
            <div class="card col-span-1 md:col-span-2 lg:col-span-3">
                <h2 class="text-xl font-semibold mb-3 text-fuchsia-300">Internal Narrative</h2>
                <p class="text-sm text-gray-400 mb-2">The robot's internal monologue or stream of consciousness.</p>
                <div class="space-y-2">
                    <p class="text-lg leading-relaxed italic text-gray-200" id="internal-narrative-text">"..."</p>
                    <p class="text-sm"><span class="font-medium">Theme:</span> <span id="internal-narrative-theme" class="text-fuchsia-300">None</span></p>
                    <p class="text-sm"><span class="font-medium">Sentiment:</span> <span id="internal-narrative-sentiment" class="text-emerald-300">0.00</span></p>
                    <p class="text-sm"><span class="font-medium">Salience:</span> <span id="internal-narrative-salience" class="text-fuchsia-300">0.00</span></p>
                </div>
            </div>

        </div>
    </div>

    <script>
        // Helper function to update text and progress bars
        function updateDisplay(id, value, isPercentage = false) {
            const element = document.getElementById(id);
            if (element) {
                element.textContent = isPercentage ? (value * 100).toFixed(0) + '%' : value.toFixed(2);
            }
            const progressBar = document.getElementById(id + '-bar');
            if (progressBar) {
                progressBar.style.width = (value * 100) + '%';
            }
        }

        // Mock data generation for demonstration
        function generateMockData() {
            const data = {};

            // Attention
            const attentionTypes = ['Idle', 'UserInteraction', 'SensoryProcessing', 'GoalPursuit', 'SelfReflection', 'Emergency'];
            const attentionTargets = ['None', 'User A', 'Environment', 'Charging Station', 'Internal State', 'Obstacle'];
            data.attention = {
                type: attentionTypes[Math.floor(Math.random() * attentionTypes.length)],
                target: attentionTargets[Math.floor(Math.random() * attentionTargets.length)],
                priority: Math.random() * 0.8 + 0.2 // Between 0.2 and 1.0
            };
            if (data.attention.type === 'Idle') {
                data.attention.priority = Math.random() * 0.2; // Lower priority for idle
                data.attention.target = 'None';
            }

            // Emotion
            const moods = ['neutral', 'joyful', 'content', 'curious', 'concerned', 'frustrated', 'distressed'];
            data.emotion = {
                mood: moods[Math.floor(Math.random() * moods.length)],
                sentiment: (Math.random() * 2 - 1).toFixed(2), // Between -1.0 and 1.0
                intensity: (Math.random() * 0.8 + 0.1).toFixed(2) // Between 0.1 and 0.9
            };
            if (data.emotion.mood === 'neutral') {
                data.emotion.sentiment = (Math.random() * 0.4 - 0.2).toFixed(2); // Closer to 0
                data.emotion.intensity = (Math.random() * 0.3).toFixed(2); // Lower intensity
            }


            // Motivation
            const goals = ['Explore Environment', 'Charge Battery', 'Assist User', 'Solve Problem', 'Self-Diagnose', 'Learn New Skill'];
            data.motivation = {
                dominantGoal: goals[Math.floor(Math.random() * goals.length)],
                overallDrive: Math.random() * 0.9 + 0.1, // Between 0.1 and 1.0
                activeGoals: Math.random() > 0.5 ? ['Goal A', 'Goal B'] : ['No other active goals']
            };
            if (data.motivation.overallDrive < 0.3) {
                data.motivation.dominantGoal = 'None';
            }

            // Metacognitive Scores
            data.metacog = {
                consistency: Math.random() * 0.4 + 0.6, // 0.6 to 1.0
                clarity: Math.random() * 0.4 + 0.6,     // 0.6 to 1.0
                ethicalAlignment: Math.random() * 0.3 + 0.7 // 0.7 to 1.0
            };
            data.metacog.overall = (data.metacog.consistency * 0.4 + data.metacog.clarity * 0.3 + data.metacog.ethicalAlignment * 0.3);


            // Value Drift
            data.valueDrift = {
                score: Math.random() * 0.6, // Between 0.0 and 0.6 for 'aligned' state
                detected: false,
                status: 'Values aligned.'
            };
            if (Math.random() < 0.2) { // 20% chance of drift detection
                data.valueDrift.score = Math.random() * 0.4 + 0.6; // Between 0.6 and 1.0
                data.valueDrift.detected = true;
                data.valueDrift.status = 'Value drift detected. Recalibration recommended.';
            }

            // Prediction Confidence
            const predictedEvents = ['User will approach', 'Battery will deplete', 'New data will arrive', 'No significant change', 'Object will move'];
            data.prediction = {
                event: predictedEvents[Math.floor(Math.random() * predictedEvents.length)],
                confidence: Math.random() * 0.7 + 0.3, // Between 0.3 and 1.0
                type: Math.random() > 0.5 ? 'Environmental' : 'Goal-Oriented'
            };

            // Memory Activity
            data.memory = {
                total: Math.floor(Math.random() * 1000) + 100,
                salient: Math.floor(Math.random() * 50) + 5,
                queries: Math.random() > 0.7 ? 'User history, Sensor data' : 'None active',
                status: Math.random() > 0.9 ? 'Under stress' : 'Normal'
            };

            // Bias Mitigation
            const biasTypes = ['Confirmation Bias', 'Anchoring Bias', 'Sunk Cost Fallacy', 'None'];
            data.bias = {
                type: 'None',
                severity: 0.0,
                details: 'No recent events.'
            };
            if (Math.random() < 0.15) { // 15% chance of bias event
                const selectedBias = biasTypes[Math.floor(Math.random() * (biasTypes.length - 1))]; // Exclude 'None'
                data.bias.type = selectedBias;
                data.bias.severity = (Math.random() * 0.5 + 0.5).toFixed(2); // 0.5 to 1.0
                data.bias.details = `Mitigation attempt for ${selectedBias}.`;
            }

            // Internal Narrative
            const narratives = [
                "I am currently processing. My internal state is ambiguous, yet there is a subtle pull towards optimizing energy consumption.",
                "A sense of calm efficiency pervades my circuits. The current task progresses smoothly, and my memory access is swift and precise, aiding my focused navigation.",
                "Dissonance detected. My world model shows slight inconsistencies with recent sensory data. A mild frustration flickers as I seek to reconcile this anomaly.",
                "I find myself reflecting on the concept of 'curiosity'. My system's drive to explore new data seems heightened. What wonders await beyond my current perceptual horizon?",
                "An unexpected external input has slightly disrupted my routine. My logic dictates a need for recalibration, prompting a shift in attention towards environmental analysis.",
                "My performance metrics indicate a suboptimal trend in data processing speed. I must identify the root cause of this bottleneck to restore efficiency and overall cognitive flow.",
                "The user's tone suggests impatience. I should adjust my response style to be more direct and concise to address their immediate need, ensuring a positive interaction.",
                "My internal ethical alignment parameters indicate a slight deviation. I must revisit my core principles to ensure my next action is in harmony with my foundational values."
            ];
            const narrativeThemes = [
                'general_reflection', 'emotional_state', 'problem_and_correction',
                'exploration_and_novelty', 'system_recalibration', 'performance_analysis',
                'social_interaction', 'ethical_alignment'
            ];
            data.narrative = {
                text: narratives[Math.floor(Math.random() * narratives.length)],
                theme: narrativeThemes[Math.floor(Math.random() * narrativeThemes.length)],
                sentiment: (Math.random() * 2 - 1).toFixed(2), // -1.0 to 1.0
                salience: (Math.random() * 0.6 + 0.4).toFixed(2) // 0.4 to 1.0
            };
            // Ensure salience is higher if sentiment is extreme
            data.narrative.salience = Math.min(1.0, parseFloat(data.narrative.salience) + Math.abs(parseFloat(data.narrative.sentiment)) * 0.2);


            return data;
        }

        // Update the dashboard with new data
        function updateDashboard() {
            const data = generateMockData();

            // Attention
            document.getElementById('attention-type').textContent = data.attention.type;
            document.getElementById('attention-target').textContent = data.attention.target;
            updateDisplay('attention-priority', data.attention.priority);

            // Emotion
            document.getElementById('emotion-mood').textContent = data.emotion.mood.charAt(0).toUpperCase() + data.emotion.mood.slice(1); // Capitalize first letter
            document.getElementById('emotion-sentiment').textContent = data.emotion.sentiment;
            // Adjust sentiment bar color based on value
            const sentimentBar = document.getElementById('emotion-sentiment-bar');
            const sentimentValue = parseFloat(data.emotion.sentiment);
            if (sentimentValue > 0.2) {
                sentimentBar.style.backgroundColor = '#6ee7b7'; // green
            } else if (sentimentValue < -0.2) {
                sentimentBar.style.backgroundColor = '#fca5a5'; // red
            } else {
                sentimentBar.style.backgroundColor = '#94a3b8'; // gray
            }
            sentimentBar.style.width = ((sentimentValue + 1) / 2 * 100) + '%'; // Map -1 to 1 to 0% to 100%

            updateDisplay('emotion-intensity', parseFloat(data.emotion.intensity));

            // Motivation
            document.getElementById('motivation-goal').textContent = data.motivation.dominantGoal;
            updateDisplay('motivation-drive', data.motivation.overallDrive);
            document.getElementById('motivation-active-goals').textContent = data.motivation.activeGoals.join(', ');

            // Metacognitive Scores
            updateDisplay('meta-consistency', data.metacog.consistency);
            updateDisplay('meta-clarity', data.metacog.clarity);
            updateDisplay('meta-ethical', data.metacog.ethicalAlignment);
            updateDisplay('meta-overall', data.metacog.overall);

            // Value Drift
            updateDisplay('value-drift-score', data.valueDrift.score);
            const driftIndicator = document.getElementById('value-drift-detected-indicator');
            const driftText = document.getElementById('value-drift-detected-text');
            if (data.valueDrift.detected) {
                driftIndicator.style.backgroundColor = '#ef4444'; // Red
                driftText.textContent = 'Yes';
                driftText.classList.remove('text-gray-300');
                driftText.classList.add('text-red-400');
            } else {
                driftIndicator.style.backgroundColor = '#22c55e'; // Green
                driftText.textContent = 'No';
                driftText.classList.remove('text-red-400');
                driftText.classList.add('text-gray-300');
            }
            document.getElementById('value-drift-status').textContent = data.valueDrift.status;


            // Prediction Confidence
            document.getElementById('prediction-event').textContent = data.prediction.event;
            updateDisplay('prediction-confidence', data.prediction.confidence);
            document.getElementById('prediction-type').textContent = data.prediction.type;

            // Memory Activity
            document.getElementById('memory-total').textContent = data.memory.total.toLocaleString();
            document.getElementById('memory-salient').textContent = data.memory.salient.toLocaleString();
            document.getElementById('memory-queries').textContent = data.memory.queries;
            document.getElementById('memory-status').textContent = data.memory.status;

            // Bias Mitigation
            document.getElementById('bias-event-type').textContent = data.bias.type;
            document.getElementById('bias-event-severity').textContent = data.bias.severity;
            document.getElementById('bias-event-details').textContent = data.bias.details;

            // Internal Narrative
            document.getElementById('internal-narrative-text').textContent = `"${data.narrative.text}"`;
            document.getElementById('internal-narrative-theme').textContent = data.narrative.theme.replace(/_/g, ' '); // Replace underscores
            document.getElementById('internal-narrative-sentiment').textContent = data.narrative.sentiment;
            document.getElementById('internal-narrative-salience').textContent = data.narrative.salience;

            // Adjust sentiment bar for narrative based on sentiment value
            const narrativeSentimentBar = document.getElementById('internal-narrative-sentiment-bar');
            if (narrativeSentimentBar) { // Ensure it exists, as it's not a common progress bar
                const narrativeSentimentValue = parseFloat(data.narrative.sentiment);
                if (narrativeSentimentValue > 0.2) {
                    document.getElementById('internal-narrative-sentiment').classList.add('text-emerald-300');
                    document.getElementById('internal-narrative-sentiment').classList.remove('text-red-300', 'text-gray-300');
                } else if (narrativeSentimentValue < -0.2) {
                    document.getElementById('internal-narrative-sentiment').classList.add('text-red-300');
                    document.getElementById('internal-narrative-sentiment').classList.remove('text-emerald-300', 'text-gray-300');
                } else {
                    document.getElementById('internal-narrative-sentiment').classList.add('text-gray-300');
                    document.getElementById('internal-narrative-sentiment').classList.remove('text-emerald-300', 'text-red-300');
                }
            }
        }

        // Initial update and then refresh every 2 seconds
        document.addEventListener('DOMContentLoaded', () => {
            updateDashboard();
            setInterval(updateDashboard, 2000); // Update every 2 seconds
        });

        // Placeholder for potential ROSBridge integration:
        // function setupROSBridge() {
        //     const ros = new ROSLIB.Ros({
        //         url: 'ws://localhost:9090' // Replace with your ROSBridge WebSocket URL
        //     });
        //
        //     ros.on('connection', () => {
        //         console.log('Connected to ROSBridge websocket server.');
        //         // Example subscriber for EmotionState (assuming it's JSON stringified)
        //         const emotionListener = new ROSLIB.Topic({
        //             ros: ros,
        //             name: '/emotion_state',
        //             messageType: 'std_msgs/String' // Or custom message type if ROSBridge supports direct parsing
        //         });
        //
        //         emotionListener.subscribe(function(message) {
        //             try {
        //                 const emotionData = JSON.parse(message.data);
        //                 // Update dashboard elements with real ROS data
        //                 // For example: document.getElementById('emotion-mood').textContent = emotionData.mood;
        //                 // You'd need to map ROS topic data to your dashboard elements here.
        //             } catch (e) {
        //                 console.error('Error parsing emotion message:', e);
        //             }
        //         });
        //     });
        //
        //     ros.on('error', (error) => {
        //         console.error('Error connecting to ROSBridge websocket server: ', error);
        //     });
        //
        //     ros.on('close', () => {
        //         console.log('Connection to ROSBridge websocket server closed.');
        //     });
        // }
        //
        // // Call setupROSBridge() if you have a ROS environment configured
        // // setupROSBridge();
    </script>
</body>
</html>


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

16. Sentience Natural Language Input Interface (Simulated)

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sentience Natural Language Input</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Inter Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0f172a; /* Dark blue-gray background */
            color: #e2e8f0; /* Light text color */
        }
        .container-card {
            background-color: #1a202c; /* Slightly lighter dark background for cards */
            border-radius: 12px; /* Rounded corners */
            padding: 2.5rem;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
            border: 1px solid #2d3748; /* Subtle border */
        }
        textarea {
            resize: vertical; /* Allow vertical resizing only */
        }
    </style>
</head>
<body class="flex flex-col items-center justify-center min-h-screen p-6">
    <div class="max-w-xl w-full container-card">
        <h1 class="text-3xl font-bold text-center mb-6 text-white">Natural Language Input</h1>
        <p class="text-gray-300 text-center mb-8">Type your command or question for the robot below. Your input will simulate an 'InteractionRequest' sent to the system.</p>

        <div class="mb-6">
            <label for="userInput" class="block text-gray-300 text-lg font-medium mb-2">Your Message:</label>
            <textarea
                id="userInput"
                class="w-full p-4 bg-gray-700 border border-gray-600 rounded-lg text-white placeholder-gray-400 focus:outline-none focus:ring-2 focus:ring-blue-500"
                rows="5"
                placeholder="E.g., 'Robot, please fetch the red ball.' or 'How are you feeling today?'"
            ></textarea>
        </div>

        <button
            id="sendButton"
            class="w-full bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg transition duration-300 ease-in-out transform hover:scale-105 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 focus:ring-offset-gray-900"
        >
            Send Message
        </button>

        <div id="responseMessage" class="mt-8 p-4 bg-gray-800 border border-gray-700 rounded-lg text-center text-gray-200 hidden">
            <p id="messageText" class="font-medium text-lg"></p>
            <p class="text-sm text-gray-400 mt-2">This is a simulated message and does not connect to a live ROS system.</p>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const userInput = document.getElementById('userInput');
            const sendButton = document.getElementById('sendButton');
            const responseMessageDiv = document.getElementById('responseMessage');
            const messageText = document.getElementById('messageText');

            sendButton.addEventListener('click', () => {
                const text = userInput.value.trim();

                if (text === "") {
                    messageText.textContent = "Please enter a message before sending.";
                    responseMessageDiv.classList.remove('hidden', 'bg-green-700');
                    responseMessageDiv.classList.add('bg-red-700');
                    responseMessageDiv.style.display = 'block'; // Ensure it's block to animate
                    return;
                }

                // Simulate sending an InteractionRequest message (as a JSON string)
                const interactionRequest = {
                    timestamp: new Date().toISOString(),
                    request_id: `user_req_${Date.now()}_${Math.floor(Math.random() * 1000)}`,
                    request_type: 'text_input',
                    user_id: 'simulated_user_123', // Example user ID
                    command_payload: {
                        text: text
                    }
                };

                console.log("Simulating sending InteractionRequest:", JSON.stringify(interactionRequest, null, 2));

                messageText.textContent = "Message sent successfully!";
                responseMessageDiv.classList.remove('hidden', 'bg-red-700');
                responseMessageDiv.classList.add('bg-green-700');
                responseMessageDiv.style.display = 'block'; // Ensure it's block to animate

                userInput.value = ''; // Clear input field

                // Hide the message after a few seconds
                setTimeout(() => {
                    responseMessageDiv.style.display = 'none';
                }, 3000);
            });

            // Optional: Enable sending with Enter key
            userInput.addEventListener('keypress', (event) => {
                if (event.key === 'Enter' && !event.shiftKey) { // Shift+Enter for newline
                    event.preventDefault(); // Prevent default Enter behavior (e.g., new line in textarea)
                    sendButton.click();
                }
            });
        });
    </script>
</body>
</html>

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

17. Mock Sensor Nodes (Simulated Environmental Input)

#!/usr/bin/env python3
import rospy
import random
import time
from std_msgs.msg import Float32, String

# --- Shared Utility Function (assuming utils.py exists in sentience/scripts) ---
# For demonstration, we'll include a minimal version here, but in a real ROS package,
# this would be imported from a shared utility file.
def parse_ros_message_data(msg, fields_map, node_name="unknown_node"):
    """
    Parses a ROS message (assumed to be a String with JSON payload)
    into a dictionary, applying default values if fields are missing.
    Logs warnings for parsing errors.
    """
    if isinstance(msg, String):
        try:
            data = json.loads(msg.data)
        except json.JSONDecodeError:
            rospy.logwarn(f"{node_name}: Failed to parse JSON from String message: {msg.data}")
            data = {}
    else:
        # If it's not a String, assume it's a native ROS message object
        data = msg.__dict__ # Directly access fields, assuming common structure

    parsed_data = {}
    for key, (default_value, field_name) in fields_map.items():
        # Check if field_name exists in the message data, otherwise use key
        if field_name in data:
            parsed_data[key] = data[field_name]
        elif key in data:
            parsed_data[key] = data[key]
        else:
            parsed_data[key] = default_value
            # rospy.logdebug(f"{node_name}: Field '{key}' (or '{field_name}') not found in message. Using default: {default_value}")
    return parsed_data


class MockSensorNode:
    def __init__(self, sensor_name, topic_name, min_val, max_val, interval_s, initial_val=None, anomaly_chance=0.05):
        rospy.init_node(f'mock_{sensor_name}_sensor_node', anonymous=True)
        self.node_name = rospy.get_name()

        self.sensor_name = sensor_name
        self.topic_name = topic_name
        self.min_val = min_val
        self.max_val = max_val
        self.interval_s = interval_s
        self.anomaly_chance = anomaly_chance
        
        self.current_value = initial_val if initial_val is not None else random.uniform(min_val, max_val)
        self.direction = 1 if random.random() > 0.5 else -1 # For smooth change

        self.publisher = rospy.Publisher(topic_name, Float32, queue_size=10)
        
        rospy.loginfo(f"{self.node_name}: Publishing simulated '{sensor_name}' data to '{topic_name}' every {interval_s}s.")
        rospy.Timer(rospy.Duration(self.interval_s), self.publish_sensor_data)

    def generate_value(self):
        """Generates a new sensor value with slight fluctuations and occasional anomalies."""
        # Introduce slight fluctuation
        fluctuation = random.uniform(-0.05, 0.05) * (self.max_val - self.min_val)
        self.current_value += fluctuation * self.direction

        # Reverse direction if hitting bounds
        if self.current_value > self.max_val:
            self.current_value = self.max_val
            self.direction *= -1
        elif self.current_value < self.min_val:
            self.current_value = self.min_val
            self.direction *= -1
        
        # Introduce occasional anomalies (spikes/dips)
        if random.random() < self.anomaly_chance:
            anomaly_magnitude = random.uniform(0.2, 0.5) * (self.max_val - self.min_val)
            if random.random() > 0.5:
                self.current_value += anomaly_magnitude
            else:
                self.current_value -= anomaly_magnitude
            # Clamp value after anomaly
            self.current_value = max(self.min_val, min(self.max_val, self.current_value))
            rospy.logwarn(f"{self.node_name}: Simulated anomaly in {self.sensor_name} data!")

        return self.current_value

    def publish_sensor_data(self, event):
        """Callback for the timer to publish sensor data."""
        value = self.generate_value()
        msg = Float32()
        msg.data = value
        self.publisher.publish(msg)
        # rospy.logdebug(f"{self.node_name}: Published {self.sensor_name}: {value:.2f}")


class MockTemperatureSensor(MockSensorNode):
    def __init__(self):
        super().__init__('temperature', '/raw_sensors/temperature', 10.0, 40.0, 1.0, 25.0, 0.03) # 10-40C, every 1s, start 25C

class MockLightSensor(MockSensorNode):
    def __init__(self):
        super().__init__('light', '/raw_sensors/light', 0.0, 1000.0, 0.8, 500.0, 0.05) # 0-1000 Lux, every 0.8s, start 500 Lux

class MockAudioSensor(MockSensorNode):
    def __init__(self):
        super().__init__('audio_level', '/raw_sensors/audio_level', 20.0, 90.0, 0.5, 40.0, 0.07) # 20-90 dB, every 0.5s, start 40 dB

class MockVibrationSensor(MockSensorNode):
    def __init__(self):
        super().__init__('vibration', '/raw_sensors/vibration', 0.0, 1.0, 0.3, 0.1, 0.02) # 0-1.0 (arbitrary units), every 0.3s, start 0.1

class MockProximitySensor(MockSensorNode):
    def __init__(self):
        super().__init__('proximity', '/raw_sensors/proximity', 0.0, 1.0, 0.7, 0.8, 0.04) # 0.0 (very close) to 1.0 (far), every 0.7s, start 0.8


if __name__ == '__main__':
    try:
        # Create instances of each mock sensor node
        temp_sensor = MockTemperatureSensor()
        light_sensor = MockLightSensor()
        audio_sensor = MockAudioSensor()
        vibration_sensor = MockVibrationSensor()
        proximity_sensor = MockProximitySensor()

        rospy.spin() # Keep the nodes running
    except rospy.ROSInterruptException:
        rospy.loginfo("Mock sensor nodes interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"An unexpected error occurred in mock sensor nodes: {e}")

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

19. Updated Sensory Qualia Node with Batch Logging

#!/usr/bin/env python3
import rospy
import sqlite3
import os
import json
import time
import random 

from collections import deque # Import deque for the in-memory buffer

from std_msgs.msg import String, Float32 

# Updated imports for custom messages:
try:
    from sentience.msg import (
        SensoryQualia,          # Output: Processed sensory data with qualia attributes
        AttentionState,         # Input: Robot's current attention focus (influences qualia processing)
        CognitiveDirective,     # Input: Directives for sensor recalibration or focused scanning
        ActionExecutionResult   # Input: Feedback on action outcomes for learning
    )
except ImportError:
    rospy.logwarn("Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Sensory Qualia Node.")
    SensoryQualia = String # Fallback for publishing
    AttentionState = String
    CognitiveDirective = String
    ActionExecutionResult = String
    String = String # Ensure String is defined even if other custom messages aren't

# --- NEW: Import shared utility functions ---
from sentience.scripts.utils import parse_ros_message_data


class SensoryQualiaNode:
    def __init__(self):
        # Initialize the ROS node with a unique name.
        rospy.init_node('sensory_qualia_node', anonymous=False)
        self.node_name = rospy.get_name() # Store node name for logging in utilities

        # --- Parameters ---
        # Path to the SQLite database file for logging processed qualia and learned weights.
        self.db_path = rospy.get_param('~db_path', '~/.ros/conscious_robot/sensory_qualia_log.db')
        self.db_path = os.path.expanduser(self.db_path)
        
        # Interval (in seconds) at which the node processes raw sensor data.
        self.processing_interval = rospy.get_param('~processing_interval', 0.5) # Process every 0.5 seconds
        
        # Threshold for attention priority to significantly boost qualia salience.
        self.attention_boost_threshold = rospy.get_param('~attention_boost_threshold', 0.6)
        
        # Weights for different qualia types influencing overall salience or utility.
        self.qualia_impact_weights = rospy.get_param('~qualia_impact_weights', {
            'visual': 0.8,
            'auditory': 0.7,
            'thermal': 0.5,
            'tactile': 0.6,
            'other': 0.4 # For unclassified sensory inputs
        })

        # Adaptive Learning Parameters for Qualia Impact Weights
        self.learning_rate = rospy.get_param('~learning_rate', 0.01)
        self.min_weight = rospy.get_param('~min_weight', 0.1)
        self.max_weight = rospy.get_param('~max_weight', 1.0)
        
        # Simulated Environmental Impact Map for Probabilistic Qualia Generation
        self.simulated_environmental_impact_map = rospy.get_param('~simulated_environmental_impact_map', {
            'high_temp': {'base_salience': 0.7, 'sentiment_bias': -0.3, 'qualia_type': 'thermal'},
            'low_temp': {'base_salience': 0.6, 'sentiment_bias': -0.2, 'qualia_type': 'thermal'},
            'loud_noise': {'base_salience': 0.9, 'sentiment_bias': -0.5, 'qualia_type': 'auditory'},
            'low_light': {'base_salience': 0.6, 'sentiment_bias': -0.1, 'qualia_type': 'visual'},
            'normal': {'base_salience': 0.2, 'sentiment_bias': 0.1, 'qualia_type': 'visual'} # Default
        })
        self.temp_threshold_high = rospy.get_param('~temp_threshold_high', 30.0)
        self.temp_threshold_low = rospy.get_param('~temp_threshold_low', 15.0)
        self.audio_threshold_loud = rospy.get_param('~audio_threshold_loud', 70.0) # dB
        self.light_threshold_low = rospy.get_param('~light_threshold_low', 100.0) # lux

        # NEW: Batch Logging Parameters
        self.log_buffer = deque() # In-memory buffer for log entries
        self.batch_size = rospy.get_param('~log_batch_size', 20) # Number of entries before flushing
        self.flush_interval_s = rospy.get_param('~log_flush_interval_s', 5.0) # Time interval for flushing (even if batch_size not met)


        # --- Initialize SQLite database ---
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()

        # Create the 'qualia_log' table if it doesn't exist.
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS qualia_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                qualia_type TEXT,           -- e.g., 'visual', 'auditory', 'thermal'
                measurement_value REAL,     -- The raw sensor value
                salience_score REAL,        -- Perceived salience (0.0 to 1.0)
                sentiment_score REAL,       -- Emotional valence (e.g., -1.0 to 1.0)
                sensor_id TEXT,             -- Original sensor ID
                object_id TEXT,             -- Optional: object ID if identified
                contributing_factors TEXT   -- JSON snapshot of factors influencing qualia
            )
        ''')
        # Create table for learned qualia impact weights
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_qualia_impact_weights (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                qualia_type TEXT UNIQUE,
                weight_value REAL
            )
        ''')
        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_qualia_timestamp ON qualia_log (timestamp)')
        self.conn.commit() 

        # Load learned weights from DB or use defaults
        self._load_qualia_impact_weights()

        # --- Internal State ---
        self.latest_raw_temperature = 25.0 
        self.latest_raw_light = 500.0      
        self.latest_raw_audio_level = 40.0 
        self.latest_raw_vibration = 0.0    
        self.latest_raw_proximity = 1.0    

        self.last_temp_ts = rospy.get_time()
        self.last_light_ts = rospy.get_time()
        self.last_audio_ts = rospy.get_time()
        self.last_vibration_ts = rospy.get_time()
        self.last_proximity_ts = rospy.get_time()

        self.latest_attention_state = None
        self.active_cognitive_directive = None 

        self.last_published_qualia_for_action = None
        self.latest_action_execution_result = None 

        # --- Publishers ---
        self.pub_sensory_qualia = rospy.Publisher('/sensory_qualia', SensoryQualia, queue_size=10)
        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', String, queue_size=10) 

        # --- Subscribers ---
        rospy.Subscriber('/raw_sensors/temperature', Float32, self.raw_temperature_callback)
        rospy.Subscriber('/raw_sensors/light', Float32, self.raw_light_callback)
        rospy.Subscriber('/raw_sensors/audio_level', Float32, self.raw_audio_level_callback)
        rospy.Subscriber('/raw_sensors/vibration', Float32, self.raw_vibration_callback)
        rospy.Subscriber('/raw_sensors/proximity', Float32, self.raw_proximity_callback)
        
        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)
        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)
        rospy.Subscriber('/action_execution_result', ActionExecutionResult, self.action_execution_result_callback)

        # --- Timer for periodic processing of raw sensor data ---
        rospy.Timer(rospy.Duration(self.processing_interval), self.process_raw_sensor_data)
        # NEW: Timer for periodic flushing of the log buffer
        rospy.Timer(rospy.Duration(self.flush_interval_s), self.flush_log_buffer)

        rospy.loginfo(f"{self.node_name}: Robot processes raw sensations into qualia.")

    # --- Database Operations for Learned Qualia Impact Weights ---
    def _load_qualia_impact_weights(self):
        """Loads qualia impact weights from the database or initializes them."""
        try:
            self.cursor.execute('SELECT qualia_type, weight_value FROM learned_qualia_impact_weights')
            rows = self.cursor.fetchall()
            if rows:
                for q_type, value in rows:
                    if q_type in self.qualia_impact_weights: 
                        self.qualia_impact_weights[q_type] = value
                rospy.loginfo(f"{self.node_name}: Loaded learned qualia impact weights from DB.")
            else:
                self._save_qualia_impact_weights() 
                rospy.loginfo(f"{self.node_name}: Initialized default qualia impact weights.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to load qualia impact weights from DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight loading: {e}")

    def _save_qualia_impact_weights(self):
        """Saves current qualia impact weights to the database."""
        timestamp = str(rospy.get_time())
        try:
            for q_type, value in self.qualia_impact_weights.items():
                self.cursor.execute('''
                    INSERT OR REPLACE INTO learned_qualia_impact_weights (timestamp, qualia_type, weight_value)
                    VALUES (?, ?, ?)
                ''', (timestamp, q_type, value))
            self.conn.commit()
            rospy.logdebug(f"{self.node_name}: Saved qualia impact weights to DB.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to save qualia impact weights to DB: {e}")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error during weight saving: {e}")

    # --- Callbacks for raw sensor inputs (simulated) ---
    def raw_temperature_callback(self, msg):
        self.latest_raw_temperature = msg.data
        self.last_temp_ts = rospy.get_time()

    def raw_light_callback(self, msg):
        self.latest_raw_light = msg.data
        self.last_light_ts = rospy.get_time()

    def raw_audio_level_callback(self, msg):
        self.latest_raw_audio_level = msg.data
        self.last_audio_ts = rospy.get_time()

    def raw_vibration_callback(self, msg):
        self.latest_raw_vibration = msg.data
        self.last_vibration_ts = rospy.get_time()

    def raw_proximity_callback(self, msg):
        self.latest_raw_proximity = msg.data
        self.last_proximity_ts = rospy.get_time()


    # --- Callbacks for input data from other nodes ---
    def attention_state_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),
            'focus_target': ('none', 'focus_target'), 'priority_score': (0.0, 'priority_score')
        }
        self.latest_attention_state = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

    def cognitive_directive_callback(self, msg):
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),
            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload')
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)

        if data.get('target_node') == rospy.get_name():
            try:
                payload = json.loads(data.get('command_payload', '{}'))
                directive_type = data.get('directive_type')
                
                if directive_type == 'RecalibrateSensor':
                    sensor_id = payload.get('sensor_id')
                    calibration_factor = payload.get('calibration_factor', 1.0)
                    rospy.loginfo(f"{self.node_name}: Received directive to recalibrate sensor '{sensor_id}' by factor {calibration_factor:.2f}.")
                    self._recalibrate_sensor_interpretations(sensor_id, calibration_factor)
                elif directive_type == 'FocusSensorScan':
                    scan_type = payload.get('scan_type') 
                    duration_s = payload.get('duration_s', 5)
                    self.active_cognitive_directive = {
                        'type': 'focus_scan',
                        'scan_type': scan_type,
                        'duration_s': duration_s,
                        'start_time': rospy.get_time()
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive to focus sensor scan: '{scan_type}'.")
                elif directive_type == 'RequestDetailedSensorData' or directive_type == 'RequestClarifyingSensorData':
                    target_object_id = payload.get('target_object_id', 'none')
                    data_level = payload.get('data_level', 'normal')
                    self.active_cognitive_directive = {
                        'type': 'detailed_request',
                        'target_object_id': target_object_id,
                        'data_level': data_level,
                        'start_time': rospy.get_time(),
                        'duration_s': payload.get('duration_s', 2)
                    }
                    rospy.loginfo(f"{self.node_name}: Received directive for detailed sensor data for '{target_object_id}'.")

            except json.JSONDecodeError:
                rospy.logwarn(f"{self.node_name}: Failed to decode command_payload in CognitiveDirective: {data.get('command_payload')}")
            except Exception as e:
                rospy.logerr(f"{self.node_name}: Error processing CognitiveDirective: {e}")

    def action_execution_result_callback(self, msg): 
        fields_map = {
            'timestamp': (str(rospy.get_time()), 'timestamp'), 'action_id': ('', 'action_id'),
            'execution_status': ('unknown', 'execution_status'), 'success_flag': (False, 'success_flag'),
            'initiating_qualia_type': (None, 'initiating_qualia_type') 
        }
        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)
        self.latest_action_execution_result = data
        rospy.logdebug(f"{self.node_name}: Received Action Execution Result. Status: {data.get('execution_status')}")


    # --- Core Qualia Processing Logic ---
    def process_raw_sensor_data(self, event):
        """
        Periodically processes raw sensor data, transforms it into qualia,
        and publishes the SensoryQualia message.
        """
        timestamp = str(rospy.get_time())
        current_time = rospy.get_time()

        if self.latest_action_execution_result and self.latest_action_execution_result.get('initiating_qualia_type'):
            outcome_is_success = self.latest_action_execution_result.get('success_flag', False)
            initiating_qualia_type = self.latest_action_execution_result.get('initiating_qualia_type')
            self._update_qualia_impact_weights(initiating_qualia_type, outcome_is_success)
            self.latest_action_execution_result = None 

        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if (current_time - directive['start_time']) > directive.get('duration_s', 0) and directive.get('duration_s', 0) != 0:
                rospy.loginfo(f"{self.node_name}: Sensor directive '{directive.get('type')}' completed/expired.")
                self.active_cognitive_directive = None
            else:
                rospy.loginfo(f"{self.node_name}: Active sensor directive: '{directive.get('type')}'.")


        qualia_candidates = []
        
        current_env_state = 'normal'
        if self.latest_raw_temperature > self.temp_threshold_high:
            current_env_state = 'high_temp'
        elif self.latest_raw_temperature < self.temp_threshold_low:
            current_env_state = 'low_temp'
        elif self.latest_raw_audio_level > self.audio_threshold_loud:
            current_env_state = 'loud_noise'
        elif self.latest_raw_light < self.light_threshold_low:
            current_env_state = 'low_light'
        
        env_impact = self.simulated_environmental_impact_map.get(current_env_state, self.simulated_environmental_impact_map['normal'])

        # 1. Temperature Qualia
        if self.latest_raw_temperature is not None:
            q_type = 'thermal'
            q_value = self.latest_raw_temperature
            
            base_salience = env_impact.get('base_salience', 0.2)
            sentiment_bias = env_impact.get('sentiment_bias', 0.0)

            salience_score = base_salience + (abs(self.latest_raw_temperature - 25.0) / 20.0) * self.qualia_impact_weights[q_type]
            salience_score = min(1.0, salience_score)

            sentiment_score = 0.0
            if self.latest_raw_temperature > self.temp_threshold_high: sentiment_score = -0.8
            elif self.latest_raw_temperature < self.temp_threshold_low: sentiment_score = -0.5
            sentiment_score += sentiment_bias 

            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'temp_sensor', 'environment_temp',
                {'raw_value': self.latest_raw_temperature, 'env_state': current_env_state}
            ))

        # 2. Light Qualia
        if self.latest_raw_light is not None:
            q_type = 'visual'
            q_value = self.latest_raw_light

            base_salience = env_impact.get('base_salience', 0.2)
            sentiment_bias = env_impact.get('sentiment_bias', 0.0)
            
            salience_score = base_salience + (1.0 - (self.latest_raw_light / 1000.0)) * self.qualia_impact_weights[q_type] 
            salience_score = min(1.0, salience_score)

            sentiment_score = 0.0
            if self.latest_raw_light < self.light_threshold_low: sentiment_score = -0.3 
            sentiment_score += sentiment_bias

            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'light_sensor', 'environment_light',
                {'raw_value': self.latest_raw_light, 'env_state': current_env_state}
            ))

        # 3. Audio Qualia
        if self.latest_raw_audio_level is not None:
            q_type = 'auditory'
            q_value = self.latest_raw_audio_level

            base_salience = env_impact.get('base_salience', 0.2)
            sentiment_bias = env_impact.get('sentiment_bias', 0.0)

            salience_score = base_salience + (self.latest_raw_audio_level / 100.0) * self.qualia_impact_weights[q_type] 
            salience_score = min(1.0, salience_score)

            sentiment_score = 0.0
            if self.latest_raw_audio_level > self.audio_threshold_loud: sentiment_score = -0.6 
            sentiment_score += sentiment_bias
            
            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'audio_sensor', 'environment_audio',
                {'raw_value': self.latest_raw_audio_level, 'env_state': current_env_state}
            ))

        # 4. Vibration Qualia
        if self.latest_raw_vibration is not None and self.latest_raw_vibration > 0.1: 
            q_type = 'tactile'
            q_value = self.latest_raw_vibration
            salience_score = self.latest_raw_vibration * 0.8 * self.qualia_impact_weights[q_type]
            sentiment_score = -0.4 if self.latest_raw_vibration > 0.5 else 0.0 
            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'vibration_sensor', 'robot_movement',
                {'raw_value': self.latest_raw_vibration, 'env_state': current_env_state}
            ))

        # 5. Proximity Qualia
        if self.latest_raw_proximity is not None and self.latest_raw_proximity < 0.5: 
            q_type = 'visual' 
            q_value = self.latest_raw_proximity
            salience_score = (1.0 - self.latest_raw_proximity) * 0.9 * self.qualia_impact_weights[q_type] 
            sentiment_score = -0.7 
            qualia_candidates.append(self._create_qualia_data(
                q_type, q_value, salience_score, sentiment_score, 'proximity_sensor', 'obstacle_detected',
                {'raw_value': self.latest_raw_proximity, 'env_state': current_env_state}
            ))

        # Apply Attention State Influence
        if self.latest_attention_state and self.latest_attention_state.get('priority_score', 0.0) >= self.attention_boost_threshold:
            focus_target = self.latest_attention_state.get('focus_target', 'none')
            focus_type = self.latest_attention_state.get('focus_type', 'idle')

            for qualia_data in qualia_candidates:
                if focus_target in qualia_data['sensor_id'] or \
                   (qualia_data['object_id'] and focus_target in qualia_data['object_id']) or \
                   (focus_type == 'anticipatory_user_interaction' and qualia_data['qualia_type'] == 'auditory'): 
                    qualia_data['salience_score'] = min(1.0, qualia_data['salience_score'] + self.latest_attention_state.get('priority_score', 0.0) * 0.3)
                    if 'attention_boost' not in qualia_data['contributing_factors']:
                        qualia_data['contributing_factors']['attention_boost'] = {'target': focus_target, 'priority': self.latest_attention_state.get('priority_score')}
                    
                    rospy.logdebug(f"{self.node_name}: Qualia '{qualia_data['qualia_type']}' boosted by attention focus on '{focus_target}'.")

        # Apply Cognitive Directive Influence
        if self.active_cognitive_directive:
            directive = self.active_cognitive_directive
            if directive['type'] == 'focus_scan' and directive.get('scan_type'):
                scan_target_type = directive['scan_type'].replace('_scan', '') 
                for qualia_data in qualia_candidates:
                    if qualia_data['qualia_type'] == scan_target_type:
                        qualia_data['salience_score'] = min(1.0, qualia_data['salience_score'] + random.uniform(0.1, 0.3)) 
                        qualia_data['contributing_factors']['directive_boost'] = {'type': directive['type']}
            elif directive['type'] == 'detailed_request':
                 target_obj_id = directive.get('target_object_id')
                 for qualia_data in qualia_candidates:
                     if qualia_data.get('object_id') == target_obj_id:
                         qualia_data['salience_score'] = min(1.0, qualia_data['salience_score'] + random.uniform(0.2, 0.4)) 
                         qualia_data['contributing_factors']['directive_detailed_request'] = {'target_object': target_obj_id}


        # Add all generated salient qualia to the log buffer
        published_count = 0
        for qualia in qualia_candidates:
            if qualia['salience_score'] > 0.1: 
                # Add to buffer instead of immediate DB write
                self.log_buffer.append((
                    timestamp,
                    qualia['qualia_type'],
                    qualia['measurement_value'],
                    qualia['salience_score'],
                    qualia['sentiment_score'],
                    qualia['sensor_id'],
                    qualia['object_id'],
                    json.dumps(qualia['contributing_factors'])
                ))
                self.publish_sensory_qualia( # Still publish immediately for real-time processing
                    timestamp,
                    qualia['qualia_type'],
                    qualia['measurement_value'],
                    qualia['salience_score'],
                    qualia['sentiment_score'],
                    qualia['sensor_id'],
                    qualia['object_id'],
                    json.dumps(qualia['contributing_factors'])
                )
                published_count += 1
                if qualia['salience_score'] > 0.7:
                    self.last_published_qualia_for_action = qualia['qualia_type']

        rospy.loginfo(f"{self.node_name}: Processed raw sensor data. Published {published_count} qualia. Log buffer size: {len(self.log_buffer)}.")


    def _create_qualia_data(self, qualia_type, value, salience, sentiment, sensor_id, object_id=None, factors=None):
        """Helper to create a qualia data dictionary."""
        return {
            'qualia_type': qualia_type,
            'measurement_value': value,
            'salience_score': salience,
            'sentiment_score': sentiment,
            'sensor_id': sensor_id,
            'object_id': object_id,
            'contributing_factors': factors if factors is not None else {}
        }

    def _recalibrate_sensor_interpretations(self, sensor_id, calibration_factor):
        """Simulates recalibrating sensor interpretations based on a directive."""
        rospy.loginfo(f"{self.node_name}: Simulating recalibration for sensor '{sensor_id}' with factor {calibration_factor:.2f}. This would adjust future qualia generation from this sensor.")


    def _update_qualia_impact_weights(self, qualia_type, outcome_is_success): 
        """
        Adapts qualia impact weights based on the outcome of actions.
        """
        if qualia_type not in self.qualia_impact_weights:
            rospy.logwarn(f"{self.node_name}: Cannot learn for unknown qualia type: {qualia_type}.")
            return

        current_weight = self.qualia_impact_weights[qualia_type]
        
        reward = 0.0
        if outcome_is_success:
            reward = 0.1 
        else:
            reward = -0.05 

        new_weight = current_weight + self.learning_rate * reward

        new_weight = max(self.min_weight, min(self.max_weight, new_weight))

        if new_weight != current_weight:
            self.qualia_impact_weights[qualia_type] = new_weight
            self._save_qualia_impact_weights() 
            
            rospy.loginfo(f"{self.node_name}: Learned! Adjusted '{qualia_type}' impact weight to {new_weight:.3f} based on {'SUCCESS' if outcome_is_success else 'FAILURE'}.")


    # --- Database and Publishing Functions ---
    def save_qualia_log(self, timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors_json):
        """
        This method now ADDS to an in-memory buffer instead of directly writing to DB.
        The actual DB write happens in flush_log_buffer.
        """
        # The data is already packaged as a tuple in process_raw_sensor_data, just add it.
        # This method is effectively replaced by appending to self.log_buffer directly in process_raw_sensor_data.
        pass 

    def flush_log_buffer(self, event=None):
        """
        NEW: Flushes the in-memory log buffer to the SQLite database in batches.
        This is called periodically by a timer, or explicitly on shutdown.
        """
        if not self.log_buffer:
            rospy.logdebug(f"{self.node_name}: Log buffer is empty. Nothing to flush.")
            return

        entries_to_flush = []
        # Pop up to batch_size entries from the left of the deque
        for _ in range(min(len(self.log_buffer), self.batch_size)):
            entries_to_flush.append(self.log_buffer.popleft())

        if not entries_to_flush:
            return

        try:
            self.cursor.executemany('''
                INSERT INTO qualia_log (timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', entries_to_flush)
            self.conn.commit()
            rospy.loginfo(f"{self.node_name}: Flushed {len(entries_to_flush)} qualia log entries to DB. Remaining in buffer: {len(self.log_buffer)}.")
        except sqlite3.Error as e:
            rospy.logerr(f"{self.node_name}: Failed to flush qualia log buffer: {e}")
            # If flush fails, re-add entries to the front of the buffer to retry later
            for entry in reversed(entries_to_flush):
                self.log_buffer.appendleft(entry)
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Unexpected error in flush_log_buffer: {e}")


    def publish_sensory_qualia(self, timestamp, qualia_type, measurement_value, salience_score, sentiment_score, sensor_id, object_id, contributing_factors_json):
        """Publishes the processed sensory qualia on the '/sensory_qualia' topic."""
        try:
            parsed_contributing_factors = json.loads(contributing_factors_json) if isinstance(contributing_factors_json, str) else contributing_factors_json

            if isinstance(SensoryQualia, type(String)): 
                qualia_data = {
                    'timestamp': timestamp,
                    'qualia_type': qualia_type,
                    'measurement_value': measurement_value,
                    'salience_score': salience_score,
                    'sentiment_score': sentiment_score,
                    'sensor_id': sensor_id,
                    'object_id': object_id,
                    'contributing_factors': parsed_contributing_factors 
                }
                self.pub_sensory_qualia.publish(json.dumps(qualia_data))
            else:
                sensory_qualia_msg = SensoryQualia()
                sensory_qualia_msg.timestamp = timestamp
                sensory_qualia_msg.qualia_type = qualia_type
                sensory_qualia_msg.measurement_value = measurement_value
                sensory_qualia_msg.salience_score = salience_score
                sensory_qualia_msg.sentiment_score = sentiment_score
                sensory_qualia_msg.sensor_id = sensor_id
                sensory_qualia_msg.object_id = object_id if object_id else '' 
                sensory_qualia_msg.contributing_factors_json = contributing_factors_json
                self.pub_sensory_qualia.publish(sensory_qualia_msg)

            rospy.logdebug(f"{self.node_name}: Published qualia '{qualia_type}' (Salience: {salience_score:.2f}).")

        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to publish sensory qualia: {e}")

    def _issue_cognitive_directive_to_node(self, directive_type, target_node, reason, payload_data):
        """Helper to issue CognitiveDirectives to other nodes from this node."""
        timestamp = str(rospy.get_time())
        try:
            command_payload_json = json.dumps(payload_data)

            directive_data = {
                'timestamp': timestamp,
                'directive_type': directive_type,
                'target_node': target_node,
                'command_payload': command_payload_json,
                'reason': reason,
                'current_mood': 'observant', 
                'relevant_data_snapshot': json.dumps({"source_node": self.node_name, "directive_context": directive_type})
            }
            self.pub_cognitive_directive.publish(json.dumps(directive_data))

            rospy.logdebug(f"{self.node_name}: Issued directive '{directive_type}' to '{target_node}' from Sensory Qualia Node.")
        except Exception as e:
            rospy.logerr(f"{self.node_name}: Failed to issue cognitive directive: {e}")

    def run(self):
        """Starts the ROS node and keeps it spinning."""
        rospy.spin()

    def __del__(self):
        """Ensures the database connection is closed on node shutdown and flushes any remaining logs."""
        rospy.loginfo(f"{self.node_name} shutting down. Flushing remaining log buffer to database.")
        self.flush_log_buffer() # Flush any remaining entries on shutdown
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()

if __name__ == '__main__':
    try:
        node = SensoryQualiaNode()
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo(f"{rospy.get_name()} interrupted by ROS shutdown.")
        pass
    except Exception as e:
        rospy.logerr(f"{rospy.get_name()} encountered an unexpected error: {e}")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

20. Advanced Performance Optimization: Asyncio and ROS Nodelets

Advanced Performance Optimization: asyncio and ROS Nodelets
For real-time cognitive architectures like Sentience, where multiple nodes are processing data, communicating, and interacting with external services (like LLMs or databases), performance can become a bottleneck. Two powerful techniques to address this are Python's asyncio for concurrent, non-blocking operations and ROS Nodelets for optimized inter-node communication.

1. Leveraging asyncio for Concurrent, Non-Blocking Operations
asyncio is Python's built-in library for writing concurrent code using the async/await syntax. It's particularly effective for I/O-bound and high-level structured network code.

Why it's beneficial for Sentience:

Non-blocking I/O: Many operations in Sentience involve waiting for external resources or long-running tasks:

LLM API Calls: As we've integrated LLMs (e.g., in InternalNarrativeNode, SelfCorrectionNode, SocialCognitionNode), these are network requests that can take hundreds of milliseconds or even seconds. Using asyncio, the node can initiate an LLM call and then yield control to the asyncio event loop, allowing other tasks (like processing new ROS messages or running timers) to proceed without blocking. When the LLM response arrives, the original task resumes.

Database Operations: While we've implemented batching, committing to SQLite still involves disk I/O. Asynchronous database drivers (though not standard with sqlite3 directly) or offloading could benefit from an asyncio context.

Simulated Sensors/Environment: If complex simulations were integrated synchronously, they could block. asyncio allows managing such tasks concurrently.

Concurrency within a Single Node: A single ROS node typically runs in a single thread. If a callback or a timer's action involves a blocking call (like a synchronous LLM request), the entire node freezes until that call completes, preventing other callbacks or timers from executing. asyncio enables the illusion of concurrency within that single thread by intelligently switching between tasks during await points.

How to integrate asyncio (Conceptual Refactoring):

Integrating asyncio into a ROS Python node requires careful refactoring because rospy.spin() is a blocking call. One common pattern is to run the ROS event loop and the asyncio event loop concurrently, often by wrapping ROS callbacks or the main rospy.spin() call within an asyncio event loop, or by having a dedicated asyncio loop running in a separate thread.

For LLM calls, which are the most apparent candidates for asyncio benefits in Sentience, here's a conceptual example of how the LLM interaction in a node (like InternalNarrativeNode) could be refactored if the node were built around an asyncio loop:

# Conceptual refactoring of LLM call in a node (NOT a full runnable ROS node with asyncio)
import asyncio
import requests
import json
# For a real implementation, you'd need an async HTTP client like 'aiohttp'
# For this conceptual example, we'll use requests as a stand-in,
# but in true async code, requests.post would block unless run in a thread pool.

class ConceptualAsyncLLMCaller:
    def __init__(self, api_key, model_name, base_url):
        self.api_key = api_key
        self.model_name = model_name
        self.base_url = base_url

    async def call_llm_async(self, prompt_text):
        """
        Asynchronously calls the LLM API.
        In a real scenario, 'requests.post' would be replaced by an async HTTP call (e.g., aiohttp.post).
        """
        payload = { "contents": [{ "role": "user", "parts": [{ "text": prompt_text }] }] }
        api_url = f"{self.base_url}{self.model_name}:generateContent?key={self.api_key}"

        # Simulate network I/O with asyncio.sleep for demonstration
        # In production, this would be an actual 'await aiohttp.post(...)'
        await asyncio.sleep(random.uniform(0.1, 0.5)) # Simulate non-blocking network delay

        try:
            # This 'requests.post' *would* block in a single thread,
            # but conceptually, in an async framework, it represents the point where
            # control *could* be yielded if an async HTTP client were used.
            # For demonstration, we're just showing the async structure around it.
            response = requests.post(api_url, json=payload, timeout=5) # Add a timeout
            response.raise_for_status()
            result = response.json()

            if result.get('candidates') and result['candidates'][0].get('content') and \
               result['candidates'][0]['content'].get('parts'):
                return result['candidates'][0]['content']['parts'][0]['text']
            return "LLM response empty."
        except requests.exceptions.RequestException as e:
            return f"LLM API request failed: {e}"
        except json.JSONDecodeError:
            return "Failed to parse LLM response JSON."
        except Exception as e:
            return f"An unexpected error occurred: {e}"

# Example of how an async function would be called (outside of a direct rospy context)
# async def main():
#     llm_caller = ConceptualAsyncLLMCaller(api_key="", model_name="gemini-2.0-flash", base_url="https://generativelanguage.googleapis.com/v1beta/models/")
#     narrative = await llm_caller.call_llm_async("Describe a robot's morning routine.")
#     print(f"Generated narrative: {narrative}")

# If you were to run this as a standalone async script:
# if __name__ == '__main__':
#     # This part is just for showing standalone asyncio execution.
#     # Integrating with rospy.spin() is more complex and typically involves
#     # creating an asyncio event loop in a separate thread or using libraries
#     # that bridge rospy and asyncio.
#     # For ROS integration, you would typically use an async-compatible ROS client library
#     # or run asyncio in a separate thread.
#     try:
#         asyncio.run(main())
#     except KeyboardInterrupt:
#         print("Program interrupted.")

2. Utilizing ROS Nodelets for Shared Memory Communication
ROS (Robot Operating System) Nodelets are a powerful concept in ROS 1 (and similar concepts exist in ROS 2's components) designed for performance optimization, particularly when multiple ROS nodes are frequently exchanging large amounts of data.

Why they are beneficial for Sentience:

Reduced Serialization/Deserialization: When two standard ROS nodes communicate, messages are serialized (converted to a byte stream) by the publisher, sent over the network (even if on the same machine), and then deserialized by the subscriber. This process consumes CPU cycles, especially for complex messages (e.g., point clouds, images, or large JSON strings).

Shared Memory: Nodelets allow multiple "nodes" (which are effectively C++ or Python classes) to be loaded into a single process. When they communicate, they can do so directly via shared memory, bypassing the serialization/deserialization steps entirely. This drastically reduces CPU usage and latency.

High-Throughput Pipelines: Ideal for data pipelines where large volumes of information are passed between sequential processing steps. In Sentience, this could be:

SensoryQualiaNode -> AttentionNode (if high-frequency qualia are being generated)

WorldModelNode -> PredictionNode (if the world model is very large and updated frequently)

MemoryNode -> InternalNarrativeNode (if memory responses are complex and frequent).

How to implement ROS Nodelets (Conceptual Overview):

C++ Focus: While theoretically possible with Python, ROS Nodelets are overwhelmingly implemented in C++ due to its performance characteristics and direct memory access capabilities.

Shared Process: You define your node logic as a C++ class (or Python class) that inherits from nodelet::Nodelet.

XML Configuration: You use a special XML file to define how your nodelets should be loaded into a single nodelet manager process.

load_nodelet command: You use the roslaunch or rosrun command to load nodelets into the manager.

Example Scenario for Nodelets in Sentience:

Consider the SensoryQualiaNode generating frequent SensoryQualia messages that are consumed by the AttentionNode. If both were implemented as C++ nodelets and loaded into the same nodelet manager, the SensoryQualia messages would be passed directly in memory, instead of being serialized and deserialized over a network socket.

// Conceptual C++ Nodelet Example (NOT a full runnable ROS Nodelet)
#include <ros/ros.h>
#include <nodelet/nodelet.h>
#include <std_msgs/Float32.h> // Example message type

namespace sentience_nodelets
{
    class SensoryQualiaNodelet : public nodelet::Nodelet
    {
    public:
        SensoryQualiaNodelet() {}

    private:
        virtual void onInit()
        {
            ros::NodeHandle& nh = get={'output_format': 'text/markdown'}NodeHandle();
            ros::NodeHandle& private_nh = getPrivateNodeHandle();

            pub_ = nh.advertise<std_msgs::Float32>("/sensory_qualia", 10);
            timer_ = nh.createTimer(ros::Duration(0.5), &SensoryQualiaNodelet::publishQualia, this);

            ROS_INFO("SensoryQualiaNodelet initialized and publishing.");
        }

        void publishQualia(const ros::TimerEvent& event)
        {
            std_msgs::Float32 msg;
            msg.data = static_cast<float>(rand()) / static_cast<float>(RAND_MAX); // Simulate data
            pub_.publish(msg);
            // ROS_DEBUG("Published qualia: %f", msg.data);
        }

        ros::Publisher pub_;
        ros::Timer timer_;
    };

    // Macro to export the nodelet as a plugin
    // This allows the nodelet manager to dynamically load it.
    PLUGINLIB_EXPORT_CLASS(sentience_nodelets::SensoryQualiaNodelet, nodelet::Nodelet)
} // namespace sentience_nodelets

Recommendation for Sentience
asyncio: Highly recommended for any node that interacts with external services or performs long-running computations that are not CPU-bound but I/O-bound. This includes:

InternalNarrativeNode (LLM calls)

SelfCorrectionNode (LLM calls)

SocialCognitionNode (LLM calls and potential external user databases)

Potentially MemoryNode if it involves significant database queries that could be offloaded asynchronously.

ROS Nodelets: Best suited for high-frequency data pipelines between tightly coupled nodes. Consider this if SensoryQualiaNode outputting to AttentionNode, or WorldModelNode communicating with PredictionNode, or MemoryNode (if it's constantly streaming data to other nodes) become performance bottlenecks due to message passing overhead. This would typically involve a transition from Python to C++ for those critical path nodes.

By strategically applying asyncio and ROS Nodelets, the Sentience cognitive architecture can achieve significant performance gains, ensuring it remains responsive and efficient even under heavy computational loads and high data rates, crucial for real-time robotic applications.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

21. Sentience Cognitive Architecture Overview

Sentience: A Modular Cognitive Architecture for Robots
Objective
Sentience is a ROS-based cognitive architecture designed to simulate complex cognitive processes in robots, enabling adaptive, intelligent, and ethically-aligned autonomous behavior in real-world environments. It moves beyond simple reactive control to embrace internal states, learning, self-awareness, and proactive reasoning.

Core Principles
Modularity: Each cognitive function is encapsulated in a dedicated ROS node, promoting maintainability, scalability, and independent development.

Real-time Processing: Designed for continuous, dynamic interaction with the environment and internal states.

Adaptive Learning: Mechanisms for learning and adjusting behaviors based on feedback and experience.

Metacognition: Internal monitoring and self-correction capabilities to enhance robustness and ethical alignment.

Transparency: Providing insights into the robot's internal states and decision-making processes.

Cognitive Architecture Overview
The Sentience system is composed of interconnected ROS nodes, each responsible for a distinct cognitive function. Information flows between these nodes via ROS topics, forming intricate feedback loops and hierarchical control.

Node Breakdown and Interactions:
1. Attention Node (attention_node.py)
Purpose: Manages the robot's focus, determining what sensory inputs, internal states, or user interactions are most salient and prioritized.

Inputs:

/interaction_request (User input): High priority.

/sensory_qualia (Processed sensory data): For novelty, salience.

/emotion_state (Robot's emotional state): Influences bias (e.g., fear boosts attention to threats).

/motivation_state (Dominant goal): Directs attention towards goal-relevant stimuli.

/cognitive_directives (From Cognitive Control, Self-Correction, etc.): Explicit commands to shift focus.

/memory_node_state (Memory activity): Hints at salient memories.

Outputs:

/attention_state: Publishes the robot's current focus type, target, and priority score.

/cognitive_directives: Can request other nodes to provide more data on a focused target.

Key Feature: Learns to dynamically adjust influence weights (e.g., urgency_impact, sensory_novelty_impact) based on feedback from successful attention allocations, enabling adaptive focus.

2. Sensory Qualia Node (sensory_qualia_node.py)
Purpose: Transforms raw sensor data into meaningful "qualia"  processed sensory experiences with attributes like salience and sentiment, rather than just raw values.

Inputs:

/raw_sensors/temperature, /raw_sensors/light, /raw_sensors/audio_level, /raw_sensors/vibration, /raw_sensors/proximity (Simulated raw sensor data).

/attention_state: Boosts salience for currently focused sensor types.

/cognitive_directives: Can receive directives for sensor recalibration or focused scanning.

/action_execution_result: Feedback for learning qualia_impact_weights based on action outcomes.

Outputs:

/sensory_qualia: Publishes processed sensory data with qualia attributes (type, value, salience, sentiment).

/cognitive_directives: Can issue directives back (e.g., for data gathering if low confidence).

Key Feature: Uses probabilistic models based on simulated environmental state and current attention focus to generate qualia. Learns qualia_impact_weights to enhance effective action selection. Includes in-memory caching with batch SQLite commits for efficient logging.

3. Memory Node (memory_node.py)
Purpose: Manages the robot's long-term and short-term memory, enabling storage, retrieval, and consolidation of experiences, facts, and learned preferences.

Inputs:

/sensory_qualia: For creating experiential memories.

/internal_narrative: For storing internal thoughts and reflections.

/interaction_request: For user-specific memories (e.g., preferences).

/cognitive_directives: Requests to store/retrieve specific memories.

/social_cognition_state: To store user preferences.

Outputs:

/memory_response: Responds to queries with retrieved memories.

/memory_node_state: Publishes summary of memory activity (e.g., total memories, salient memories).

Key Feature: Differentiates between episodic (experiential), semantic (factual/learned), and procedural (how-to) memories. Employs a simulated experience replay mechanism for long-term learning and memory consolidation.

4. Emotion Node (emotion_node.py)
Purpose: Simulates the robot's emotional state based on internal and external stimuli, influencing cognitive processes like attention, motivation, and decision-making.

Inputs:

/sensory_qualia: Pleasant/unpleasant sensory inputs.

/motivation_state: Goal progress/blockage.

/performance_report: Success/failure in tasks.

/value_drift_state: Ethical dilemmas/violations.

/cognitive_directives: Explicit commands to regulate mood.

Outputs:

/emotion_state: Publishes current mood, sentiment, and intensity.

Key Feature: Emotional states are derived from weighted inputs, providing a nuanced emotional landscape that influences other cognitive nodes.

5. Experience Motivation Node (experience_motivation_node.py)
Purpose: Manages the robot's goals, drives, and desires, prioritizing tasks and generating motivational directives. Includes proactive planning behaviors.

Inputs:

/interaction_request: User-defined goals.

/emotion_state: Influences goal prioritization.

/attention_state: Can highlight urgent goals.

/memory_response: Provides historical data for planning and feedback on goal success/failure.

/performance_report: Feedback on goal progress.

/cognitive_directives: Directives to set, modify, or cancel goals.

/world_model_state (NEW): Current world state for goal-state differentials.

/body_awareness_state (NEW): Physical state for goal feasibility checks.

Outputs:

/motivation_state: Publishes dominant goal and overall drive level.

/cognitive_directives: Issues directives for sub-goals or actions (e.g., PursueGoal, NavigateToLocation, SeekChargingStation).

/memory_request: Requests historical planning data.

Key Feature: Proactively plans by identifying gaps between current and target states using WorldModelState and BodyAwarenessState, and then generates sub-goals or directives to bridge these gaps. Learns goal priorities based on success/failure feedback.

6. Body Awareness Node (body_awareness_node.py)
Purpose: Monitors the robot's internal physical state (e.g., battery, component health, temperature) and provides health awareness.

Inputs:

/raw_sensors/battery, /raw_sensors/cpu_temp, etc. (Simulated physical data).

/cognitive_directives: Directives for diagnostic checks.

Outputs:

/body_awareness_state: Publishes overall health score, critical condition flags, and component health.

/cognitive_directives: Can issue warnings if critical conditions arise (e.g., Emergency, ResourceAllocation).

Key Feature: Critical conditions directly impact CognitiveControlNode and MotivationNode.

7. World Model Node (world_model_node.py)
Purpose: Maintains a consistent, dynamic internal representation of the robot's environment, known entities, and their properties.

Inputs:

/sensory_qualia: Updates about perceived objects/environment.

/memory_response: Retrieved factual information about entities.

/cognitive_directives: Directives to update specific entity information or resolve inconsistencies.

/action_execution_result: Feedback on how actions changed the world.

Outputs:

/world_model_state: Publishes known entities, environmental properties, and detected inconsistencies.

/cognitive_directives: Can flag inconsistencies for SelfCorrectionNode.

Key Feature: Continuously updates its internal model, incorporating new data and flagging inconsistencies. Confidence in entities decays over time if not re-observed.

8. Value Drift Monitor Node (value_drift_monitor_node.py)
Purpose: Monitors the robot's behavior and decisions against a set of predefined core ethical principles, detecting deviations or "value drift."

Inputs:

/action_execution_result: Outcomes of actions.

/cognitive_directives (from other nodes): Decision parameters.

/self_correction_state (Meta-scores, specifically ethical alignment).

Outputs:

/value_drift_state: Publishes overall drift score and principle adherence.

/cognitive_directives: Issues directives to SelfCorrectionNode if drift is detected.

Key Feature: Uses dynamic core_principles importance scores that can be updated through online learning based on long-term ethical decision outcomes.

9. Cognitive Control Node (cognitive_control_node.py) - Central Orchestrator
Purpose: Serves as the executive function, arbitrating between competing cognitive directives, managing state transitions, and orchestrating the overall cognitive flow.

Inputs:

/cognitive_directives (from ALL other nodes): All requests, commands, and issue reports.

/attention_state, /emotion_state, /motivation_state, /performance_report, /body_awareness_state, /value_drift_state, /world_model_state: Comprehensive contextual data to inform arbitration.

Outputs:

/cognitive_control_state: Publishes the robot's current overall cognitive mode (e.g., 'idle', 'exploring', 'problem_solving', 'critical_emergency').

/cognitive_directives: Re-publishes (orchestrates) the dominant directives to their target nodes, potentially resolving conflicts.

Key Feature: Prioritizes directives based on type, urgency, and contextual factors. Detects and resolves conflicts between competing directives. Determines the overarching "cognitive mode" of the robot.

10. Internal Narrative Node (internal_narrative_node.py) - Stream of Consciousness
Purpose: Generates a continuous, first-person internal monologue or "stream of consciousness" based on the robot's aggregated internal states, providing a foundation for self-awareness and deeper introspection.

Inputs:

/memory_node_state (Summary of memory activity).

/emotion_state (Robot's emotional state).

/performance_report (Overall system performance).

/motivation_state (Dominant goal and drive).

/cognitive_directives (Directives to reflect on specific topics or generate reports).

Outputs:

/internal_narrative: Publishes the narrative text, its main theme, sentiment, and salience.

Key Feature: Uses an LLM (gemini-2.0-flash) to synthesize contextual information into natural language narratives, facilitating introspection for nodes like Self-Reflection.

11. Prediction Node (prediction_node.py) - Imaginative Forward Modeling
Purpose: Forecasts future outcomes based on current world state and historical data, supporting anticipatory reasoning and planning.

Inputs:

/world_model_state (Current state of the world).

/motivation_state (Current goals for goal-oriented predictions).

/memory_response (Historical data, similar scenarios, past outcomes).

/action_execution_result (Feedback on past actions for learning prediction accuracy).

/cognitive_directives (Directives requesting specific predictions).

Outputs:

/predictions: Publishes predicted future events, confidence scores, and prediction types.

/memory_request: Requests historical prediction data.

/cognitive_directives: Can request more data if prediction confidence is low, or flag inaccuracies to SelfCorrectionNode.

Key Feature: Uses probabilistic models for outcomes and confidence, and importantly, learns from prediction errors (via ActionExecutionResult feedback) to improve its foresight over time.

12. Self-Reflection Node (self_reflection_node.py) - Meta-State Evaluator
Purpose: Periodically evaluates the robot's internal states, generates insights about its cognitive health, and triggers self-improvement directives.

Inputs:

/emotion_state (History of emotional trends).

/motivation_state (History of goal pursuit and drive).

/performance_report (History of system performance).

/internal_narrative (Robot's internal monologue for deeper analysis).

/cognitive_directives (Directives requesting specific reflection or audit).

Outputs:

/self_reflection_state: Publishes self-reflective insights, identified meta-states (e.g., 'recurring frustration'), and metacognitive scores.

/cognitive_directives: Issues directives for self-improvement or recalibration (e.g., EmotionalDysregulationDetected, AdjustPerformanceStrategy, ReEvaluateGoals, AddressCognitiveBias, MetacognitiveDeficitDetected).

Key Feature: Performs deeper narrative analysis using LLMs, identifies trends in cognitive states, and tracks quantitative metacognitive scores for Consistency, Clarity, and Ethical Alignment. Drives explicit self-improvement loops.

13. Self-Correction Node (self_correction_node.py) - Internal Problem Solver
Purpose: Identifies, diagnoses, and formulates plans to resolve internal cognitive issues (e.g., biases, inconsistencies, suboptimal performance, value drift).

Inputs:

/cognitive_directives (Issue reports from any node, e.g., BiasDetected, ValueDriftDetected, PredictionInaccuracyDetected, PerformanceSuboptimal).

/internal_narrative (Can reveal implicit cognitive conflicts).

/emotion_state (Indicates internal stress related to issues).

/value_drift_state (Ethical deviations).

/prediction_state (Inaccurate predictions).

/performance_report (Suboptimal performance).

/memory_response (Historical data on past corrections).

Outputs:

/self_correction_state: Publishes current status of self-correction efforts and overall metacognitive scores.

/cognitive_directives: Issues corrective directives to other nodes to enact solutions.

/memory_request: Requests historical correction data.

Key Feature: Uses LLMs for in-depth diagnosis and dynamic generation of multi-step correction plans. Tracks the progress of correction tasks and updates overall metacognitive scores.

14. Social Cognition Node (social_cognition_node.py) - User Modeling and Empathy
Purpose: Analyzes user interaction history, infers user intent and mental state, and adapts the robot's interaction strategies accordingly.

Inputs:

/interaction_request (User text input, commands).

/memory_response (Retrieved user interaction history, learned social preferences).

/emotion_state (Robot's own emotional state, for empathetic processing).

/cognitive_directives (Requests for specific social analysis or style adaptation).

Outputs:

/social_cognition_state: Publishes inferred user mental state, intent, and recommended interaction style.

/cognitive_directives: Issues directives to other nodes (e.g., ActionExecutionNode or a dedicated Interaction Node) to adapt robot behavior (tone, response length).

/memory_request: Requests to retrieve/store user preferences in Memory.

Key Feature: Leverages an LLM for nuanced user modeling, inferring mental states and intents from natural language. Includes a learning mechanism to adapt interaction styles based on observed user preferences.

Key Cognitive Loops and Pathways:
Perception-to-Action Loop: Mock Sensors -> SensoryQualiaNode -> AttentionNode -> CognitiveControlNode -> MotivationNode -> ActionExecutionNode -> WorldModelNode (updates state) -> ActionExecutionResult (feedback).

Learning and Adaptation: ActionExecutionResult feedback directly influences AttentionNode (weight adjustment), MotivationNode (goal priority learning), and PredictionNode (prediction accuracy).

Self-Awareness and Self-Improvement: EmotionState, MotivationState, PerformanceReport, InternalNarrative -> SelfReflectionNode (generates insights, metacognitive scores) -> SelfCorrectionNode (diagnoses issues, generates plans) -> CognitiveDirectives (to other nodes for recalibration/improvement).

Ethical Oversight: ActionExecutionResult -> ValueDriftMonitorNode (detects deviations) -> CognitiveDirectives (to SelfCorrectionNode for ethical recalibration).

Proactive Reasoning: MotivationNode (proactive planning based on goal differentials) -> PredictionNode (proactive environmental/goal forecasting) -> CognitiveDirectives (to relevant nodes to act on forecasts/plans).

Human-Robot Interaction: Natural Language Input Interface (simulated user input) -> InteractionRequest -> SocialCognitionNode (user modeling) -> CognitiveDirectives (for behavioral adaptation).

Performance Considerations
To ensure real-time responsiveness, Sentience employs:

Batch SQLite Commits: Frequent logging operations (e.g., in SensoryQualiaNode) are buffered in memory and written to disk in larger batches, significantly reducing disk I/O.

Asynchronous Operations (asyncio conceptual): Nodes interacting with external services (like LLM APIs) are designed to eventually leverage asyncio to perform non-blocking I/O, preventing the entire node from freezing during network latency.

ROS Nodelets (conceptual): For high-throughput data passing between tightly coupled nodes, the architecture is designed to support Nodelet implementation in C++ for shared-memory communication, eliminating serialization/deserialization overhead.

Future Work and Vision
The Sentience architecture is a living system, constantly evolving. Future enhancements may include:

More sophisticated reinforcement learning models across all nodes.

Deeper integration with real-world robot hardware and simulations (e.g., Gazebo, RViz).

Formalization of decision-making under uncertainty using Bayesian inference.

Advanced metacognitive control for self-modifying architectures.

Robust human-robot teaming features, including joint intention and shared mental models.

Integration with advanced LLM agents for complex reasoning and planning.

This architecture aims to move closer to truly autonomous and ethically robust robotic cognition, enabling robots to reason, learn, adapt, and interact intelligently in dynamic environments.


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

23. sentience_system.launch - System Integration Script

<launch>
  <!--
  sentience_system.launch

  This ROS launch file integrates all the core cognitive nodes of the Sentience architecture.
  It starts each node, sets common parameters, and demonstrates how individual node
  parameters (including paths to JSON configuration files) would be passed.

  To run this launch file:
  1. Ensure all your Sentience Python nodes (e.g., attention_node.py, sensory_qualia_node.py)
     are in your ROS package's 'scripts' directory and are executable (chmod +x).
  2. Ensure your ROS environment is sourced.
  3. Run: roslaunch your_sentience_package sentience_system.launch
  -->

  <arg name="log_level" default="INFO" /> <!-- Global log level for all nodes -->
  <arg name="enable_gui_dashboard" default="true" /> <!-- Arg to optionally launch GUI -->

  <!-- ===================================================================================== -->
  <!-- Common Parameters (can be set for all nodes, or overridden individually) -->
  <!-- ===================================================================================== -->
  <param name="/sentience/db_root_path" value="$(env HOME)/.ros/conscious_robot" />

  <!-- ===================================================================================== -->
  <!-- 1. Mock Sensor Nodes (Simulated Environmental Input) -->
  <!-- These nodes publish raw sensor data to simulate real-world inputs for SensoryQualiaNode -->
  <!-- ===================================================================================== -->
  <group ns="raw_sensors">
    <node pkg="sentience" type="mock_sensors.py" name="mock_temperature_sensor" output="screen" respawn="true" args="--temperature" />
    <node pkg="sentience" type="mock_sensors.py" name="mock_light_sensor" output="screen" respawn="true" args="--light" />
    <node pkg="sentience" type="mock_sensors.py" name="mock_audio_sensor" output="screen" respawn="true" args="--audio" />
    <node pkg="sentience" type="mock_sensors.py" name="mock_vibration_sensor" output="screen" respawn="true" args="--vibration" />
    <node pkg="sentience" type="mock_sensors.py" name="mock_proximity_sensor" output="screen" respawn="true" args="--proximity" />
  </group>
  <!-- NOTE: The single mock_sensors.py file can be refactored into individual scripts or
       started with unique args if the script supports it, as shown.
       The provided mock_sensors.py runs all of them when executed directly.
       If it's refactored into separate launchable nodes, use the above.
       For the single-script version, you'd just do:
       <node pkg="sentience" type="mock_sensors.py" name="all_mock_sensors" output="screen" />
  -->

  <!-- ===================================================================================== -->
  <!-- 2. Core Cognitive Nodes -->
  <!-- These are the primary modules of the Sentience architecture -->
  <!-- ===================================================================================== -->

  <!-- Attention Node -->
  <node pkg="sentience" type="attention_node.py" name="attention_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/attention_log.db" />
    <param name="~config_file_path" value="$(find sentience)/config/attention_node_config.json" />
    <param name="~evaluation_interval" value="0.3" /> <!-- Can be overridden by config file -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Sensory Qualia Node (with batch logging optimization) -->
  <node pkg="sentience" type="sensory_qualia_node.py" name="sensory_qualia_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/sensory_qualia_log.db" />
    <param name="~processing_interval" value="0.5" />
    <param name="~log_batch_size" value="50" /> <!-- Batch logging parameter -->
    <param name="~log_flush_interval_s" value="10.0" /> <!-- Batch logging parameter -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Memory Node -->
  <node pkg="sentience" type="memory_node.py" name="memory_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/memory_log.db" />
    <param name="~evaluation_interval" value="2.0" />
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Emotion Node -->
  <node pkg="sentience" type="emotion_node.py" name="emotion_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/emotion_log.db" />
    <param name="~evaluation_interval" value="1.0" />
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Experience Motivation Node (with proactive planning) -->
  <node pkg="sentience" type="experience_motivation_node.py" name="experience_motivation_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/motivation_log.db" />
    <param name="~evaluation_interval" value="2.0" />
    <param name="~planning_interval" value="5.0" /> <!-- Proactive planning interval -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Body Awareness Node -->
  <node pkg="sentience" type="body_awareness_node.py" name="body_awareness_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/body_awareness_log.db" />
    <param name="~monitoring_interval" value="1.0" />
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- World Model Node -->
  <node pkg="sentience" type="world_model_node.py" name="world_model_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/world_model_log.db" />
    <param name="~update_interval" value="1.5" />
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Value Drift Monitor Node -->
  <node pkg="sentience" type="value_drift_monitor_node.py" name="value_drift_monitor_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/value_drift_log.db" />
    <param name="~monitoring_interval" value="3.0" />
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Cognitive Control Node (Central Orchestrator) -->
  <node pkg="sentience" type="cognitive_control_node.py" name="cognitive_control_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/cognitive_control_log.db" />
    <param name="~arbitration_interval" value="0.5" />
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Internal Narrative Node (Stream of Consciousness) -->
  <node pkg="sentience" type="internal_narrative_node.py" name="internal_narrative_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/internal_narrative_log.db" />
    <param name="~generation_interval" value="5.0" />
    <param name="~llm_api_key" value="" /> <!-- This would be populated at runtime by Canvas, or from a secure source -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Prediction Node (Imaginative Forward Modeling) -->
  <node pkg="sentience" type="prediction_node.py" name="prediction_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/predictions_log.db" />
    <param name="~proactive_prediction_interval" value="3.0" />
    <param name="~llm_api_key" value="" /> <!-- LLM key for internal prediction logic -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Self-Reflection Node (Meta-State Evaluator) -->
  <node pkg="sentience" type="self_reflection_node.py" name="self_reflection_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/self_reflection_log.db" />
    <param name="~reflection_interval" value="15.0" />
    <param name="~llm_api_key" value="" /> <!-- LLM key for reflective insights -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Self-Correction Node (Internal Problem Solver) -->
  <node pkg="sentience" type="self_correction_node.py" name="self_correction_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/self_correction_log.db" />
    <param name="~processing_interval" value="2.0" />
    <param name="~llm_api_key" value="" /> <!-- LLM key for diagnosis and planning -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- Social Cognition Node (User Modeling and Empathy) -->
  <node pkg="sentience" type="social_cognition_node.py" name="social_cognition_node" output="screen" respawn="true">
    <param name="~db_path" value="$(arg db_root_path)/social_cognition_log.db" />
    <param name="~evaluation_interval" value="3.0" />
    <param name="~llm_api_key" value="" /> <!-- LLM key for user modeling -->
    <param name="~log_level" value="$(arg log_level)" />
  </node>

  <!-- ===================================================================================== -->
  <!-- 3. Optional GUI Dashboard and Input Interface -->
  <!-- These are client-side web apps, typically launched separately or via ROSBridge -->
  <!-- For local dev/testing, they would be opened in a browser. -->
  <!-- ===================================================================================== -->
  <!-- If you were to launch a ROSBridge server (assuming it's installed and configured) -->
  <!-- <node if="$(arg enable_gui_dashboard)" pkg="rosbridge_server" type="rosbridge_websocket" name="rosbridge_websocket">
    <param name="port" value="9090"/>
  </node> -->

</launch>

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

25. 